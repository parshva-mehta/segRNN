{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2202b95-bff9-4b44-8a29-d0b27d8108c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "444d6b91-c49d-4a6f-bb7b-ceeaa97398bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"JRB.csv\", low_memory=False)  # force to str\n",
    "# df[df['station'] == 'JRB'].shape[0] == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800f972e-509e-40f2-bb51-5d590cffee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "# Load the dataset\n",
    "# Replace 'your_dataset.csv' with your actual data file\n",
    "df = pd.read_csv('JRB.csv', low_memory=False)\n",
    "\n",
    "# Step 1: Ensure 'valid' column is datetime and sort the DataFrame\n",
    "df['valid'] = pd.to_datetime(df['valid'])\n",
    "df = df.sort_values(by=['station', 'valid']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e0dbc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>dwpf</th>\n",
       "      <th>relh</th>\n",
       "      <th>drct</th>\n",
       "      <th>sknt</th>\n",
       "      <th>p01i</th>\n",
       "      <th>alti</th>\n",
       "      <th>mslp</th>\n",
       "      <th>...</th>\n",
       "      <th>wxcodes</th>\n",
       "      <th>ice_accretion_1hr</th>\n",
       "      <th>ice_accretion_3hr</th>\n",
       "      <th>ice_accretion_6hr</th>\n",
       "      <th>peak_wind_gust</th>\n",
       "      <th>peak_wind_drct</th>\n",
       "      <th>peak_wind_time</th>\n",
       "      <th>feel</th>\n",
       "      <th>metar</th>\n",
       "      <th>snowdepth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 08:15:00</td>\n",
       "      <td>73.40</td>\n",
       "      <td>66.20</td>\n",
       "      <td>78.19</td>\n",
       "      <td>240.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>73.40</td>\n",
       "      <td>KJRB 211215Z 24005KT 10SM CLR 23/19 A3017 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 08:35:00</td>\n",
       "      <td>73.40</td>\n",
       "      <td>66.20</td>\n",
       "      <td>78.19</td>\n",
       "      <td>240.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>73.40</td>\n",
       "      <td>KJRB 211235Z 24005KT 10SM CLR 23/19 A3017 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 08:55:00</td>\n",
       "      <td>75.20</td>\n",
       "      <td>66.20</td>\n",
       "      <td>73.61</td>\n",
       "      <td>240.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>75.20</td>\n",
       "      <td>KJRB 211255Z 24006KT 10SM CLR 24/19 A3017 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 09:15:00</td>\n",
       "      <td>75.20</td>\n",
       "      <td>66.20</td>\n",
       "      <td>73.61</td>\n",
       "      <td>240.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>75.20</td>\n",
       "      <td>KJRB 211315Z 24005KT 10SM CLR 24/19 A3017 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 09:35:00</td>\n",
       "      <td>78.80</td>\n",
       "      <td>66.20</td>\n",
       "      <td>65.33</td>\n",
       "      <td>240.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.16</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>80.82</td>\n",
       "      <td>KJRB 211335Z 24005KT 10SM CLR 26/19 A3016 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  station               valid   tmpf   dwpf   relh    drct  sknt  p01i   alti  \\\n",
       "0     JRB 2016-07-21 08:15:00  73.40  66.20  78.19  240.00  5.00  0.00  30.17   \n",
       "1     JRB 2016-07-21 08:35:00  73.40  66.20  78.19  240.00  5.00  0.00  30.17   \n",
       "2     JRB 2016-07-21 08:55:00  75.20  66.20  73.61  240.00  6.00  0.00  30.17   \n",
       "3     JRB 2016-07-21 09:15:00  75.20  66.20  73.61  240.00  5.00  0.00  30.17   \n",
       "4     JRB 2016-07-21 09:35:00  78.80  66.20  65.33  240.00  5.00  0.00  30.16   \n",
       "\n",
       "  mslp  ... wxcodes ice_accretion_1hr ice_accretion_3hr ice_accretion_6hr  \\\n",
       "0    M  ...       M                 M                 M                 M   \n",
       "1    M  ...       M                 M                 M                 M   \n",
       "2    M  ...       M                 M                 M                 M   \n",
       "3    M  ...       M                 M                 M                 M   \n",
       "4    M  ...       M                 M                 M                 M   \n",
       "\n",
       "  peak_wind_gust peak_wind_drct peak_wind_time   feel  \\\n",
       "0              M              M              M  73.40   \n",
       "1              M              M              M  73.40   \n",
       "2              M              M              M  75.20   \n",
       "3              M              M              M  75.20   \n",
       "4              M              M              M  80.82   \n",
       "\n",
       "                                               metar snowdepth  \n",
       "0  KJRB 211215Z 24005KT 10SM CLR 23/19 A3017 RMK AO1         M  \n",
       "1  KJRB 211235Z 24005KT 10SM CLR 23/19 A3017 RMK AO1         M  \n",
       "2  KJRB 211255Z 24006KT 10SM CLR 24/19 A3017 RMK AO1         M  \n",
       "3  KJRB 211315Z 24005KT 10SM CLR 24/19 A3017 RMK AO1         M  \n",
       "4  KJRB 211335Z 24005KT 10SM CLR 26/19 A3016 RMK AO1         M  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c993893a-b1e6-41b5-8243-6799fb89d8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1698756/2860399940.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Replace placeholders with np.nan in continuous columns\n",
    "continuous_cols = ['tmpf', 'dwpf', 'relh', 'feel', 'drct', 'sknt', 'gust',\n",
    "                   'peak_wind_gust', 'peak_wind_drct', 'alti', 'mslp', 'vsby',\n",
    "                   'p01i', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr',\n",
    "                   'skyl1', 'skyl2', 'skyl3', 'skyl4', 'snowdepth', 'peak_wind_time']\n",
    "\n",
    "# List of placeholders to replace\n",
    "placeholders = ['M', 'T', '', 'NaN', 'NULL', 'None']\n",
    "\n",
    "# Replace placeholders with np.nan\n",
    "df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n",
    "\n",
    "# Convert continuous columns to numeric, coercing errors to np.nan\n",
    "for col in continuous_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d200400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                   6865\n",
      "dwpf                   7015\n",
      "relh                   7112\n",
      "feel                   7125\n",
      "drct                  25052\n",
      "sknt                   5024\n",
      "gust                 101714\n",
      "peak_wind_gust       108345\n",
      "peak_wind_drct       108345\n",
      "alti                  12732\n",
      "mslp                  37235\n",
      "vsby                   9941\n",
      "p01i                   7730\n",
      "ice_accretion_1hr    114664\n",
      "ice_accretion_3hr    114664\n",
      "ice_accretion_6hr    114664\n",
      "skyl1                 54223\n",
      "skyl2                 93650\n",
      "skyl3                107296\n",
      "skyl4                114664\n",
      "snowdepth            114664\n",
      "peak_wind_time       114664\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in continuous columns before processing:\")\n",
    "print(df[continuous_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd125b17-a291-4804-9adc-259aa99af2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns after processing:\n",
      "feel              0\n",
      "vsby              0\n",
      "drct              0\n",
      "mslp              0\n",
      "sknt              0\n",
      "skyl2             0\n",
      "p01i              0\n",
      "dwpf              0\n",
      "relh              0\n",
      "tmpf              0\n",
      "peak_wind_gust    0\n",
      "skyl3             0\n",
      "peak_wind_drct    0\n",
      "skyl1             0\n",
      "alti              0\n",
      "gust              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Handle missing values in continuous variables\n",
    "# Apply linear interpolation within each station group using transform\n",
    "df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
    "    lambda group: group.interpolate(method='linear')\n",
    ")\n",
    "\n",
    "# Handle any remaining missing values with forward and backward fill using transform\n",
    "df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
    "    lambda group: group.ffill().bfill()\n",
    ")\n",
    "\n",
    "# all of these columns have all nans\n",
    "bad_columns = bad_columns = [col for col in df.columns if df[col].isnull().sum() == df.shape[0]]\n",
    "# for JRB, this is ['ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'skyl4', 'snowdepth', 'peak_wind_time']\n",
    "df.drop(columns=bad_columns, inplace=True)\n",
    "continuous_cols = list(set(continuous_cols) - set(bad_columns))\n",
    "\n",
    "\n",
    "# Verify missing values are filled\n",
    "print(\"Missing values in continuous columns after processing:\")\n",
    "print(df[continuous_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ba1dd0-f082-475f-ab51-527f8d9e5574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station skyc1 skyc2 skyc3 skyc4 wxcodes\n",
      "0     JRB   CLR     M     M     M       M\n",
      "1     JRB   CLR     M     M     M       M\n",
      "2     JRB   CLR     M     M     M       M\n",
      "3     JRB   CLR     M     M     M       M\n",
      "4     JRB   CLR     M     M     M       M\n",
      "   station  skyc1  skyc2  skyc3  skyc4  wxcodes\n",
      "0        0      1      2      1      0       26\n",
      "1        0      1      2      1      0       26\n",
      "2        0      1      2      1      0       26\n",
      "3        0      1      2      1      0       26\n",
      "4        0      1      2      1      0       26\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Encode categorical variables\n",
    "# Categorical columns\n",
    "categorical_cols = ['station', 'skyc1', 'skyc2', 'skyc3', 'skyc4', 'wxcodes']\n",
    "\n",
    "# Fill missing values in categorical columns with a placeholder\n",
    "df[categorical_cols] = df[categorical_cols].fillna('Unknown')\n",
    "\n",
    "print(df[categorical_cols].head())\n",
    "\n",
    "# Apply label encoding to categorical columns\n",
    "le_dict = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    le_dict[col] = le  # Save the encoder if needed later\n",
    "\n",
    "print(df[categorical_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6609200a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metar', 'valid'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.columns) - set(df[continuous_cols].columns) - set(df[categorical_cols].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d77192-039b-4a7e-8e4b-f543ce63b026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114664, 22)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Feature scaling\n",
    "# List of all features (excluding 'valid' and 'metar')\n",
    "feature_cols = continuous_cols + categorical_cols\n",
    "print(df[feature_cols].shape)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "678bb536-b26d-4e1f-9521-baf8eaa878f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114640, 24, 22)\n",
      "(114640, 1)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Prepare sequences for LSTM input\n",
    "# Assuming we are predicting 'tmpf' (temperature) as the target variable\n",
    "# and using previous 24 time steps/8 hours (n_steps_in) to predict the next time step/20 minutes from now (n_steps_out)\n",
    "# create sliding window sequences X: (114640, 24, features), y: (114640, 1)\n",
    "\n",
    "n_steps_in = 24  # Number of past time steps\n",
    "n_steps_out = 1  # Number of future time steps to predict\n",
    "\n",
    "# We'll create sequences for each station separately\n",
    "def create_sequences(data, n_steps_in, n_steps_out, target_col):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps_in - n_steps_out + 1):\n",
    "        X.append(data[i:(i + n_steps_in), :])\n",
    "        y.append(data[(i + n_steps_in):(i + n_steps_in + n_steps_out), target_col])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare data for each station\n",
    "X_list = []\n",
    "y_list = []\n",
    "stations = df['station'].unique()\n",
    "\n",
    "for station in stations:\n",
    "    station_data = df[df['station'] == station]\n",
    "    station_data = station_data.reset_index(drop=True)\n",
    "    data_values = station_data[feature_cols].values\n",
    "    target_col_index = feature_cols.index('tmpf')  # Index of target variable in features\n",
    "\n",
    "    X_station, y_station = create_sequences(data_values, n_steps_in, n_steps_out, target_col_index)\n",
    "    X_list.append(X_station)\n",
    "    y_list.append(y_station)\n",
    "\n",
    "\n",
    "# Concatenate data from all stations\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c60c4d2-3530-4638-baa3-d182686746da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Split the data into training and testing sets\n",
    "# Since it's time-series data, we'll use the first 80% for training and the rest for testing\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Now the data is ready for training the LSTM model\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b82caf3-0b75-4599-80b7-ed39d935ad3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n",
      "inputsize is 22\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = WeatherDataset(X_train, y_train)\n",
    "test_dataset = WeatherDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Step 8: Define and Train an LSTM Model Using PyTorch\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # batch_first=True: input and output tensors are of shape (batch, seq, feature)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, x):\n",
    "        # Set initial hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = out[:, -1, :]  # Take the output from the last time step\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device is {device}')\n",
    "\n",
    "input_size = X.shape[2]  # Number of features\n",
    "print(f'inputsize is {input_size}')\n",
    "hidden_size = 50\n",
    "num_layers = 1\n",
    "output_size = n_steps_out  # Number of outputs\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b710219-3a69-4677-9c2e-438bccf7115d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Train Loss: 0.0772, Val Loss: 0.0095\n",
      "Epoch [2/50], Train Loss: 0.0454, Val Loss: 0.0077\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Backward and optimize\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 25\u001b[0m, in \u001b[0;36mLSTMModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Forward propagate LSTM\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# out: tensor of shape (batch_size, seq_length, hidden_size)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Decode the hidden state of the last time step\u001b[39;00m\n\u001b[1;32m     27\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]  \u001b[38;5;66;03m# Take the output from the last time step\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/perlmutter/python-3.11/lib/python3.11/site-packages/torch/nn/modules/rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import additional libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Initialize lists for logging losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Step 9: Training the model with logging\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Optional: Validation loss (calculated on test_loader)\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, targets).item()\n",
    "    val_loss /= len(test_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Plotting loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f998f0c-2793-42e8-b393-969b82a7522f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 10: Evaluate the model with scatter plots and metrics\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions.append(outputs.cpu().numpy())\n",
    "        actuals.append(targets.cpu().numpy())\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    actuals = np.concatenate(actuals, axis=0)\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    r2 = r2_score(actuals, predictions)\n",
    "    rmse = mean_squared_error(actuals, predictions, squared=False)\n",
    "\n",
    "    print(f\"Test RÂ²: {r2:.4f}\")\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Scatter plot of predicted vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actuals, predictions, alpha=0.6)\n",
    "plt.plot([actuals.min(), actuals.max()], [actuals.min(), actuals.max()], 'r--', label='Ideal Fit')  # Ideal line\n",
    "plt.xlabel(\"Actual Temperatures\")\n",
    "plt.ylabel(\"Predicted Temperatures\")\n",
    "plt.title(\"Predicted vs. Actual Values\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Time-series plot of predictions vs actuals\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(actuals[:100], label=\"Actual\")\n",
    "plt.plot(predictions[:100], label=\"Predicted\")\n",
    "plt.xlabel(\"Time Steps\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.title(\"Temperature Prediction Over Time\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
