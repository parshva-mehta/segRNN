{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from segrnn import SegRNNModel\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from utils import preprocess_and_save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                     2\n",
      "dwpf                     3\n",
      "relh                     3\n",
      "feel                    14\n",
      "drct                   634\n",
      "sknt                    29\n",
      "gust                 44180\n",
      "peak_wind_gust       48793\n",
      "peak_wind_drct       48793\n",
      "alti                     1\n",
      "mslp                 10049\n",
      "vsby                     0\n",
      "p01i                 10614\n",
      "ice_accretion_1hr    52974\n",
      "ice_accretion_3hr    53018\n",
      "ice_accretion_6hr    53008\n",
      "skyl1                 3687\n",
      "skyl2                21406\n",
      "skyl3                37709\n",
      "skyl4                51113\n",
      "snowdepth            52315\n",
      "peak_wind_time       53032\n",
      "dtype: int64\n",
      "nan thresh is 26516.0\n",
      "bad columns are ['gust', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['mslp', 'vsby', 'dwpf', 'tmpf', 'p01i', 'alti', 'sknt', 'feel', 'drct', 'relh']\n",
      "Missing values in continuous columns after processing:\n",
      "mslp    0\n",
      "vsby    0\n",
      "dwpf    0\n",
      "tmpf    0\n",
      "p01i    0\n",
      "alti    0\n",
      "sknt    0\n",
      "feel    0\n",
      "drct    0\n",
      "relh    0\n",
      "dtype: int64\n",
      "(53032, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs/ROC_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/p/parshvam/segrnn/segRNN/utils.py:77: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                  5037\n",
      "dwpf                  5198\n",
      "relh                  5198\n",
      "feel                  5198\n",
      "drct                  9272\n",
      "sknt                   127\n",
      "gust                 41371\n",
      "peak_wind_gust       44018\n",
      "peak_wind_drct       44018\n",
      "alti                    10\n",
      "mslp                 12991\n",
      "vsby                  1258\n",
      "p01i                  3098\n",
      "ice_accretion_1hr    47642\n",
      "ice_accretion_3hr    47642\n",
      "ice_accretion_6hr    47642\n",
      "skyl1                20500\n",
      "skyl2                37465\n",
      "skyl3                43766\n",
      "skyl4                47642\n",
      "snowdepth            47642\n",
      "peak_wind_time       47642\n",
      "dtype: int64\n",
      "nan thresh is 23821.0\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['mslp', 'vsby', 'dwpf', 'tmpf', 'p01i', 'alti', 'sknt', 'feel', 'drct', 'relh']\n",
      "Missing values in continuous columns after processing:\n",
      "mslp    0\n",
      "vsby    0\n",
      "dwpf    0\n",
      "tmpf    0\n",
      "p01i    0\n",
      "alti    0\n",
      "sknt    0\n",
      "feel    0\n",
      "drct    0\n",
      "relh    0\n",
      "dtype: int64\n",
      "(47642, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs/JRB_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/p/parshvam/segrnn/segRNN/utils.py:77: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                    44\n",
      "dwpf                    44\n",
      "relh                    44\n",
      "feel                    76\n",
      "drct                  1377\n",
      "sknt                   180\n",
      "gust                 52379\n",
      "peak_wind_gust       60197\n",
      "peak_wind_drct       60197\n",
      "alti                     1\n",
      "mslp                 21145\n",
      "vsby                    59\n",
      "p01i                 10097\n",
      "ice_accretion_1hr    63161\n",
      "ice_accretion_3hr    63552\n",
      "ice_accretion_6hr    63518\n",
      "skyl1                16351\n",
      "skyl2                38243\n",
      "skyl3                51742\n",
      "skyl4                63611\n",
      "snowdepth            63611\n",
      "peak_wind_time       63611\n",
      "dtype: int64\n",
      "nan thresh is 31805.5\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['mslp', 'vsby', 'dwpf', 'tmpf', 'p01i', 'alti', 'sknt', 'feel', 'drct', 'relh']\n",
      "Missing values in continuous columns after processing:\n",
      "mslp    0\n",
      "vsby    0\n",
      "dwpf    0\n",
      "tmpf    0\n",
      "p01i    0\n",
      "alti    0\n",
      "sknt    0\n",
      "feel    0\n",
      "drct    0\n",
      "relh    0\n",
      "dtype: int64\n",
      "(63611, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs/BGM_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/p/parshvam/segrnn/segRNN/utils.py:77: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                     9\n",
      "dwpf                   455\n",
      "relh                   455\n",
      "feel                   553\n",
      "drct                  4971\n",
      "sknt                   328\n",
      "gust                 48691\n",
      "peak_wind_gust       56201\n",
      "peak_wind_drct       56201\n",
      "alti                     1\n",
      "mslp                 16369\n",
      "vsby                    25\n",
      "p01i                 10510\n",
      "ice_accretion_1hr    58969\n",
      "ice_accretion_3hr    59122\n",
      "ice_accretion_6hr    59109\n",
      "skyl1                17488\n",
      "skyl2                38038\n",
      "skyl3                49721\n",
      "skyl4                59152\n",
      "snowdepth            59152\n",
      "peak_wind_time       59152\n",
      "dtype: int64\n",
      "nan thresh is 29576.0\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['mslp', 'vsby', 'dwpf', 'tmpf', 'p01i', 'alti', 'sknt', 'feel', 'drct', 'relh']\n",
      "Missing values in continuous columns after processing:\n",
      "mslp    0\n",
      "vsby    0\n",
      "dwpf    0\n",
      "tmpf    0\n",
      "p01i    0\n",
      "alti    0\n",
      "sknt    0\n",
      "feel    0\n",
      "drct    0\n",
      "relh    0\n",
      "dtype: int64\n",
      "(59152, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs/PEO_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/p/parshvam/segrnn/segRNN/utils.py:77: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                   115\n",
      "dwpf                   139\n",
      "relh                   139\n",
      "feel                   149\n",
      "drct                  1325\n",
      "sknt                    58\n",
      "gust                 53522\n",
      "peak_wind_gust       56820\n",
      "peak_wind_drct       56820\n",
      "alti                     1\n",
      "mslp                 16297\n",
      "vsby                    13\n",
      "p01i                  9421\n",
      "ice_accretion_1hr    58874\n",
      "ice_accretion_3hr    59079\n",
      "ice_accretion_6hr    59060\n",
      "skyl1                16377\n",
      "skyl2                36364\n",
      "skyl3                48795\n",
      "skyl4                59111\n",
      "snowdepth            59111\n",
      "peak_wind_time       59111\n",
      "dtype: int64\n",
      "nan thresh is 29555.5\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['mslp', 'vsby', 'dwpf', 'tmpf', 'p01i', 'alti', 'sknt', 'feel', 'drct', 'relh']\n",
      "Missing values in continuous columns after processing:\n",
      "mslp    0\n",
      "vsby    0\n",
      "dwpf    0\n",
      "tmpf    0\n",
      "p01i    0\n",
      "alti    0\n",
      "sknt    0\n",
      "feel    0\n",
      "drct    0\n",
      "relh    0\n",
      "dtype: int64\n",
      "(59111, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs/RME_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pscratch/sd/p/parshvam/segrnn/segRNN/utils.py:77: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                   142\n",
      "dwpf                   290\n",
      "relh                   290\n",
      "feel                   320\n",
      "drct                   994\n",
      "sknt                   254\n",
      "gust                 50746\n",
      "peak_wind_gust       55448\n",
      "peak_wind_drct       55448\n",
      "alti                     0\n",
      "mslp                 16471\n",
      "vsby                   192\n",
      "p01i                  9366\n",
      "ice_accretion_1hr    57798\n",
      "ice_accretion_3hr    58255\n",
      "ice_accretion_6hr    58204\n",
      "skyl1                18803\n",
      "skyl2                39975\n",
      "skyl3                50875\n",
      "skyl4                58320\n",
      "snowdepth            58320\n",
      "peak_wind_time       58320\n",
      "dtype: int64\n",
      "nan thresh is 29160.0\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['mslp', 'vsby', 'dwpf', 'tmpf', 'p01i', 'alti', 'sknt', 'feel', 'drct', 'relh']\n",
      "Missing values in continuous columns after processing:\n",
      "mslp    0\n",
      "vsby    0\n",
      "dwpf    0\n",
      "tmpf    0\n",
      "p01i    0\n",
      "alti    0\n",
      "sknt    0\n",
      "feel    0\n",
      "drct    0\n",
      "relh    0\n",
      "dtype: int64\n",
      "(58320, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs/MSS_processed.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mslp',\n",
       " 'vsby',\n",
       " 'dwpf',\n",
       " 'tmpf',\n",
       " 'p01i',\n",
       " 'alti',\n",
       " 'sknt',\n",
       " 'feel',\n",
       " 'drct',\n",
       " 'relh']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_and_save_data('./csvs/ROC.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/JRB.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/BGM.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/PEO.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/RME.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/MSS.csv', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stid</th>\n",
       "      <th>station_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elev</th>\n",
       "      <th>begints</th>\n",
       "      <th>endts</th>\n",
       "      <th>iem_network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6B9</td>\n",
       "      <td>Skaneateles</td>\n",
       "      <td>42.9140</td>\n",
       "      <td>-76.4408</td>\n",
       "      <td>304.324520</td>\n",
       "      <td>2016-07-22 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALB</td>\n",
       "      <td>ALBANY COUNTY ARPT</td>\n",
       "      <td>42.7576</td>\n",
       "      <td>-73.8036</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1945-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ART</td>\n",
       "      <td>WATERTOWN INTL ARPT</td>\n",
       "      <td>43.9888</td>\n",
       "      <td>-76.0262</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1949-04-30 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BGM</td>\n",
       "      <td>BINGHAMTON/BROOME</td>\n",
       "      <td>42.2086</td>\n",
       "      <td>-75.9797</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>1948-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUF</td>\n",
       "      <td>BUFFALO INTL ARPT</td>\n",
       "      <td>42.9408</td>\n",
       "      <td>-78.7358</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>1942-01-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DKK</td>\n",
       "      <td>DUNKIRK AIRPORT</td>\n",
       "      <td>42.4933</td>\n",
       "      <td>-79.2720</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DSV</td>\n",
       "      <td>DANSVILLE MUNICIPAL</td>\n",
       "      <td>42.5709</td>\n",
       "      <td>-77.7130</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELM</td>\n",
       "      <td>Elmira / Corning</td>\n",
       "      <td>42.1571</td>\n",
       "      <td>-76.8994</td>\n",
       "      <td>287.125370</td>\n",
       "      <td>1949-02-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ELZ</td>\n",
       "      <td>Wellsville Municipal</td>\n",
       "      <td>42.1078</td>\n",
       "      <td>-77.9842</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>1978-06-13 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FOK</td>\n",
       "      <td>WESTHAMPTON BEACH</td>\n",
       "      <td>40.8436</td>\n",
       "      <td>-72.6318</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1943-07-18 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRG</td>\n",
       "      <td>FARMINGDALE/REPUBLC</td>\n",
       "      <td>40.7288</td>\n",
       "      <td>-73.4134</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1943-04-12 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FZY</td>\n",
       "      <td>Oswego County</td>\n",
       "      <td>43.3504</td>\n",
       "      <td>-76.3831</td>\n",
       "      <td>141.826460</td>\n",
       "      <td>1997-05-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GFL</td>\n",
       "      <td>GLEN FALLS/WARREN</td>\n",
       "      <td>43.3412</td>\n",
       "      <td>-73.6103</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1949-01-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GTB</td>\n",
       "      <td>FORT DRUM/WHEELER</td>\n",
       "      <td>44.0556</td>\n",
       "      <td>-75.7195</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>1942-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GVQ</td>\n",
       "      <td>Batavia</td>\n",
       "      <td>43.0317</td>\n",
       "      <td>-78.1675</td>\n",
       "      <td>275.450840</td>\n",
       "      <td>2009-06-28 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HPN</td>\n",
       "      <td>WHITE PLAINS</td>\n",
       "      <td>41.0669</td>\n",
       "      <td>-73.7075</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HTO</td>\n",
       "      <td>EAST HAMPTON</td>\n",
       "      <td>40.9600</td>\n",
       "      <td>-72.2500</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2000-01-07 00:00</td>\n",
       "      <td>2022-03-02 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HWV</td>\n",
       "      <td>BROOKHAVEN AIRPORT/SHIRLEY</td>\n",
       "      <td>40.8217</td>\n",
       "      <td>-72.8689</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1999-09-30 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IAG</td>\n",
       "      <td>NIAGARA FALLS INTL</td>\n",
       "      <td>43.1073</td>\n",
       "      <td>-78.9462</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1951-06-12 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ISP</td>\n",
       "      <td>ISLIP/MACARTHUR</td>\n",
       "      <td>40.7939</td>\n",
       "      <td>-73.1017</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1972-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ITH</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>42.4910</td>\n",
       "      <td>-76.4584</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1972-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IUA</td>\n",
       "      <td>Canandaigua</td>\n",
       "      <td>42.9089</td>\n",
       "      <td>-77.3252</td>\n",
       "      <td>244.597890</td>\n",
       "      <td>2021-10-14 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JFK</td>\n",
       "      <td>NEW YORK/JF KENNEDY</td>\n",
       "      <td>40.6386</td>\n",
       "      <td>-73.7622</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1948-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JHW</td>\n",
       "      <td>JAMESTOWN (AWOS)</td>\n",
       "      <td>42.1534</td>\n",
       "      <td>-79.2580</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>1972-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JPX</td>\n",
       "      <td>East Hampton</td>\n",
       "      <td>40.9594</td>\n",
       "      <td>-72.2517</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1996-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JRB</td>\n",
       "      <td>Manhattan - Wall Street</td>\n",
       "      <td>40.7012</td>\n",
       "      <td>-74.0090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016-07-21 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LGA</td>\n",
       "      <td>New York/LaGuardia</td>\n",
       "      <td>40.7794</td>\n",
       "      <td>-73.8803</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1948-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MGJ</td>\n",
       "      <td>ORANGE COUNTY AIRPORT</td>\n",
       "      <td>41.5092</td>\n",
       "      <td>-74.2650</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>1997-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MSS</td>\n",
       "      <td>MASSENA/RICHARDS</td>\n",
       "      <td>44.9358</td>\n",
       "      <td>-74.8456</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1949-02-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MSV</td>\n",
       "      <td>MONTICELLO(AWOS)</td>\n",
       "      <td>41.7016</td>\n",
       "      <td>-74.7950</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>1981-02-12 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MTP</td>\n",
       "      <td>MONTAUK AIRPORT</td>\n",
       "      <td>41.0731</td>\n",
       "      <td>-71.9233</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1975-10-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>N03</td>\n",
       "      <td>Cortland</td>\n",
       "      <td>42.5929</td>\n",
       "      <td>-76.2174</td>\n",
       "      <td>356.635200</td>\n",
       "      <td>2013-10-24 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NY0</td>\n",
       "      <td>Johnstown</td>\n",
       "      <td>42.9982</td>\n",
       "      <td>-74.3296</td>\n",
       "      <td>263.009900</td>\n",
       "      <td>2014-08-20 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NEW YORK CITY</td>\n",
       "      <td>40.7790</td>\n",
       "      <td>-73.9692</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1943-12-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>OGS</td>\n",
       "      <td>OGDENSBURG INTL</td>\n",
       "      <td>44.6819</td>\n",
       "      <td>-75.4655</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1977-05-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OIC</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>42.5666</td>\n",
       "      <td>-75.5241</td>\n",
       "      <td>306.802000</td>\n",
       "      <td>2007-12-17 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OLE</td>\n",
       "      <td>Olean</td>\n",
       "      <td>42.2412</td>\n",
       "      <td>-78.3714</td>\n",
       "      <td>649.319760</td>\n",
       "      <td>1987-08-13 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PBG</td>\n",
       "      <td>Plattsburgh AFB</td>\n",
       "      <td>44.6382</td>\n",
       "      <td>-73.4624</td>\n",
       "      <td>46.954082</td>\n",
       "      <td>1956-01-14 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PEO</td>\n",
       "      <td>Penn Yan</td>\n",
       "      <td>42.6441</td>\n",
       "      <td>-77.0529</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>1997-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PLB</td>\n",
       "      <td>PLATTSBURGH/CLINTON</td>\n",
       "      <td>44.6875</td>\n",
       "      <td>-73.5245</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1978-08-22 00:00</td>\n",
       "      <td>2007-05-22 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>POU</td>\n",
       "      <td>POUGHKEEPSIE</td>\n",
       "      <td>41.6266</td>\n",
       "      <td>-73.8842</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PTD</td>\n",
       "      <td>Potsdam</td>\n",
       "      <td>44.6757</td>\n",
       "      <td>-74.9469</td>\n",
       "      <td>140.470340</td>\n",
       "      <td>2018-02-03 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RME</td>\n",
       "      <td>Griffiss AFB / Rome</td>\n",
       "      <td>43.2239</td>\n",
       "      <td>-75.3953</td>\n",
       "      <td>143.616610</td>\n",
       "      <td>1942-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ROC</td>\n",
       "      <td>ROCHESTER/MONROE CO</td>\n",
       "      <td>43.1167</td>\n",
       "      <td>-77.6767</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>1948-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SCH</td>\n",
       "      <td>SCHENECTADY AIRPORT</td>\n",
       "      <td>42.8500</td>\n",
       "      <td>-73.9300</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1950-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SDC</td>\n",
       "      <td>Williamson</td>\n",
       "      <td>43.2346</td>\n",
       "      <td>-77.1195</td>\n",
       "      <td>127.863280</td>\n",
       "      <td>2017-12-08 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SLK</td>\n",
       "      <td>SARANAC LAKE/ADIRON</td>\n",
       "      <td>44.3853</td>\n",
       "      <td>-74.2062</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>1973-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SWF</td>\n",
       "      <td>NEWBURGH/STEWART</td>\n",
       "      <td>41.5041</td>\n",
       "      <td>-74.1048</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>1942-08-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SYR</td>\n",
       "      <td>SYRACUSE/HANCOCK</td>\n",
       "      <td>43.1112</td>\n",
       "      <td>-76.1063</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1942-10-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UCA</td>\n",
       "      <td>UTICA/ONEIDA CO.</td>\n",
       "      <td>43.1451</td>\n",
       "      <td>-75.3839</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>1947-12-31 00:00</td>\n",
       "      <td>2010-12-31 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>VGC</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>42.8434</td>\n",
       "      <td>-75.5612</td>\n",
       "      <td>342.825680</td>\n",
       "      <td>2020-08-06 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>XNT</td>\n",
       "      <td>Springville - Bertrand Chaffee</td>\n",
       "      <td>42.5084</td>\n",
       "      <td>-78.6581</td>\n",
       "      <td>423.819000</td>\n",
       "      <td>2016-08-24 00:00</td>\n",
       "      <td>2017-07-05 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stid                    station_name      lat      lon        elev  \\\n",
       "0   6B9                     Skaneateles  42.9140 -76.4408  304.324520   \n",
       "1   ALB              ALBANY COUNTY ARPT  42.7576 -73.8036   89.000000   \n",
       "2   ART             WATERTOWN INTL ARPT  43.9888 -76.0262   99.000000   \n",
       "3   BGM               BINGHAMTON/BROOME  42.2086 -75.9797  497.000000   \n",
       "4   BUF               BUFFALO INTL ARPT  42.9408 -78.7358  215.000000   \n",
       "5   DKK                 DUNKIRK AIRPORT  42.4933 -79.2720  203.000000   \n",
       "6   DSV             DANSVILLE MUNICIPAL  42.5709 -77.7130  209.000000   \n",
       "7   ELM                Elmira / Corning  42.1571 -76.8994  287.125370   \n",
       "8   ELZ            Wellsville Municipal  42.1078 -77.9842  639.000000   \n",
       "9   FOK               WESTHAMPTON BEACH  40.8436 -72.6318   20.000000   \n",
       "10  FRG             FARMINGDALE/REPUBLC  40.7288 -73.4134   25.000000   \n",
       "11  FZY                   Oswego County  43.3504 -76.3831  141.826460   \n",
       "12  GFL               GLEN FALLS/WARREN  43.3412 -73.6103  100.000000   \n",
       "13  GTB               FORT DRUM/WHEELER  44.0556 -75.7195  207.000000   \n",
       "14  GVQ                         Batavia  43.0317 -78.1675  275.450840   \n",
       "15  HPN                    WHITE PLAINS  41.0669 -73.7075  134.000000   \n",
       "16  HTO                    EAST HAMPTON  40.9600 -72.2500   17.000000   \n",
       "17  HWV      BROOKHAVEN AIRPORT/SHIRLEY  40.8217 -72.8689   25.000000   \n",
       "18  IAG              NIAGARA FALLS INTL  43.1073 -78.9462  180.000000   \n",
       "19  ISP                 ISLIP/MACARTHUR  40.7939 -73.1017   30.000000   \n",
       "20  ITH                          Ithaca  42.4910 -76.4584  335.000000   \n",
       "21  IUA                     Canandaigua  42.9089 -77.3252  244.597890   \n",
       "22  JFK             NEW YORK/JF KENNEDY  40.6386 -73.7622    7.000000   \n",
       "23  JHW                JAMESTOWN (AWOS)  42.1534 -79.2580  525.000000   \n",
       "24  JPX                    East Hampton  40.9594 -72.2517   11.000000   \n",
       "25  JRB         Manhattan - Wall Street  40.7012 -74.0090    0.000000   \n",
       "26  LGA              New York/LaGuardia  40.7794 -73.8803    9.000000   \n",
       "27  MGJ           ORANGE COUNTY AIRPORT  41.5092 -74.2650  111.000000   \n",
       "28  MSS                MASSENA/RICHARDS  44.9358 -74.8456   65.000000   \n",
       "29  MSV                MONTICELLO(AWOS)  41.7016 -74.7950  428.000000   \n",
       "30  MTP                 MONTAUK AIRPORT  41.0731 -71.9233    6.000000   \n",
       "31  N03                        Cortland  42.5929 -76.2174  356.635200   \n",
       "32  NY0                       Johnstown  42.9982 -74.3296  263.009900   \n",
       "33  NYC                   NEW YORK CITY  40.7790 -73.9692   27.000000   \n",
       "34  OGS                 OGDENSBURG INTL  44.6819 -75.4655   91.000000   \n",
       "35  OIC                         Norwich  42.5666 -75.5241  306.802000   \n",
       "36  OLE                           Olean  42.2412 -78.3714  649.319760   \n",
       "37  PBG                 Plattsburgh AFB  44.6382 -73.4624   46.954082   \n",
       "38  PEO                        Penn Yan  42.6441 -77.0529  267.000000   \n",
       "39  PLB             PLATTSBURGH/CLINTON  44.6875 -73.5245  113.000000   \n",
       "40  POU                    POUGHKEEPSIE  41.6266 -73.8842   51.000000   \n",
       "41  PTD                         Potsdam  44.6757 -74.9469  140.470340   \n",
       "42  RME             Griffiss AFB / Rome  43.2239 -75.3953  143.616610   \n",
       "43  ROC             ROCHESTER/MONROE CO  43.1167 -77.6767  169.000000   \n",
       "44  SCH             SCHENECTADY AIRPORT  42.8500 -73.9300  115.000000   \n",
       "45  SDC                      Williamson  43.2346 -77.1195  127.863280   \n",
       "46  SLK             SARANAC LAKE/ADIRON  44.3853 -74.2062  507.000000   \n",
       "47  SWF                NEWBURGH/STEWART  41.5041 -74.1048  150.000000   \n",
       "48  SYR                SYRACUSE/HANCOCK  43.1112 -76.1063  124.000000   \n",
       "49  UCA                UTICA/ONEIDA CO.  43.1451 -75.3839  226.000000   \n",
       "50  VGC                        Hamilton  42.8434 -75.5612  342.825680   \n",
       "51  XNT  Springville - Bertrand Chaffee  42.5084 -78.6581  423.819000   \n",
       "\n",
       "             begints             endts iem_network  \n",
       "0   2016-07-22 00:00               NaN     NY_ASOS  \n",
       "1   1945-01-01 00:00               NaN     NY_ASOS  \n",
       "2   1949-04-30 00:00               NaN     NY_ASOS  \n",
       "3   1948-01-01 00:00               NaN     NY_ASOS  \n",
       "4   1942-01-31 00:00               NaN     NY_ASOS  \n",
       "5   1948-12-31 00:00               NaN     NY_ASOS  \n",
       "6   1948-12-31 00:00               NaN     NY_ASOS  \n",
       "7   1949-02-01 00:00               NaN     NY_ASOS  \n",
       "8   1978-06-13 00:00               NaN     NY_ASOS  \n",
       "9   1943-07-18 00:00               NaN     NY_ASOS  \n",
       "10  1943-04-12 00:00               NaN     NY_ASOS  \n",
       "11  1997-05-31 00:00               NaN     NY_ASOS  \n",
       "12  1949-01-31 00:00               NaN     NY_ASOS  \n",
       "13  1942-01-01 00:00               NaN     NY_ASOS  \n",
       "14  2009-06-28 00:00               NaN     NY_ASOS  \n",
       "15  1948-12-31 00:00               NaN     NY_ASOS  \n",
       "16  2000-01-07 00:00  2022-03-02 00:00     NY_ASOS  \n",
       "17  1999-09-30 00:00               NaN     NY_ASOS  \n",
       "18  1951-06-12 00:00               NaN     NY_ASOS  \n",
       "19  1972-12-31 00:00               NaN     NY_ASOS  \n",
       "20  1972-12-31 00:00               NaN     NY_ASOS  \n",
       "21  2021-10-14 00:00               NaN     NY_ASOS  \n",
       "22  1948-07-01 00:00               NaN     NY_ASOS  \n",
       "23  1972-12-31 00:00               NaN     NY_ASOS  \n",
       "24  1996-07-01 00:00               NaN     NY_ASOS  \n",
       "25  2016-07-21 00:00               NaN     NY_ASOS  \n",
       "26  1948-07-01 00:00               NaN     NY_ASOS  \n",
       "27  1997-12-31 00:00               NaN     NY_ASOS  \n",
       "28  1949-02-01 00:00               NaN     NY_ASOS  \n",
       "29  1981-02-12 00:00               NaN     NY_ASOS  \n",
       "30  1975-10-01 00:00               NaN     NY_ASOS  \n",
       "31  2013-10-24 00:00               NaN     NY_ASOS  \n",
       "32  2014-08-20 00:00               NaN     NY_ASOS  \n",
       "33  1943-12-01 00:00               NaN     NY_ASOS  \n",
       "34  1977-05-01 00:00               NaN     NY_ASOS  \n",
       "35  2007-12-17 00:00               NaN     NY_ASOS  \n",
       "36  1987-08-13 00:00               NaN     NY_ASOS  \n",
       "37  1956-01-14 00:00               NaN     NY_ASOS  \n",
       "38  1997-12-31 00:00               NaN     NY_ASOS  \n",
       "39  1978-08-22 00:00  2007-05-22 00:00     NY_ASOS  \n",
       "40  1948-12-31 00:00               NaN     NY_ASOS  \n",
       "41  2018-02-03 00:00               NaN     NY_ASOS  \n",
       "42  1942-07-01 00:00               NaN     NY_ASOS  \n",
       "43  1948-01-01 00:00               NaN     NY_ASOS  \n",
       "44  1950-01-01 00:00               NaN     NY_ASOS  \n",
       "45  2017-12-08 00:00               NaN     NY_ASOS  \n",
       "46  1973-01-01 00:00               NaN     NY_ASOS  \n",
       "47  1942-08-01 00:00               NaN     NY_ASOS  \n",
       "48  1942-10-01 00:00               NaN     NY_ASOS  \n",
       "49  1947-12-31 00:00  2010-12-31 00:00     NY_ASOS  \n",
       "50  2020-08-06 00:00               NaN     NY_ASOS  \n",
       "51  2016-08-24 00:00  2017-07-05 00:00     NY_ASOS  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nylocations = './csvs/_nylocations.csv'\n",
    "latlongs = pd.read_csv(nylocations)\n",
    "latlongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>dwpf</th>\n",
       "      <th>relh</th>\n",
       "      <th>drct</th>\n",
       "      <th>sknt</th>\n",
       "      <th>p01i</th>\n",
       "      <th>alti</th>\n",
       "      <th>mslp</th>\n",
       "      <th>vsby</th>\n",
       "      <th>feel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2020-01-01 00:54:00</td>\n",
       "      <td>-0.942380</td>\n",
       "      <td>-0.872567</td>\n",
       "      <td>0.120999</td>\n",
       "      <td>0.575668</td>\n",
       "      <td>0.899204</td>\n",
       "      <td>-0.207339</td>\n",
       "      <td>-1.770322</td>\n",
       "      <td>-1.688849</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-1.070871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2020-01-01 01:54:00</td>\n",
       "      <td>-0.942380</td>\n",
       "      <td>-1.050176</td>\n",
       "      <td>-0.406298</td>\n",
       "      <td>0.575668</td>\n",
       "      <td>1.530761</td>\n",
       "      <td>-0.207339</td>\n",
       "      <td>-1.770322</td>\n",
       "      <td>-1.701429</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-1.125387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2020-01-01 02:54:00</td>\n",
       "      <td>-0.942380</td>\n",
       "      <td>-1.050176</td>\n",
       "      <td>-0.406298</td>\n",
       "      <td>0.670413</td>\n",
       "      <td>0.688685</td>\n",
       "      <td>-0.207339</td>\n",
       "      <td>-1.727055</td>\n",
       "      <td>-1.663691</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-1.049869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2020-01-01 03:54:00</td>\n",
       "      <td>-1.001766</td>\n",
       "      <td>-1.101739</td>\n",
       "      <td>-0.382094</td>\n",
       "      <td>0.670413</td>\n",
       "      <td>1.320242</td>\n",
       "      <td>-0.207339</td>\n",
       "      <td>-1.727055</td>\n",
       "      <td>-1.651112</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-1.171859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2020-01-01 04:54:00</td>\n",
       "      <td>-1.001766</td>\n",
       "      <td>-1.101739</td>\n",
       "      <td>-0.382094</td>\n",
       "      <td>0.575668</td>\n",
       "      <td>1.109723</td>\n",
       "      <td>-0.207339</td>\n",
       "      <td>-1.727055</td>\n",
       "      <td>-1.651112</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-1.153091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53027</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 19:54:00</td>\n",
       "      <td>-0.564467</td>\n",
       "      <td>-0.299635</td>\n",
       "      <td>0.717451</td>\n",
       "      <td>1.144142</td>\n",
       "      <td>0.267646</td>\n",
       "      <td>0.046903</td>\n",
       "      <td>-1.207852</td>\n",
       "      <td>-1.185684</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-0.614192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53028</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 20:54:00</td>\n",
       "      <td>-0.564467</td>\n",
       "      <td>-0.299635</td>\n",
       "      <td>0.717451</td>\n",
       "      <td>1.049396</td>\n",
       "      <td>-0.574430</td>\n",
       "      <td>-0.080218</td>\n",
       "      <td>-1.078051</td>\n",
       "      <td>-1.047313</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-0.502926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53029</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 21:54:00</td>\n",
       "      <td>-0.618454</td>\n",
       "      <td>-0.356928</td>\n",
       "      <td>0.713417</td>\n",
       "      <td>0.575668</td>\n",
       "      <td>-0.363911</td>\n",
       "      <td>-0.207339</td>\n",
       "      <td>-0.948250</td>\n",
       "      <td>-0.896363</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-0.590062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53030</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 22:54:00</td>\n",
       "      <td>-0.618454</td>\n",
       "      <td>-0.356928</td>\n",
       "      <td>0.713417</td>\n",
       "      <td>0.386176</td>\n",
       "      <td>-0.153392</td>\n",
       "      <td>-0.207339</td>\n",
       "      <td>-0.861716</td>\n",
       "      <td>-0.833468</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-0.620001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53031</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 23:54:00</td>\n",
       "      <td>-0.618454</td>\n",
       "      <td>-0.471514</td>\n",
       "      <td>0.334224</td>\n",
       "      <td>0.480922</td>\n",
       "      <td>0.057127</td>\n",
       "      <td>-0.207339</td>\n",
       "      <td>-0.861716</td>\n",
       "      <td>-0.808309</td>\n",
       "      <td>0.490278</td>\n",
       "      <td>-0.646365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53032 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      station                valid      tmpf      dwpf      relh      drct  \\\n",
       "0         ROC  2020-01-01 00:54:00 -0.942380 -0.872567  0.120999  0.575668   \n",
       "1         ROC  2020-01-01 01:54:00 -0.942380 -1.050176 -0.406298  0.575668   \n",
       "2         ROC  2020-01-01 02:54:00 -0.942380 -1.050176 -0.406298  0.670413   \n",
       "3         ROC  2020-01-01 03:54:00 -1.001766 -1.101739 -0.382094  0.670413   \n",
       "4         ROC  2020-01-01 04:54:00 -1.001766 -1.101739 -0.382094  0.575668   \n",
       "...       ...                  ...       ...       ...       ...       ...   \n",
       "53027     ROC  2024-11-28 19:54:00 -0.564467 -0.299635  0.717451  1.144142   \n",
       "53028     ROC  2024-11-28 20:54:00 -0.564467 -0.299635  0.717451  1.049396   \n",
       "53029     ROC  2024-11-28 21:54:00 -0.618454 -0.356928  0.713417  0.575668   \n",
       "53030     ROC  2024-11-28 22:54:00 -0.618454 -0.356928  0.713417  0.386176   \n",
       "53031     ROC  2024-11-28 23:54:00 -0.618454 -0.471514  0.334224  0.480922   \n",
       "\n",
       "           sknt      p01i      alti      mslp      vsby      feel  \n",
       "0      0.899204 -0.207339 -1.770322 -1.688849  0.490278 -1.070871  \n",
       "1      1.530761 -0.207339 -1.770322 -1.701429  0.490278 -1.125387  \n",
       "2      0.688685 -0.207339 -1.727055 -1.663691  0.490278 -1.049869  \n",
       "3      1.320242 -0.207339 -1.727055 -1.651112  0.490278 -1.171859  \n",
       "4      1.109723 -0.207339 -1.727055 -1.651112  0.490278 -1.153091  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "53027  0.267646  0.046903 -1.207852 -1.185684  0.490278 -0.614192  \n",
       "53028 -0.574430 -0.080218 -1.078051 -1.047313  0.490278 -0.502926  \n",
       "53029 -0.363911 -0.207339 -0.948250 -0.896363  0.490278 -0.590062  \n",
       "53030 -0.153392 -0.207339 -0.861716 -0.833468  0.490278 -0.620001  \n",
       "53031  0.057127 -0.207339 -0.861716 -0.808309  0.490278 -0.646365  \n",
       "\n",
       "[53032 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc = './csvs/ROC_processed.csv'\n",
    "roc_p = pd.read_csv(roc)\n",
    "roc_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BGM': {'lat': 42.2086, 'lon': -75.9797}, 'JRB': {'lat': 40.7012, 'lon': -74.009}, 'MSS': {'lat': 44.9358, 'lon': -74.8456}, 'PEO': {'lat': 42.6441, 'lon': -77.0529}, 'RME': {'lat': 43.2239, 'lon': -75.3953}, 'ROC': {'lat': 43.1167, 'lon': -77.6767}}\n",
      "{'JRB': './csvs/JRB_processed.csv', 'ROC': './csvs/ROC_processed.csv', 'BGM': './csvs/BGM_processed.csv', 'MSS': './csvs/MSS_processed.csv', 'PEO': './csvs/PEO_processed.csv', 'RME': './csvs/RME_processed.csv'}\n",
      "latlong is tensor([0.7261, 0.2944])\n",
      "latlong is tensor([0.7395, 0.2842])\n",
      "latlong is tensor([0.7345, 0.2889])\n",
      "latlong is tensor([0.7496, 0.2921])\n",
      "latlong is tensor([0.7369, 0.2860])\n",
      "latlong is tensor([0.7401, 0.2906])\n",
      "n latlongs: [[0.7261177777777778, 0.29441944444444446], [0.7395372222222223, 0.2842313888888889], [0.7344922222222222, 0.2889452777777778], [0.7496433333333333, 0.29209555555555555], [0.7369116666666667, 0.2859641666666667], [0.7401327777777779, 0.2905686111111111]]\n",
      "torch.Size([6, 12])\n",
      "tensor([[-1.0023e-03,  6.0683e-03,  2.5727e-03, -1.8761e-02,  6.0973e-03,\n",
      "         -2.5134e-02,  7.4355e-03,  2.6595e-02, -1.9331e-03,  5.1881e-03,\n",
      "          7.3212e-01,  2.8670e-01],\n",
      "        [ 2.4996e-02, -8.7907e-03,  3.2794e-02, -1.1499e-02, -1.2039e-03,\n",
      "         -3.4671e-03, -5.1337e-04,  7.8411e-03, -1.2158e-02, -1.3858e-02,\n",
      "          7.4209e-01,  2.9553e-01],\n",
      "        [-7.6840e-03, -1.2434e-02, -6.7317e-03,  1.0095e-02,  3.3849e-05,\n",
      "          9.6062e-03,  2.3778e-03, -6.1846e-03, -1.9982e-02, -1.4177e-02,\n",
      "          7.3655e-01,  2.7957e-01],\n",
      "        [-6.1837e-03,  4.5866e-03,  2.0360e-02, -1.8890e-02, -1.4883e-03,\n",
      "         -4.7524e-03,  3.8306e-03,  2.5982e-04,  1.1971e-02, -2.5519e-03,\n",
      "          7.5937e-01,  2.8224e-01],\n",
      "        [-1.4175e-02, -4.7808e-03,  7.4997e-03,  6.6362e-03,  2.3529e-02,\n",
      "         -3.6055e-03, -8.4664e-03,  6.7324e-03,  4.6401e-04, -4.6382e-03,\n",
      "          7.2705e-01,  2.7250e-01],\n",
      "        [ 2.1839e-02, -7.9137e-03,  1.0084e-02, -4.0272e-03, -5.0172e-03,\n",
      "          1.0363e-02,  6.4368e-03, -1.1392e-04,  8.3029e-03,  2.3020e-03,\n",
      "          7.2366e-01,  2.8097e-01]])\n",
      "tensor([2.6964e-04, 5.7003e-05, 1.9221e-04, 1.5636e-04, 1.0786e-04, 1.6618e-04,\n",
      "        3.3690e-05, 1.2935e-04, 1.4673e-04, 6.5017e-05, 1.6541e-04, 5.9473e-05])\n",
      "Distance Matrix:\n",
      "[[0.         0.01684868 0.01000489 0.02364006 0.0137113  0.01453441]\n",
      " [0.01684868 0.         0.00690455 0.01280541 0.0031458  0.00636515]\n",
      " [0.01000489 0.00690455 0.         0.01547515 0.00383937 0.0058695 ]\n",
      " [0.02364006 0.01280541 0.01547515 0.         0.01413115 0.00963235]\n",
      " [0.0137113  0.0031458  0.00383937 0.01413115 0.         0.00561929]\n",
      " [0.01453441 0.00636515 0.0058695  0.00963235 0.00561929 0.        ]]\n",
      "Edge Index:\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5],\n",
      "        [2, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 1, 4, 5, 0, 1, 2, 3, 5, 0, 1, 2, 3, 4]])\n",
      "Data(x=[6, 12], edge_index=[2, 24])\n"
     ]
    }
   ],
   "source": [
    "required_stations = ['JRB', 'ROC', 'BGM', 'MSS', 'PEO', 'RME']\n",
    "\n",
    "### first get the locations of stations\n",
    "# Filter the DataFrame for the required stations\n",
    "stations_df = latlongs[latlongs['stid'].isin(required_stations)]\n",
    "# Create a dictionary from the filtered DataFrame\n",
    "stations_latlong = stations_df.set_index('stid')[['lat', 'lon']].T.to_dict()\n",
    "\n",
    "print(stations_latlong)\n",
    "\n",
    "### now get station data itself\n",
    "processed_data_paths = {station:f'./csvs/{station}_processed.csv' for station in required_stations}\n",
    "print(processed_data_paths)\n",
    "\n",
    "station_features = []\n",
    "normalized_latlongs = []\n",
    "for stid in required_stations:\n",
    "   station_data = pd.read_csv(processed_data_paths[stid])\n",
    "   features = torch.tensor(station_data.drop(columns=['station', 'valid']).values, dtype=torch.float)\n",
    "   mean_features = features.mean(dim=0)  # Mean of all the features to get \"average weather\"\n",
    "\n",
    "   # Append latitude and longitude to the feature vector\n",
    "   lat, long = stations_latlong[stid]['lat'], stations_latlong[stid]['lon']\n",
    "   nlat = (lat+90)/ (180)\n",
    "   nlong = (long+180)/ (360) \n",
    "   lat_long = torch.tensor([nlat,nlong], dtype=torch.float)\n",
    "   print(f\"latlong is {lat_long}\")\n",
    "   combined_features = torch.cat((mean_features, lat_long))  # Concatenate features with lat/lon\n",
    "\n",
    "   station_features.append(combined_features)\n",
    "   normalized_latlongs.append([nlat, nlong])\n",
    "\n",
    "print(f'n latlongs: {normalized_latlongs}')\n",
    "\n",
    "node_features = torch.stack(station_features)\n",
    "node_features += torch.randn_like(node_features) * 0.01  # noise\n",
    "print(node_features.shape)\n",
    "print(node_features)\n",
    "print(torch.var(node_features, dim=0))\n",
    "\n",
    "def calculate_distances(latlongs):\n",
    "   num_stations = len(latlongs)\n",
    "   distances = np.zeros((num_stations, num_stations))\n",
    "   for i, coord1 in enumerate(latlongs):\n",
    "      for j, coord2 in enumerate(latlongs):\n",
    "         # Calculate Euclidean distance for normalized coordinates\n",
    "         distances[i, j] = np.linalg.norm(np.array(coord1) - np.array(coord2))\n",
    "   return distances\n",
    "\n",
    "distances = calculate_distances(normalized_latlongs)\n",
    "print(\"Distance Matrix:\")\n",
    "print(distances)\n",
    "\n",
    "distance_threshold = 0.015  # Adjust this threshold based on your scale and data\n",
    "edges = []\n",
    "\n",
    "for i in range(len(distances)):\n",
    "   for j in range(len(distances)):\n",
    "      if i != j and distances[i, j] <= distance_threshold:\n",
    "         edges.append((i, j))\n",
    "\n",
    "# Define edges \n",
    "edge_index = torch.tensor(edges, dtype=torch.long).T  # Transpose to match edge_index format\n",
    "print(\"Edge Index:\")\n",
    "print(edge_index)\n",
    "\n",
    "# Create the graph data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleGNN(torch.nn.Module):\n",
    "   def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "      super(SimpleGNN, self).__init__()\n",
    "      self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "      self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "   def forward(self, data):\n",
    "      x, edge_index = data.x, data.edge_index\n",
    "      x = self.conv1(x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      x = self.conv2(x, edge_index)\n",
    "      return x  # Embeddings for each node\n",
    "\n",
    "# Initialize the GNN\n",
    "input_dim = node_features.shape[1]  # Latitude and longitude plus features\n",
    "hidden_dim = 14\n",
    "output_dim = 12  # Embedding size\n",
    "gnn = SimpleGNN(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial embeddings for each station:\n",
      "tensor([[-0.0010, -0.0639,  0.0999, -0.0328,  0.0132,  0.1274, -0.0606, -0.2108,\n",
      "          0.1127, -0.2048, -0.1221, -0.1166],\n",
      "        [-0.0020, -0.0724,  0.1121, -0.0349,  0.0146,  0.1426, -0.0685, -0.2363,\n",
      "          0.1258, -0.2284, -0.1363, -0.1286],\n",
      "        [-0.0014, -0.0717,  0.1119, -0.0359,  0.0151,  0.1422, -0.0677, -0.2358,\n",
      "          0.1255, -0.2284, -0.1365, -0.1298],\n",
      "        [-0.0018, -0.0651,  0.1005, -0.0310,  0.0131,  0.1278, -0.0614, -0.2120,\n",
      "          0.1128, -0.2046, -0.1221, -0.1148],\n",
      "        [-0.0017, -0.0788,  0.1224, -0.0388,  0.0162,  0.1555, -0.0743, -0.2580,\n",
      "          0.1375, -0.2497, -0.1489, -0.1411],\n",
      "        [-0.0017, -0.0788,  0.1224, -0.0388,  0.0162,  0.1555, -0.0743, -0.2580,\n",
      "          0.1375, -0.2497, -0.1489, -0.1411]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embeddings = gnn(data)\n",
    "\n",
    "# Print embeddings\n",
    "print(\"initial embeddings for each station:\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity matrix is tensor([[0.6201, 0.6285, 0.6187, 0.6374, 0.6106, 0.6101],\n",
      "        [0.6285, 0.6404, 0.6291, 0.6475, 0.6200, 0.6209],\n",
      "        [0.6187, 0.6291, 0.6218, 0.6376, 0.6118, 0.6113],\n",
      "        [0.6374, 0.6475, 0.6376, 0.6573, 0.6291, 0.6290],\n",
      "        [0.6106, 0.6200, 0.6118, 0.6291, 0.6039, 0.6023],\n",
      "        [0.6101, 0.6209, 0.6113, 0.6290, 0.6023, 0.6035]])\n",
      "Epoch 1, Loss: 0.1791\n",
      "Epoch 2, Loss: 0.1702\n",
      "Epoch 3, Loss: 0.1612\n",
      "Epoch 4, Loss: 0.1521\n",
      "Epoch 5, Loss: 0.1430\n",
      "Epoch 6, Loss: 0.1339\n",
      "Epoch 7, Loss: 0.1248\n",
      "Epoch 8, Loss: 0.1158\n",
      "Epoch 9, Loss: 0.1068\n",
      "Epoch 10, Loss: 0.0980\n",
      "Epoch 11, Loss: 0.0894\n",
      "Epoch 12, Loss: 0.0809\n",
      "Epoch 13, Loss: 0.0728\n",
      "Epoch 14, Loss: 0.0649\n",
      "Epoch 15, Loss: 0.0574\n",
      "Epoch 16, Loss: 0.0502\n",
      "Epoch 17, Loss: 0.0435\n",
      "Epoch 18, Loss: 0.0373\n",
      "Epoch 19, Loss: 0.0316\n",
      "Epoch 20, Loss: 0.0264\n",
      "Epoch 21, Loss: 0.0218\n",
      "Epoch 22, Loss: 0.0178\n",
      "Epoch 23, Loss: 0.0144\n",
      "Epoch 24, Loss: 0.0117\n",
      "Epoch 25, Loss: 0.0095\n",
      "Epoch 26, Loss: 0.0080\n",
      "Epoch 27, Loss: 0.0069\n",
      "Epoch 28, Loss: 0.0063\n",
      "Epoch 29, Loss: 0.0061\n",
      "Epoch 30, Loss: 0.0062\n",
      "Epoch 31, Loss: 0.0065\n",
      "Epoch 32, Loss: 0.0070\n",
      "Epoch 33, Loss: 0.0076\n",
      "Epoch 34, Loss: 0.0082\n",
      "Epoch 35, Loss: 0.0087\n",
      "Epoch 36, Loss: 0.0092\n",
      "Epoch 37, Loss: 0.0095\n",
      "Epoch 38, Loss: 0.0097\n",
      "Epoch 39, Loss: 0.0098\n",
      "Epoch 40, Loss: 0.0097\n",
      "Epoch 41, Loss: 0.0095\n",
      "Epoch 42, Loss: 0.0092\n",
      "Epoch 43, Loss: 0.0088\n",
      "Epoch 44, Loss: 0.0084\n",
      "Epoch 45, Loss: 0.0080\n",
      "Epoch 46, Loss: 0.0076\n",
      "Epoch 47, Loss: 0.0073\n",
      "Epoch 48, Loss: 0.0069\n",
      "Epoch 49, Loss: 0.0067\n",
      "Epoch 50, Loss: 0.0064\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "# Compute similarity matrix from node features\n",
    "similarity_matrix = torch.mm(node_features, node_features.T)\n",
    "print(f'similarity matrix is {similarity_matrix}')\n",
    "\n",
    "# Define unsupervised loss function with regularization\n",
    "def contrastive_loss(embeddings, similarity_matrix, distance_matrix, lambda_diversity=0.1, lambda_distance=0.1):\n",
    "   pred_similarity = torch.mm(embeddings, embeddings.T)\n",
    "   mse_loss = torch.nn.functional.mse_loss(pred_similarity, similarity_matrix)\n",
    "\n",
    "   diversity_loss = -torch.var(embeddings, dim=0).mean()  # Penalize low variance\n",
    "\n",
    "   pred_distance_matrix = torch.cdist(embeddings, embeddings, p=2)\n",
    "   distance_loss = torch.nn.functional.mse_loss(pred_distance_matrix, distance_matrix)\n",
    "\n",
    "   total_loss = mse_loss + lambda_diversity * diversity_loss + lambda_distance * distance_loss\n",
    "   return total_loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "optimizer = torch.optim.Adam(gnn.parameters(), lr=0.001)\n",
    "\n",
    "gnn.train()\n",
    "for epoch in range(epochs):\n",
    "   optimizer.zero_grad()  # Reset gradients\n",
    "   embeddings = gnn(data)  # Forward pass\n",
    "\n",
    "   # Compute contrastive loss\n",
    "   loss = contrastive_loss(embeddings, similarity_matrix, torch.Tensor(distances))\n",
    "   \n",
    "   # Backward pass and optimization\n",
    "   loss.backward()\n",
    "   optimizer.step()\n",
    "\n",
    "   # Print loss and gradient information\n",
    "   print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "   # for name, param in gnn.named_parameters():\n",
    "   #    if param.grad is not None:\n",
    "   #       print(f\"Gradient for {name}: {param.grad.abs().mean().item():.6f}\")\n",
    "   #    else:\n",
    "   #       print(f\"No gradient for {name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned embeddings:\n",
      "tensor([[-0.1468, -0.1550,  0.2000, -0.0575,  0.1047,  0.2262, -0.1686, -0.3321,\n",
      "          0.1651, -0.3363, -0.2194, -0.2050],\n",
      "        [-0.1621, -0.1709,  0.2205, -0.0594,  0.1135,  0.2501, -0.1864, -0.3685,\n",
      "          0.1810, -0.3727, -0.2421, -0.2246],\n",
      "        [-0.1610, -0.1701,  0.2202, -0.0604,  0.1138,  0.2493, -0.1853, -0.3679,\n",
      "          0.1810, -0.3723, -0.2420, -0.2255],\n",
      "        [-0.1482, -0.1560,  0.2003, -0.0558,  0.1047,  0.2270, -0.1701, -0.3329,\n",
      "          0.1649, -0.3366, -0.2198, -0.2038],\n",
      "        [-0.1748, -0.1845,  0.2390, -0.0627,  0.1220,  0.2706, -0.2010, -0.4010,\n",
      "          0.1959, -0.4057, -0.2622, -0.2437],\n",
      "        [-0.1748, -0.1845,  0.2390, -0.0627,  0.1220,  0.2706, -0.2010, -0.4010,\n",
      "          0.1959, -0.4057, -0.2622, -0.2437]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learned_embeddings = gnn(data)  # Get final embeddings\n",
    "print(\"Learned embeddings:\")\n",
    "print(learned_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JRB\n",
      "(47642, 12)\n",
      "ROC\n",
      "(53032, 12)\n",
      "BGM\n",
      "(63611, 12)\n",
      "MSS\n",
      "(58320, 12)\n",
      "PEO\n",
      "(59152, 12)\n",
      "RME\n",
      "(59111, 12)\n"
     ]
    }
   ],
   "source": [
    "for r in required_stations:\n",
    "   df = pd.read_csv(f'./csvs/{r}_processed.csv')\n",
    "   print(r)\n",
    "   print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each station, add on the static embedding that we just learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47642, 12)\n",
      "(47642, 24)\n",
      "(53032, 12)\n",
      "(53032, 24)\n",
      "(63611, 12)\n",
      "(63611, 24)\n",
      "(58320, 12)\n",
      "(58320, 24)\n",
      "(59152, 12)\n",
      "(59152, 24)\n",
      "(59111, 12)\n",
      "(59111, 24)\n",
      "(340868, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>dwpf</th>\n",
       "      <th>relh</th>\n",
       "      <th>drct</th>\n",
       "      <th>sknt</th>\n",
       "      <th>p01i</th>\n",
       "      <th>alti</th>\n",
       "      <th>mslp</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>embedding_10</th>\n",
       "      <th>embedding_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2020-01-01 00:56:00</td>\n",
       "      <td>-1.052667</td>\n",
       "      <td>-0.583350</td>\n",
       "      <td>0.657509</td>\n",
       "      <td>1.118256</td>\n",
       "      <td>0.310933</td>\n",
       "      <td>-0.119089</td>\n",
       "      <td>-1.621235</td>\n",
       "      <td>-1.705313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199959</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>0.22618</td>\n",
       "      <td>-0.168643</td>\n",
       "      <td>-0.332092</td>\n",
       "      <td>0.165093</td>\n",
       "      <td>-0.336337</td>\n",
       "      <td>-0.219415</td>\n",
       "      <td>-0.205045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2020-01-01 01:56:00</td>\n",
       "      <td>-1.118122</td>\n",
       "      <td>-0.704325</td>\n",
       "      <td>0.523108</td>\n",
       "      <td>1.118256</td>\n",
       "      <td>0.836536</td>\n",
       "      <td>-0.119089</td>\n",
       "      <td>-1.534873</td>\n",
       "      <td>-1.639390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199959</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>0.22618</td>\n",
       "      <td>-0.168643</td>\n",
       "      <td>-0.332092</td>\n",
       "      <td>0.165093</td>\n",
       "      <td>-0.336337</td>\n",
       "      <td>-0.219415</td>\n",
       "      <td>-0.205045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2020-01-01 02:56:00</td>\n",
       "      <td>-1.183577</td>\n",
       "      <td>-0.764813</td>\n",
       "      <td>0.518875</td>\n",
       "      <td>1.118256</td>\n",
       "      <td>1.099338</td>\n",
       "      <td>-0.119089</td>\n",
       "      <td>-1.578054</td>\n",
       "      <td>-1.678944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199959</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>0.22618</td>\n",
       "      <td>-0.168643</td>\n",
       "      <td>-0.332092</td>\n",
       "      <td>0.165093</td>\n",
       "      <td>-0.336337</td>\n",
       "      <td>-0.219415</td>\n",
       "      <td>-0.205045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2020-01-01 03:56:00</td>\n",
       "      <td>-1.183577</td>\n",
       "      <td>-0.825300</td>\n",
       "      <td>0.346377</td>\n",
       "      <td>1.118256</td>\n",
       "      <td>0.573735</td>\n",
       "      <td>-0.119089</td>\n",
       "      <td>-1.578054</td>\n",
       "      <td>-1.652575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199959</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>0.22618</td>\n",
       "      <td>-0.168643</td>\n",
       "      <td>-0.332092</td>\n",
       "      <td>0.165093</td>\n",
       "      <td>-0.336337</td>\n",
       "      <td>-0.219415</td>\n",
       "      <td>-0.205045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2020-01-01 04:56:00</td>\n",
       "      <td>-1.249032</td>\n",
       "      <td>-1.012812</td>\n",
       "      <td>0.042123</td>\n",
       "      <td>1.118256</td>\n",
       "      <td>1.624941</td>\n",
       "      <td>-0.119089</td>\n",
       "      <td>-1.534873</td>\n",
       "      <td>-1.613021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199959</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>0.104688</td>\n",
       "      <td>0.22618</td>\n",
       "      <td>-0.168643</td>\n",
       "      <td>-0.332092</td>\n",
       "      <td>0.165093</td>\n",
       "      <td>-0.336337</td>\n",
       "      <td>-0.219415</td>\n",
       "      <td>-0.205045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  station                valid      tmpf      dwpf      relh      drct  \\\n",
       "0     JRB  2020-01-01 00:56:00 -1.052667 -0.583350  0.657509  1.118256   \n",
       "1     JRB  2020-01-01 01:56:00 -1.118122 -0.704325  0.523108  1.118256   \n",
       "2     JRB  2020-01-01 02:56:00 -1.183577 -0.764813  0.518875  1.118256   \n",
       "3     JRB  2020-01-01 03:56:00 -1.183577 -0.825300  0.346377  1.118256   \n",
       "4     JRB  2020-01-01 04:56:00 -1.249032 -1.012812  0.042123  1.118256   \n",
       "\n",
       "       sknt      p01i      alti      mslp  ...  embedding_2  embedding_3  \\\n",
       "0  0.310933 -0.119089 -1.621235 -1.705313  ...     0.199959    -0.057479   \n",
       "1  0.836536 -0.119089 -1.534873 -1.639390  ...     0.199959    -0.057479   \n",
       "2  1.099338 -0.119089 -1.578054 -1.678944  ...     0.199959    -0.057479   \n",
       "3  0.573735 -0.119089 -1.578054 -1.652575  ...     0.199959    -0.057479   \n",
       "4  1.624941 -0.119089 -1.534873 -1.613021  ...     0.199959    -0.057479   \n",
       "\n",
       "   embedding_4  embedding_5  embedding_6  embedding_7  embedding_8  \\\n",
       "0     0.104688      0.22618    -0.168643    -0.332092     0.165093   \n",
       "1     0.104688      0.22618    -0.168643    -0.332092     0.165093   \n",
       "2     0.104688      0.22618    -0.168643    -0.332092     0.165093   \n",
       "3     0.104688      0.22618    -0.168643    -0.332092     0.165093   \n",
       "4     0.104688      0.22618    -0.168643    -0.332092     0.165093   \n",
       "\n",
       "   embedding_9  embedding_10  embedding_11  \n",
       "0    -0.336337     -0.219415     -0.205045  \n",
       "1    -0.336337     -0.219415     -0.205045  \n",
       "2    -0.336337     -0.219415     -0.205045  \n",
       "3    -0.336337     -0.219415     -0.205045  \n",
       "4    -0.336337     -0.219415     -0.205045  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "for idx, (station, path) in enumerate(processed_data_paths.items()):\n",
    "   # Load the CSV into a DataFrame\n",
    "   df = pd.read_csv(path)\n",
    "   print(df.shape)\n",
    "   \n",
    "   # Get the corresponding embedding for this station\n",
    "   embedding = learned_embeddings[idx].detach().numpy()\n",
    "   \n",
    "   # Add the embedding as new columns to the DataFrame\n",
    "   for i, value in enumerate(embedding):\n",
    "      df[f'embedding_{i}'] = value\n",
    "\n",
    "   print(df.shape)\n",
    "   \n",
    "   # Append to the list of all data\n",
    "   all_data.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Display the result\n",
    "print(combined_df.shape)\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59087, 24, 22)\n",
      "(59087, 22)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Prepare sequences for LSTM input\n",
    "# Assuming we are predicting 'tmpf' (temperature) as the target variable\n",
    "# and using previous 24 time steps/8 hours (n_steps_in) to predict the next time step/20 minutes from now (n_steps_out)\n",
    "# create sliding window sequences X: (114640, 24, 10), y: (114640, 10)\n",
    "feature_cols = list(set(df.columns) - set(['station', 'valid']))\n",
    "\n",
    "n_steps_in = 24  # Number of past time steps\n",
    "n_steps_out = 1  # Number of future time steps to predict\n",
    "\n",
    "# We'll create sequences for each station separately\n",
    "def create_sequences(data, n_steps_in, n_steps_out):\n",
    "   X, y = [], []\n",
    "   for i in range(len(data) - n_steps_in - n_steps_out + 1):\n",
    "      X.append(data[i:(i + n_steps_in), :])\n",
    "      y.append(data[(i + n_steps_in):(i + n_steps_in + n_steps_out), :])\n",
    "   return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare data for each station\n",
    "X_list = []\n",
    "y_list = []\n",
    "stations = df['station'].unique()\n",
    "\n",
    "for station in stations:\n",
    "   station_data = df[df['station'] == station]\n",
    "   station_data = station_data.reset_index(drop=True)\n",
    "   data_values = station_data[feature_cols].values\n",
    "   # target_col_index = feature_cols.index('tmpf')  # Index of target variable in features\n",
    "\n",
    "   X_station, y_station = create_sequences(data_values, n_steps_in, n_steps_out)\n",
    "   X_list.append(X_station)\n",
    "   y_list.append(y_station)\n",
    "\n",
    "\n",
    "# Concatenate data from all stations\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "\n",
    "if n_steps_out == 1:\n",
    "   y = y.squeeze(1)  # Shape becomes (num_samples, num_features) = (114640, 10) for JRB\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 41360, Validation size: 5908, Test size: 11819\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Split the data into training, validation, and testing sets\n",
    "# Since it's time-series data, we'll use the first 70% for training, next 10% for validation, and the rest for testing\n",
    "train_size = int(len(X) * 0.7)\n",
    "val_size = int(len(X) * 0.1)\n",
    "test_size = len(X) - train_size - val_size\n",
    "\n",
    "X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n",
    "\n",
    "# Now the data is ready for training the LSTM model\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class WeatherDataset(Dataset):\n",
    "   def __init__(self, X, y):\n",
    "      self.X = X\n",
    "      self.y = y\n",
    "   def __len__(self):\n",
    "      return len(self.X)\n",
    "   def __getitem__(self, idx):\n",
    "      return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create Dataset objects for training, validation, and testing\n",
    "train_dataset = WeatherDataset(X_train, y_train)\n",
    "val_dataset = WeatherDataset(X_val, y_val)\n",
    "test_dataset = WeatherDataset(X_test, y_test)\n",
    "\n",
    "# Example to check shapes\n",
    "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type    | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | model      | SegRNN  | 2.4 M  | train\n",
      "1 | criterion  | MSELoss | 0      | train\n",
      "2 | criterion2 | L1Loss  | 0      | train\n",
      "-----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.642     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.516322135925293\n",
      "Validation Loss: 0.3555587828159332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/p/parshvam/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n",
      "/global/homes/p/parshvam/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cedba463fc4f42921c5750f95b9395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.02118496783077717\n",
      "Validation Loss: 0.049162041395902634\n",
      "Validation Loss: 0.03336353600025177\n",
      "Validation Loss: 0.028187468647956848\n",
      "Validation Loss: 0.059936702251434326\n",
      "Validation Loss: 0.02290920913219452\n",
      "Validation Loss: 0.019369736313819885\n",
      "Validation Loss: 0.015387424267828465\n",
      "Validation Loss: 0.027209624648094177\n",
      "Validation Loss: 0.04243132472038269\n",
      "Validation Loss: 0.0678059458732605\n",
      "Validation Loss: 0.09146402031183243\n",
      "Validation Loss: 0.08311328291893005\n",
      "Validation Loss: 0.030933771282434464\n",
      "Validation Loss: 0.10519303381443024\n",
      "Validation Loss: 0.026902299374341965\n",
      "Validation Loss: 0.06371869146823883\n",
      "Validation Loss: 0.040127743035554886\n",
      "Validation Loss: 0.040692444890737534\n",
      "Validation Loss: 0.033423569053411484\n",
      "Validation Loss: 0.0878966823220253\n",
      "Validation Loss: 0.06840655952692032\n",
      "Validation Loss: 0.04355301707983017\n",
      "Validation Loss: 0.030622180551290512\n",
      "Validation Loss: 0.08760601282119751\n",
      "Validation Loss: 0.048805296421051025\n",
      "Validation Loss: 0.02814120054244995\n",
      "Validation Loss: 0.05624604970216751\n",
      "Validation Loss: 0.1206677183508873\n",
      "Validation Loss: 0.045043785125017166\n",
      "Validation Loss: 0.03284452483057976\n",
      "Validation Loss: 0.14940154552459717\n",
      "Validation Loss: 0.05327349528670311\n",
      "Validation Loss: 0.01801992394030094\n",
      "Validation Loss: 0.04426078870892525\n",
      "Validation Loss: 0.05137166753411293\n",
      "Validation Loss: 0.08459344506263733\n",
      "Validation Loss: 0.040216077119112015\n",
      "Validation Loss: 0.038371097296476364\n",
      "Validation Loss: 0.03883419185876846\n",
      "Validation Loss: 0.08006512373685837\n",
      "Validation Loss: 0.036174070090055466\n",
      "Validation Loss: 0.34199947118759155\n",
      "Validation Loss: 0.05956190451979637\n",
      "Validation Loss: 0.02579534612596035\n",
      "Validation Loss: 0.03646085783839226\n",
      "Validation Loss: 0.05658416450023651\n",
      "Validation Loss: 0.06398024410009384\n",
      "Validation Loss: 0.15005162358283997\n",
      "Validation Loss: 0.05700112506747246\n",
      "Validation Loss: 0.05148479342460632\n",
      "Validation Loss: 0.04955131560564041\n",
      "Validation Loss: 0.14530685544013977\n",
      "Validation Loss: 0.233424112200737\n",
      "Validation Loss: 0.25067567825317383\n",
      "Validation Loss: 0.07965116202831268\n",
      "Validation Loss: 0.05619358271360397\n",
      "Validation Loss: 0.08455032855272293\n",
      "Validation Loss: 0.09892906248569489\n",
      "Validation Loss: 0.04071193188428879\n",
      "Validation Loss: 0.03302944079041481\n",
      "Validation Loss: 0.05905098840594292\n",
      "Validation Loss: 0.17755353450775146\n",
      "Validation Loss: 0.0665898323059082\n",
      "Validation Loss: 0.025636350736021996\n",
      "Validation Loss: 0.33804264664649963\n",
      "Validation Loss: 0.02993299812078476\n",
      "Validation Loss: 0.035720933228731155\n",
      "Validation Loss: 0.025837650522589684\n",
      "Validation Loss: 0.05178539454936981\n",
      "Validation Loss: 0.16716060042381287\n",
      "Validation Loss: 0.1271194964647293\n",
      "Validation Loss: 0.11532773077487946\n",
      "Validation Loss: 0.03749072551727295\n",
      "Validation Loss: 0.07383930683135986\n",
      "Validation Loss: 0.11310683935880661\n",
      "Validation Loss: 0.03437470272183418\n",
      "Validation Loss: 0.0197319146245718\n",
      "Validation Loss: 0.10422477126121521\n",
      "Validation Loss: 0.03808699920773506\n",
      "Validation Loss: 0.04190211743116379\n",
      "Validation Loss: 0.07219989597797394\n",
      "Validation Loss: 0.07135409116744995\n",
      "Validation Loss: 0.041281748563051224\n",
      "Validation Loss: 0.0690498948097229\n",
      "Validation Loss: 0.061085045337677\n",
      "Validation Loss: 0.04884645342826843\n",
      "Validation Loss: 0.041891977190971375\n",
      "Validation Loss: 0.06601020693778992\n",
      "Validation Loss: 0.029990673065185547\n",
      "Validation Loss: 0.02878464385867119\n",
      "Validation Loss: 0.040839336812496185\n",
      "Validation Loss: 0.11758910864591599\n",
      "Validation Loss: 0.04549184814095497\n",
      "Validation Loss: 0.19400350749492645\n",
      "Validation Loss: 0.06141633540391922\n",
      "Validation Loss: 0.11429762095212936\n",
      "Validation Loss: 0.053592801094055176\n",
      "Validation Loss: 0.08865468204021454\n",
      "Validation Loss: 0.058476682752370834\n",
      "Validation Loss: 0.02580835111439228\n",
      "Validation Loss: 0.026256632059812546\n",
      "Validation Loss: 0.06959550082683563\n",
      "Validation Loss: 0.0622287355363369\n",
      "Validation Loss: 0.07735494524240494\n",
      "Validation Loss: 0.039658889174461365\n",
      "Validation Loss: 0.027731947600841522\n",
      "Validation Loss: 0.04301023483276367\n",
      "Validation Loss: 0.023280534893274307\n",
      "Validation Loss: 0.02860327623784542\n",
      "Validation Loss: 0.03206780552864075\n",
      "Validation Loss: 0.015069033950567245\n",
      "Validation Loss: 0.030949804931879044\n",
      "Validation Loss: 0.038162413984537125\n",
      "Validation Loss: 0.0911746472120285\n",
      "Validation Loss: 0.061991725116968155\n",
      "Validation Loss: 0.0401768796145916\n",
      "Validation Loss: 0.034494731575250626\n",
      "Validation Loss: 0.0409211590886116\n",
      "Validation Loss: 0.02137187123298645\n",
      "Validation Loss: 0.16440750658512115\n",
      "Validation Loss: 0.3640996515750885\n",
      "Validation Loss: 0.09000978618860245\n",
      "Validation Loss: 0.023284414783120155\n",
      "Validation Loss: 0.00957228522747755\n",
      "Validation Loss: 0.030762700363993645\n",
      "Validation Loss: 0.04703589156270027\n",
      "Validation Loss: 0.043493568897247314\n",
      "Validation Loss: 0.08015237003564835\n",
      "Validation Loss: 0.04330640658736229\n",
      "Validation Loss: 0.060051798820495605\n",
      "Validation Loss: 0.021856723353266716\n",
      "Validation Loss: 0.021785276010632515\n",
      "Validation Loss: 0.038549575954675674\n",
      "Validation Loss: 0.056921299546957016\n",
      "Validation Loss: 0.04901379346847534\n",
      "Validation Loss: 0.03224857896566391\n",
      "Validation Loss: 0.01362523902207613\n",
      "Validation Loss: 0.02165832929313183\n",
      "Validation Loss: 0.045587312430143356\n",
      "Validation Loss: 0.0439349003136158\n",
      "Validation Loss: 0.0915437638759613\n",
      "Validation Loss: 0.05279655009508133\n",
      "Validation Loss: 0.03274863213300705\n",
      "Validation Loss: 0.050188809633255005\n",
      "Validation Loss: 0.037996482104063034\n",
      "Validation Loss: 0.037782277911901474\n",
      "Validation Loss: 0.03289661556482315\n",
      "Validation Loss: 0.02455790527164936\n",
      "Validation Loss: 0.06450576335191727\n",
      "Validation Loss: 0.05205349624156952\n",
      "Validation Loss: 0.048353858292102814\n",
      "Validation Loss: 0.053131818771362305\n",
      "Validation Loss: 0.08711306750774384\n",
      "Validation Loss: 0.0593947097659111\n",
      "Validation Loss: 0.09102651476860046\n",
      "Validation Loss: 0.061824731528759\n",
      "Validation Loss: 0.024700555950403214\n",
      "Validation Loss: 0.07377691566944122\n",
      "Validation Loss: 0.03863568231463432\n",
      "Validation Loss: 0.04555055499076843\n",
      "Validation Loss: 0.06428787857294083\n",
      "Validation Loss: 0.044423967599868774\n",
      "Validation Loss: 0.069308340549469\n",
      "Validation Loss: 0.07868323475122452\n",
      "Validation Loss: 0.04191454127430916\n",
      "Validation Loss: 0.042246367782354355\n",
      "Validation Loss: 0.032384712249040604\n",
      "Validation Loss: 0.02959785982966423\n",
      "Validation Loss: 0.057319995015859604\n",
      "Validation Loss: 0.015390580520033836\n",
      "Validation Loss: 0.06835370510816574\n",
      "Validation Loss: 0.06095321848988533\n",
      "Validation Loss: 0.05652507022023201\n",
      "Validation Loss: 0.056458137929439545\n",
      "Validation Loss: 0.02743319608271122\n",
      "Validation Loss: 0.021986927837133408\n",
      "Validation Loss: 0.05704937502741814\n",
      "Validation Loss: 0.034192074090242386\n",
      "Validation Loss: 0.056280408054590225\n",
      "Validation Loss: 0.019380325451493263\n",
      "Validation Loss: 0.042958635836839676\n",
      "Validation Loss: 0.06627685576677322\n",
      "Validation Loss: 0.07978826761245728\n",
      "Validation Loss: 0.0443824902176857\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.031127803027629852\n",
      "Validation Loss: 0.044886644929647446\n",
      "Validation Loss: 0.04052957892417908\n",
      "Validation Loss: 0.03270455077290535\n",
      "Validation Loss: 0.06343920528888702\n",
      "Validation Loss: 0.0238400436937809\n",
      "Validation Loss: 0.02250540815293789\n",
      "Validation Loss: 0.01728300377726555\n",
      "Validation Loss: 0.030804185196757317\n",
      "Validation Loss: 0.04657330363988876\n",
      "Validation Loss: 0.0715823769569397\n",
      "Validation Loss: 0.10105163604021072\n",
      "Validation Loss: 0.11575150489807129\n",
      "Validation Loss: 0.040590133517980576\n",
      "Validation Loss: 0.10888384282588959\n",
      "Validation Loss: 0.0362447127699852\n",
      "Validation Loss: 0.05929860472679138\n",
      "Validation Loss: 0.042324285954236984\n",
      "Validation Loss: 0.04969281703233719\n",
      "Validation Loss: 0.04442274942994118\n",
      "Validation Loss: 0.09953875094652176\n",
      "Validation Loss: 0.07252638787031174\n",
      "Validation Loss: 0.04939959570765495\n",
      "Validation Loss: 0.032573774456977844\n",
      "Validation Loss: 0.07782281935214996\n",
      "Validation Loss: 0.05157085135579109\n",
      "Validation Loss: 0.03625218942761421\n",
      "Validation Loss: 0.05578848719596863\n",
      "Validation Loss: 0.11950837075710297\n",
      "Validation Loss: 0.04801368713378906\n",
      "Validation Loss: 0.03673381358385086\n",
      "Validation Loss: 0.14451247453689575\n",
      "Validation Loss: 0.058787278831005096\n",
      "Validation Loss: 0.027631327509880066\n",
      "Validation Loss: 0.05029625818133354\n",
      "Validation Loss: 0.05371647700667381\n",
      "Validation Loss: 0.10079425573348999\n",
      "Validation Loss: 0.045154184103012085\n",
      "Validation Loss: 0.038125086575746536\n",
      "Validation Loss: 0.04434724897146225\n",
      "Validation Loss: 0.08435164391994476\n",
      "Validation Loss: 0.03268744423985481\n",
      "Validation Loss: 0.3770003318786621\n",
      "Validation Loss: 0.06546329706907272\n",
      "Validation Loss: 0.028329502791166306\n",
      "Validation Loss: 0.05186377093195915\n",
      "Validation Loss: 0.058606620877981186\n",
      "Validation Loss: 0.07166746258735657\n",
      "Validation Loss: 0.12201832234859467\n",
      "Validation Loss: 0.06232617795467377\n",
      "Validation Loss: 0.05330518260598183\n",
      "Validation Loss: 0.04620792716741562\n",
      "Validation Loss: 0.12709882855415344\n",
      "Validation Loss: 0.3102206289768219\n",
      "Validation Loss: 0.24078071117401123\n",
      "Validation Loss: 0.08336109668016434\n",
      "Validation Loss: 0.06666327267885208\n",
      "Validation Loss: 0.1080085039138794\n",
      "Validation Loss: 0.1246010884642601\n",
      "Validation Loss: 0.06459558755159378\n",
      "Validation Loss: 0.04170723259449005\n",
      "Validation Loss: 0.057145971804857254\n",
      "Validation Loss: 0.1691618263721466\n",
      "Validation Loss: 0.07976450026035309\n",
      "Validation Loss: 0.029618261381983757\n",
      "Validation Loss: 0.29968249797821045\n",
      "Validation Loss: 0.034332770854234695\n",
      "Validation Loss: 0.04107539728283882\n",
      "Validation Loss: 0.03519688919186592\n",
      "Validation Loss: 0.055181656032800674\n",
      "Validation Loss: 0.14869406819343567\n",
      "Validation Loss: 0.13311311602592468\n",
      "Validation Loss: 0.11365880817174911\n",
      "Validation Loss: 0.04104764014482498\n",
      "Validation Loss: 0.07153534889221191\n",
      "Validation Loss: 0.10582820326089859\n",
      "Validation Loss: 0.034380730241537094\n",
      "Validation Loss: 0.028406864032149315\n",
      "Validation Loss: 0.12409629672765732\n",
      "Validation Loss: 0.04436204209923744\n",
      "Validation Loss: 0.04522228613495827\n",
      "Validation Loss: 0.0707821175456047\n",
      "Validation Loss: 0.07925323396921158\n",
      "Validation Loss: 0.05633661523461342\n",
      "Validation Loss: 0.05358476564288139\n",
      "Validation Loss: 0.0713806301355362\n",
      "Validation Loss: 0.05083836242556572\n",
      "Validation Loss: 0.03993316367268562\n",
      "Validation Loss: 0.07241115719079971\n",
      "Validation Loss: 0.033378586173057556\n",
      "Validation Loss: 0.03296026960015297\n",
      "Validation Loss: 0.042891424149274826\n",
      "Validation Loss: 0.1294836401939392\n",
      "Validation Loss: 0.04769746586680412\n",
      "Validation Loss: 0.22775596380233765\n",
      "Validation Loss: 0.06481748819351196\n",
      "Validation Loss: 0.1124536469578743\n",
      "Validation Loss: 0.05540679395198822\n",
      "Validation Loss: 0.0898490846157074\n",
      "Validation Loss: 0.056523919105529785\n",
      "Validation Loss: 0.029315510764718056\n",
      "Validation Loss: 0.03211752325296402\n",
      "Validation Loss: 0.07202070951461792\n",
      "Validation Loss: 0.0591074638068676\n",
      "Validation Loss: 0.0773826390504837\n",
      "Validation Loss: 0.043263185769319534\n",
      "Validation Loss: 0.029561981558799744\n",
      "Validation Loss: 0.046381112188100815\n",
      "Validation Loss: 0.026729129254817963\n",
      "Validation Loss: 0.03232419490814209\n",
      "Validation Loss: 0.03345537930727005\n",
      "Validation Loss: 0.02094193734228611\n",
      "Validation Loss: 0.02974804863333702\n",
      "Validation Loss: 0.04019593074917793\n",
      "Validation Loss: 0.08531367778778076\n",
      "Validation Loss: 0.05819186568260193\n",
      "Validation Loss: 0.04259909689426422\n",
      "Validation Loss: 0.03752213716506958\n",
      "Validation Loss: 0.04250175505876541\n",
      "Validation Loss: 0.021370843052864075\n",
      "Validation Loss: 0.20932501554489136\n",
      "Validation Loss: 0.31636786460876465\n",
      "Validation Loss: 0.08829706907272339\n",
      "Validation Loss: 0.03495332598686218\n",
      "Validation Loss: 0.01185822207480669\n",
      "Validation Loss: 0.03119957447052002\n",
      "Validation Loss: 0.04871984198689461\n",
      "Validation Loss: 0.04349271208047867\n",
      "Validation Loss: 0.08038999885320663\n",
      "Validation Loss: 0.04607190564274788\n",
      "Validation Loss: 0.06066281348466873\n",
      "Validation Loss: 0.02482067607343197\n",
      "Validation Loss: 0.023683294653892517\n",
      "Validation Loss: 0.043143969029188156\n",
      "Validation Loss: 0.06588206440210342\n",
      "Validation Loss: 0.06392095237970352\n",
      "Validation Loss: 0.03655635565519333\n",
      "Validation Loss: 0.011377806775271893\n",
      "Validation Loss: 0.01989128254354\n",
      "Validation Loss: 0.04254332184791565\n",
      "Validation Loss: 0.049051642417907715\n",
      "Validation Loss: 0.10243649035692215\n",
      "Validation Loss: 0.05830232799053192\n",
      "Validation Loss: 0.035989850759506226\n",
      "Validation Loss: 0.051480624824762344\n",
      "Validation Loss: 0.040694184601306915\n",
      "Validation Loss: 0.03901577740907669\n",
      "Validation Loss: 0.03336603194475174\n",
      "Validation Loss: 0.02823585830628872\n",
      "Validation Loss: 0.06630904972553253\n",
      "Validation Loss: 0.05528004840016365\n",
      "Validation Loss: 0.049226611852645874\n",
      "Validation Loss: 0.053445130586624146\n",
      "Validation Loss: 0.08233670890331268\n",
      "Validation Loss: 0.0697430744767189\n",
      "Validation Loss: 0.08791794627904892\n",
      "Validation Loss: 0.07092739641666412\n",
      "Validation Loss: 0.028702549636363983\n",
      "Validation Loss: 0.07037831842899323\n",
      "Validation Loss: 0.03770165517926216\n",
      "Validation Loss: 0.051414329558610916\n",
      "Validation Loss: 0.06293699890375137\n",
      "Validation Loss: 0.041632767766714096\n",
      "Validation Loss: 0.0635959655046463\n",
      "Validation Loss: 0.07780924439430237\n",
      "Validation Loss: 0.04279956594109535\n",
      "Validation Loss: 0.05015562102198601\n",
      "Validation Loss: 0.03846510127186775\n",
      "Validation Loss: 0.030763821676373482\n",
      "Validation Loss: 0.054203685373067856\n",
      "Validation Loss: 0.01766093261539936\n",
      "Validation Loss: 0.0713014006614685\n",
      "Validation Loss: 0.05994945392012596\n",
      "Validation Loss: 0.054843805730342865\n",
      "Validation Loss: 0.05646161735057831\n",
      "Validation Loss: 0.029973117634654045\n",
      "Validation Loss: 0.02379765175282955\n",
      "Validation Loss: 0.06039867177605629\n",
      "Validation Loss: 0.0358838327229023\n",
      "Validation Loss: 0.052590902894735336\n",
      "Validation Loss: 0.020802857354283333\n",
      "Validation Loss: 0.03690742328763008\n",
      "Validation Loss: 0.06369286775588989\n",
      "Validation Loss: 0.07739660888910294\n",
      "Validation Loss: 0.04602402448654175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.021894650533795357\n",
      "Validation Loss: 0.043388962745666504\n",
      "Validation Loss: 0.03544503450393677\n",
      "Validation Loss: 0.03370160609483719\n",
      "Validation Loss: 0.0566285103559494\n",
      "Validation Loss: 0.017940545454621315\n",
      "Validation Loss: 0.020882513374090195\n",
      "Validation Loss: 0.01490133535116911\n",
      "Validation Loss: 0.028458600863814354\n",
      "Validation Loss: 0.03430856019258499\n",
      "Validation Loss: 0.06559798866510391\n",
      "Validation Loss: 0.08381196111440659\n",
      "Validation Loss: 0.1002800464630127\n",
      "Validation Loss: 0.027035024017095566\n",
      "Validation Loss: 0.10000082105398178\n",
      "Validation Loss: 0.03344879671931267\n",
      "Validation Loss: 0.062412068247795105\n",
      "Validation Loss: 0.034084778279066086\n",
      "Validation Loss: 0.04329141974449158\n",
      "Validation Loss: 0.03896281123161316\n",
      "Validation Loss: 0.0826081782579422\n",
      "Validation Loss: 0.05864090472459793\n",
      "Validation Loss: 0.042500752955675125\n",
      "Validation Loss: 0.025688795372843742\n",
      "Validation Loss: 0.07642205059528351\n",
      "Validation Loss: 0.04721487686038017\n",
      "Validation Loss: 0.029061302542686462\n",
      "Validation Loss: 0.051393624395132065\n",
      "Validation Loss: 0.11487486213445663\n",
      "Validation Loss: 0.03711258992552757\n",
      "Validation Loss: 0.03079715184867382\n",
      "Validation Loss: 0.13716605305671692\n",
      "Validation Loss: 0.05039837211370468\n",
      "Validation Loss: 0.01765439845621586\n",
      "Validation Loss: 0.039931368082761765\n",
      "Validation Loss: 0.04958338662981987\n",
      "Validation Loss: 0.0982307568192482\n",
      "Validation Loss: 0.03730202838778496\n",
      "Validation Loss: 0.03192665055394173\n",
      "Validation Loss: 0.04508620500564575\n",
      "Validation Loss: 0.07419091463088989\n",
      "Validation Loss: 0.036986589431762695\n",
      "Validation Loss: 0.32671764492988586\n",
      "Validation Loss: 0.05422844737768173\n",
      "Validation Loss: 0.02641967311501503\n",
      "Validation Loss: 0.04646516963839531\n",
      "Validation Loss: 0.05224550515413284\n",
      "Validation Loss: 0.057981450110673904\n",
      "Validation Loss: 0.12770932912826538\n",
      "Validation Loss: 0.058313999325037\n",
      "Validation Loss: 0.05292993411421776\n",
      "Validation Loss: 0.04627665877342224\n",
      "Validation Loss: 0.1242135763168335\n",
      "Validation Loss: 0.26175928115844727\n",
      "Validation Loss: 0.2226840853691101\n",
      "Validation Loss: 0.07522933185100555\n",
      "Validation Loss: 0.05803125351667404\n",
      "Validation Loss: 0.09979884326457977\n",
      "Validation Loss: 0.11857062578201294\n",
      "Validation Loss: 0.05769296735525131\n",
      "Validation Loss: 0.034087713807821274\n",
      "Validation Loss: 0.05151095986366272\n",
      "Validation Loss: 0.14726103842258453\n",
      "Validation Loss: 0.06688647717237473\n",
      "Validation Loss: 0.024966131895780563\n",
      "Validation Loss: 0.29722118377685547\n",
      "Validation Loss: 0.027503762394189835\n",
      "Validation Loss: 0.030240103602409363\n",
      "Validation Loss: 0.03245318681001663\n",
      "Validation Loss: 0.04859202727675438\n",
      "Validation Loss: 0.133372500538826\n",
      "Validation Loss: 0.13240130245685577\n",
      "Validation Loss: 0.11518311500549316\n",
      "Validation Loss: 0.032705504447221756\n",
      "Validation Loss: 0.0641479566693306\n",
      "Validation Loss: 0.1119319349527359\n",
      "Validation Loss: 0.02967427670955658\n",
      "Validation Loss: 0.027141354978084564\n",
      "Validation Loss: 0.11184138059616089\n",
      "Validation Loss: 0.03853365778923035\n",
      "Validation Loss: 0.05153192952275276\n",
      "Validation Loss: 0.07350406050682068\n",
      "Validation Loss: 0.06357935816049576\n",
      "Validation Loss: 0.048676177859306335\n",
      "Validation Loss: 0.04461018368601799\n",
      "Validation Loss: 0.06478140503168106\n",
      "Validation Loss: 0.04641382023692131\n",
      "Validation Loss: 0.03738386929035187\n",
      "Validation Loss: 0.06465977430343628\n",
      "Validation Loss: 0.02864990010857582\n",
      "Validation Loss: 0.02356167882680893\n",
      "Validation Loss: 0.032747745513916016\n",
      "Validation Loss: 0.12931516766548157\n",
      "Validation Loss: 0.04287516698241234\n",
      "Validation Loss: 0.2108495533466339\n",
      "Validation Loss: 0.0654965192079544\n",
      "Validation Loss: 0.10145105421543121\n",
      "Validation Loss: 0.05746981501579285\n",
      "Validation Loss: 0.07777136564254761\n",
      "Validation Loss: 0.050697680562734604\n",
      "Validation Loss: 0.027049819007515907\n",
      "Validation Loss: 0.032588303089141846\n",
      "Validation Loss: 0.0755116194486618\n",
      "Validation Loss: 0.053316064178943634\n",
      "Validation Loss: 0.0738459974527359\n",
      "Validation Loss: 0.03662142902612686\n",
      "Validation Loss: 0.026958908885717392\n",
      "Validation Loss: 0.03917841613292694\n",
      "Validation Loss: 0.023774197325110435\n",
      "Validation Loss: 0.02637016400694847\n",
      "Validation Loss: 0.03148321807384491\n",
      "Validation Loss: 0.018535666167736053\n",
      "Validation Loss: 0.02969367988407612\n",
      "Validation Loss: 0.0367654450237751\n",
      "Validation Loss: 0.07934346050024033\n",
      "Validation Loss: 0.05406934767961502\n",
      "Validation Loss: 0.02731676958501339\n",
      "Validation Loss: 0.036172084510326385\n",
      "Validation Loss: 0.03319893777370453\n",
      "Validation Loss: 0.0230756513774395\n",
      "Validation Loss: 0.19133271276950836\n",
      "Validation Loss: 0.3282313346862793\n",
      "Validation Loss: 0.08233556151390076\n",
      "Validation Loss: 0.0332387275993824\n",
      "Validation Loss: 0.011601483449339867\n",
      "Validation Loss: 0.028024975210428238\n",
      "Validation Loss: 0.0447457879781723\n",
      "Validation Loss: 0.041386764496564865\n",
      "Validation Loss: 0.0783555880188942\n",
      "Validation Loss: 0.04087061807513237\n",
      "Validation Loss: 0.06181858107447624\n",
      "Validation Loss: 0.019368670880794525\n",
      "Validation Loss: 0.022439610213041306\n",
      "Validation Loss: 0.03919706121087074\n",
      "Validation Loss: 0.0638151466846466\n",
      "Validation Loss: 0.05165531486272812\n",
      "Validation Loss: 0.03240031749010086\n",
      "Validation Loss: 0.011256236582994461\n",
      "Validation Loss: 0.019605325534939766\n",
      "Validation Loss: 0.039909619837999344\n",
      "Validation Loss: 0.04124293848872185\n",
      "Validation Loss: 0.09328417479991913\n",
      "Validation Loss: 0.04811491817235947\n",
      "Validation Loss: 0.03305777534842491\n",
      "Validation Loss: 0.04942498728632927\n",
      "Validation Loss: 0.03647870570421219\n",
      "Validation Loss: 0.03654355928301811\n",
      "Validation Loss: 0.029282456263899803\n",
      "Validation Loss: 0.028091875836253166\n",
      "Validation Loss: 0.06628262996673584\n",
      "Validation Loss: 0.05186500400304794\n",
      "Validation Loss: 0.05096001178026199\n",
      "Validation Loss: 0.05315970629453659\n",
      "Validation Loss: 0.06979534029960632\n",
      "Validation Loss: 0.06654711812734604\n",
      "Validation Loss: 0.08744537830352783\n",
      "Validation Loss: 0.06130285933613777\n",
      "Validation Loss: 0.02382180467247963\n",
      "Validation Loss: 0.06903481483459473\n",
      "Validation Loss: 0.03274455666542053\n",
      "Validation Loss: 0.040845390409231186\n",
      "Validation Loss: 0.062365930527448654\n",
      "Validation Loss: 0.041912246495485306\n",
      "Validation Loss: 0.06672261655330658\n",
      "Validation Loss: 0.0673564225435257\n",
      "Validation Loss: 0.042069580405950546\n",
      "Validation Loss: 0.04191848635673523\n",
      "Validation Loss: 0.03559768199920654\n",
      "Validation Loss: 0.0300898514688015\n",
      "Validation Loss: 0.048581283539533615\n",
      "Validation Loss: 0.015155945904552937\n",
      "Validation Loss: 0.07057645916938782\n",
      "Validation Loss: 0.06032876670360565\n",
      "Validation Loss: 0.0546761229634285\n",
      "Validation Loss: 0.04898051917552948\n",
      "Validation Loss: 0.03294101729989052\n",
      "Validation Loss: 0.021545425057411194\n",
      "Validation Loss: 0.05414024367928505\n",
      "Validation Loss: 0.034644849598407745\n",
      "Validation Loss: 0.04805191233754158\n",
      "Validation Loss: 0.016913671046495438\n",
      "Validation Loss: 0.036826975643634796\n",
      "Validation Loss: 0.06154968589544296\n",
      "Validation Loss: 0.07929880172014236\n",
      "Validation Loss: 0.039038438349962234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.01804862916469574\n",
      "Validation Loss: 0.046025462448596954\n",
      "Validation Loss: 0.03636140376329422\n",
      "Validation Loss: 0.025744853541254997\n",
      "Validation Loss: 0.058799874037504196\n",
      "Validation Loss: 0.020060067996382713\n",
      "Validation Loss: 0.020537665113806725\n",
      "Validation Loss: 0.01594615913927555\n",
      "Validation Loss: 0.02952362224459648\n",
      "Validation Loss: 0.03425747901201248\n",
      "Validation Loss: 0.06244624778628349\n",
      "Validation Loss: 0.0833880677819252\n",
      "Validation Loss: 0.09671323001384735\n",
      "Validation Loss: 0.02878391370177269\n",
      "Validation Loss: 0.09183213114738464\n",
      "Validation Loss: 0.032710250467061996\n",
      "Validation Loss: 0.07029068470001221\n",
      "Validation Loss: 0.04273078963160515\n",
      "Validation Loss: 0.04701032489538193\n",
      "Validation Loss: 0.03806116059422493\n",
      "Validation Loss: 0.08073365688323975\n",
      "Validation Loss: 0.06024584174156189\n",
      "Validation Loss: 0.04003274068236351\n",
      "Validation Loss: 0.0277983658015728\n",
      "Validation Loss: 0.08370191603899002\n",
      "Validation Loss: 0.04062407836318016\n",
      "Validation Loss: 0.02721412107348442\n",
      "Validation Loss: 0.050289373844861984\n",
      "Validation Loss: 0.12244506925344467\n",
      "Validation Loss: 0.03877975791692734\n",
      "Validation Loss: 0.029335137456655502\n",
      "Validation Loss: 0.17322690784931183\n",
      "Validation Loss: 0.048608023673295975\n",
      "Validation Loss: 0.01702001504600048\n",
      "Validation Loss: 0.04005732387304306\n",
      "Validation Loss: 0.05094165354967117\n",
      "Validation Loss: 0.0911933183670044\n",
      "Validation Loss: 0.04031077027320862\n",
      "Validation Loss: 0.03380855917930603\n",
      "Validation Loss: 0.03692122921347618\n",
      "Validation Loss: 0.07365763187408447\n",
      "Validation Loss: 0.03291063383221626\n",
      "Validation Loss: 0.44105643033981323\n",
      "Validation Loss: 0.054187070578336716\n",
      "Validation Loss: 0.02572840079665184\n",
      "Validation Loss: 0.04153710603713989\n",
      "Validation Loss: 0.05313500761985779\n",
      "Validation Loss: 0.06347383558750153\n",
      "Validation Loss: 0.15770329535007477\n",
      "Validation Loss: 0.05091369152069092\n",
      "Validation Loss: 0.049638792872428894\n",
      "Validation Loss: 0.043433040380477905\n",
      "Validation Loss: 0.12583531439304352\n",
      "Validation Loss: 0.38665637373924255\n",
      "Validation Loss: 0.2170887291431427\n",
      "Validation Loss: 0.06851755827665329\n",
      "Validation Loss: 0.054761167615652084\n",
      "Validation Loss: 0.1022743210196495\n",
      "Validation Loss: 0.10838072001934052\n",
      "Validation Loss: 0.04383813589811325\n",
      "Validation Loss: 0.030956268310546875\n",
      "Validation Loss: 0.051783520728349686\n",
      "Validation Loss: 0.14587046205997467\n",
      "Validation Loss: 0.062112484127283096\n",
      "Validation Loss: 0.023766903206706047\n",
      "Validation Loss: 0.3363916575908661\n",
      "Validation Loss: 0.024944409728050232\n",
      "Validation Loss: 0.029421184211969376\n",
      "Validation Loss: 0.026372574269771576\n",
      "Validation Loss: 0.052169810980558395\n",
      "Validation Loss: 0.1754627227783203\n",
      "Validation Loss: 0.14804911613464355\n",
      "Validation Loss: 0.13077273964881897\n",
      "Validation Loss: 0.030800461769104004\n",
      "Validation Loss: 0.06374707072973251\n",
      "Validation Loss: 0.10881587117910385\n",
      "Validation Loss: 0.02921679988503456\n",
      "Validation Loss: 0.024453336372971535\n",
      "Validation Loss: 0.10537465661764145\n",
      "Validation Loss: 0.03763134032487869\n",
      "Validation Loss: 0.04161567613482475\n",
      "Validation Loss: 0.07291225343942642\n",
      "Validation Loss: 0.06428025662899017\n",
      "Validation Loss: 0.042378369718790054\n",
      "Validation Loss: 0.0596100389957428\n",
      "Validation Loss: 0.05593569204211235\n",
      "Validation Loss: 0.04588576406240463\n",
      "Validation Loss: 0.03438464552164078\n",
      "Validation Loss: 0.05630871653556824\n",
      "Validation Loss: 0.024053648114204407\n",
      "Validation Loss: 0.023168614134192467\n",
      "Validation Loss: 0.03277621045708656\n",
      "Validation Loss: 0.12540540099143982\n",
      "Validation Loss: 0.04115411639213562\n",
      "Validation Loss: 0.2321367710828781\n",
      "Validation Loss: 0.05742743983864784\n",
      "Validation Loss: 0.10375043004751205\n",
      "Validation Loss: 0.05412167310714722\n",
      "Validation Loss: 0.07674834877252579\n",
      "Validation Loss: 0.05106378719210625\n",
      "Validation Loss: 0.025115374475717545\n",
      "Validation Loss: 0.02762662060558796\n",
      "Validation Loss: 0.07623422145843506\n",
      "Validation Loss: 0.054503291845321655\n",
      "Validation Loss: 0.07072338461875916\n",
      "Validation Loss: 0.03730536624789238\n",
      "Validation Loss: 0.023761961609125137\n",
      "Validation Loss: 0.04174128547310829\n",
      "Validation Loss: 0.02244998700916767\n",
      "Validation Loss: 0.025354592129588127\n",
      "Validation Loss: 0.03292112424969673\n",
      "Validation Loss: 0.015513705089688301\n",
      "Validation Loss: 0.03128074109554291\n",
      "Validation Loss: 0.036088645458221436\n",
      "Validation Loss: 0.08877700567245483\n",
      "Validation Loss: 0.052764516323804855\n",
      "Validation Loss: 0.03938671201467514\n",
      "Validation Loss: 0.028384339064359665\n",
      "Validation Loss: 0.03246315196156502\n",
      "Validation Loss: 0.022653738036751747\n",
      "Validation Loss: 0.21978959441184998\n",
      "Validation Loss: 0.3739396035671234\n",
      "Validation Loss: 0.08549878746271133\n",
      "Validation Loss: 0.028753941878676414\n",
      "Validation Loss: 0.009618150070309639\n",
      "Validation Loss: 0.029104411602020264\n",
      "Validation Loss: 0.04289534315466881\n",
      "Validation Loss: 0.036158204078674316\n",
      "Validation Loss: 0.07615635544061661\n",
      "Validation Loss: 0.03630079701542854\n",
      "Validation Loss: 0.0601949617266655\n",
      "Validation Loss: 0.01764044351875782\n",
      "Validation Loss: 0.022106492891907692\n",
      "Validation Loss: 0.03637516498565674\n",
      "Validation Loss: 0.055389851331710815\n",
      "Validation Loss: 0.04815682768821716\n",
      "Validation Loss: 0.03383442759513855\n",
      "Validation Loss: 0.012933125719428062\n",
      "Validation Loss: 0.02014603279531002\n",
      "Validation Loss: 0.040423665195703506\n",
      "Validation Loss: 0.0420248806476593\n",
      "Validation Loss: 0.0883435383439064\n",
      "Validation Loss: 0.05036390572786331\n",
      "Validation Loss: 0.036225464195013046\n",
      "Validation Loss: 0.04959951713681221\n",
      "Validation Loss: 0.0352371521294117\n",
      "Validation Loss: 0.03577066585421562\n",
      "Validation Loss: 0.029064174741506577\n",
      "Validation Loss: 0.027864620089530945\n",
      "Validation Loss: 0.06152631714940071\n",
      "Validation Loss: 0.05053475871682167\n",
      "Validation Loss: 0.05216367915272713\n",
      "Validation Loss: 0.0497579425573349\n",
      "Validation Loss: 0.07552596926689148\n",
      "Validation Loss: 0.06578642874956131\n",
      "Validation Loss: 0.09065290540456772\n",
      "Validation Loss: 0.06128959357738495\n",
      "Validation Loss: 0.022638998925685883\n",
      "Validation Loss: 0.0728965625166893\n",
      "Validation Loss: 0.03469320386648178\n",
      "Validation Loss: 0.03932306915521622\n",
      "Validation Loss: 0.06332159042358398\n",
      "Validation Loss: 0.04385429248213768\n",
      "Validation Loss: 0.0633787140250206\n",
      "Validation Loss: 0.06844815611839294\n",
      "Validation Loss: 0.04239332303404808\n",
      "Validation Loss: 0.04459505155682564\n",
      "Validation Loss: 0.03625601530075073\n",
      "Validation Loss: 0.027780191972851753\n",
      "Validation Loss: 0.05098254606127739\n",
      "Validation Loss: 0.01720023714005947\n",
      "Validation Loss: 0.06622627377510071\n",
      "Validation Loss: 0.0604381263256073\n",
      "Validation Loss: 0.05577516555786133\n",
      "Validation Loss: 0.048911724239587784\n",
      "Validation Loss: 0.02810562215745449\n",
      "Validation Loss: 0.023753318935632706\n",
      "Validation Loss: 0.05647074431180954\n",
      "Validation Loss: 0.03415802866220474\n",
      "Validation Loss: 0.04535100236535072\n",
      "Validation Loss: 0.017964806407690048\n",
      "Validation Loss: 0.038619931787252426\n",
      "Validation Loss: 0.06425466388463974\n",
      "Validation Loss: 0.07976536452770233\n",
      "Validation Loss: 0.03924425691366196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.018322257325053215\n",
      "Validation Loss: 0.04162782430648804\n",
      "Validation Loss: 0.031317658722400665\n",
      "Validation Loss: 0.031012866646051407\n",
      "Validation Loss: 0.055236779153347015\n",
      "Validation Loss: 0.01750394143164158\n",
      "Validation Loss: 0.020173106342554092\n",
      "Validation Loss: 0.01577604003250599\n",
      "Validation Loss: 0.028544645756483078\n",
      "Validation Loss: 0.031616371124982834\n",
      "Validation Loss: 0.059890005737543106\n",
      "Validation Loss: 0.08164022117853165\n",
      "Validation Loss: 0.07734458148479462\n",
      "Validation Loss: 0.026711102575063705\n",
      "Validation Loss: 0.09472515434026718\n",
      "Validation Loss: 0.026841603219509125\n",
      "Validation Loss: 0.055669840425252914\n",
      "Validation Loss: 0.03190189599990845\n",
      "Validation Loss: 0.03747944161295891\n",
      "Validation Loss: 0.034260571002960205\n",
      "Validation Loss: 0.08067076653242111\n",
      "Validation Loss: 0.0559365339577198\n",
      "Validation Loss: 0.04254445806145668\n",
      "Validation Loss: 0.02584470808506012\n",
      "Validation Loss: 0.07872568815946579\n",
      "Validation Loss: 0.04502083733677864\n",
      "Validation Loss: 0.03140450268983841\n",
      "Validation Loss: 0.04844388738274574\n",
      "Validation Loss: 0.10800182074308395\n",
      "Validation Loss: 0.035677120089530945\n",
      "Validation Loss: 0.02964467741549015\n",
      "Validation Loss: 0.20423869788646698\n",
      "Validation Loss: 0.051778923720121384\n",
      "Validation Loss: 0.016411978751420975\n",
      "Validation Loss: 0.03758362680673599\n",
      "Validation Loss: 0.043701961636543274\n",
      "Validation Loss: 0.07653702795505524\n",
      "Validation Loss: 0.035923972725868225\n",
      "Validation Loss: 0.029264559969305992\n",
      "Validation Loss: 0.040634024888277054\n",
      "Validation Loss: 0.07399601489305496\n",
      "Validation Loss: 0.03323858603835106\n",
      "Validation Loss: 0.33488985896110535\n",
      "Validation Loss: 0.05545557290315628\n",
      "Validation Loss: 0.027171125635504723\n",
      "Validation Loss: 0.039942339062690735\n",
      "Validation Loss: 0.05247945338487625\n",
      "Validation Loss: 0.05775974318385124\n",
      "Validation Loss: 0.1328417807817459\n",
      "Validation Loss: 0.05836625024676323\n",
      "Validation Loss: 0.050689905881881714\n",
      "Validation Loss: 0.04310992360115051\n",
      "Validation Loss: 0.13607749342918396\n",
      "Validation Loss: 0.19584010541439056\n",
      "Validation Loss: 0.2448175698518753\n",
      "Validation Loss: 0.07175744324922562\n",
      "Validation Loss: 0.05081341788172722\n",
      "Validation Loss: 0.08840928226709366\n",
      "Validation Loss: 0.09103855490684509\n",
      "Validation Loss: 0.040825724601745605\n",
      "Validation Loss: 0.030568670481443405\n",
      "Validation Loss: 0.051017094403505325\n",
      "Validation Loss: 0.16107887029647827\n",
      "Validation Loss: 0.060418229550123215\n",
      "Validation Loss: 0.024555128067731857\n",
      "Validation Loss: 0.3132461607456207\n",
      "Validation Loss: 0.026235580444335938\n",
      "Validation Loss: 0.028548821806907654\n",
      "Validation Loss: 0.028177836909890175\n",
      "Validation Loss: 0.04826899245381355\n",
      "Validation Loss: 0.1308578997850418\n",
      "Validation Loss: 0.1210637092590332\n",
      "Validation Loss: 0.10572683066129684\n",
      "Validation Loss: 0.03314902260899544\n",
      "Validation Loss: 0.06486628204584122\n",
      "Validation Loss: 0.10649257898330688\n",
      "Validation Loss: 0.030727574601769447\n",
      "Validation Loss: 0.02374783158302307\n",
      "Validation Loss: 0.09886397421360016\n",
      "Validation Loss: 0.03689279779791832\n",
      "Validation Loss: 0.04614641144871712\n",
      "Validation Loss: 0.07042694091796875\n",
      "Validation Loss: 0.06383536010980606\n",
      "Validation Loss: 0.043636586517095566\n",
      "Validation Loss: 0.05305374786257744\n",
      "Validation Loss: 0.05765644088387489\n",
      "Validation Loss: 0.04401976242661476\n",
      "Validation Loss: 0.034333810210227966\n",
      "Validation Loss: 0.06284043937921524\n",
      "Validation Loss: 0.025521865114569664\n",
      "Validation Loss: 0.024318311363458633\n",
      "Validation Loss: 0.0315900593996048\n",
      "Validation Loss: 0.11734060943126678\n",
      "Validation Loss: 0.04205099865794182\n",
      "Validation Loss: 0.17736786603927612\n",
      "Validation Loss: 0.06347205489873886\n",
      "Validation Loss: 0.1018666997551918\n",
      "Validation Loss: 0.05595631152391434\n",
      "Validation Loss: 0.07489804178476334\n",
      "Validation Loss: 0.04890620335936546\n",
      "Validation Loss: 0.026608966290950775\n",
      "Validation Loss: 0.034197576344013214\n",
      "Validation Loss: 0.07451474666595459\n",
      "Validation Loss: 0.05051414296030998\n",
      "Validation Loss: 0.07166053354740143\n",
      "Validation Loss: 0.04225371405482292\n",
      "Validation Loss: 0.02387935295701027\n",
      "Validation Loss: 0.03822416812181473\n",
      "Validation Loss: 0.022567518055438995\n",
      "Validation Loss: 0.02430698089301586\n",
      "Validation Loss: 0.03218408301472664\n",
      "Validation Loss: 0.0167312640696764\n",
      "Validation Loss: 0.031388647854328156\n",
      "Validation Loss: 0.03633485734462738\n",
      "Validation Loss: 0.08204398304224014\n",
      "Validation Loss: 0.05338898301124573\n",
      "Validation Loss: 0.02946321666240692\n",
      "Validation Loss: 0.03260229900479317\n",
      "Validation Loss: 0.0326673798263073\n",
      "Validation Loss: 0.02328808233141899\n",
      "Validation Loss: 0.14563997089862823\n",
      "Validation Loss: 0.35738900303840637\n",
      "Validation Loss: 0.08361200243234634\n",
      "Validation Loss: 0.025204086676239967\n",
      "Validation Loss: 0.011290740221738815\n",
      "Validation Loss: 0.02786150947213173\n",
      "Validation Loss: 0.04254870116710663\n",
      "Validation Loss: 0.03950398787856102\n",
      "Validation Loss: 0.08093403279781342\n",
      "Validation Loss: 0.04176366329193115\n",
      "Validation Loss: 0.062382619827985764\n",
      "Validation Loss: 0.01953750103712082\n",
      "Validation Loss: 0.023801235482096672\n",
      "Validation Loss: 0.03955664113163948\n",
      "Validation Loss: 0.05493748188018799\n",
      "Validation Loss: 0.041325151920318604\n",
      "Validation Loss: 0.03210574388504028\n",
      "Validation Loss: 0.012062758207321167\n",
      "Validation Loss: 0.0174093097448349\n",
      "Validation Loss: 0.039353903383016586\n",
      "Validation Loss: 0.04082268103957176\n",
      "Validation Loss: 0.09154043346643448\n",
      "Validation Loss: 0.047958262264728546\n",
      "Validation Loss: 0.03444606065750122\n",
      "Validation Loss: 0.05059795081615448\n",
      "Validation Loss: 0.039005231112241745\n",
      "Validation Loss: 0.03545813634991646\n",
      "Validation Loss: 0.029937783256173134\n",
      "Validation Loss: 0.02842709794640541\n",
      "Validation Loss: 0.063554547727108\n",
      "Validation Loss: 0.0496767982840538\n",
      "Validation Loss: 0.04643803462386131\n",
      "Validation Loss: 0.0525330975651741\n",
      "Validation Loss: 0.06686718016862869\n",
      "Validation Loss: 0.06499798595905304\n",
      "Validation Loss: 0.08649632334709167\n",
      "Validation Loss: 0.05991482734680176\n",
      "Validation Loss: 0.021668365225195885\n",
      "Validation Loss: 0.07200441509485245\n",
      "Validation Loss: 0.03100145235657692\n",
      "Validation Loss: 0.04013998433947563\n",
      "Validation Loss: 0.059255026280879974\n",
      "Validation Loss: 0.0400797538459301\n",
      "Validation Loss: 0.07017914205789566\n",
      "Validation Loss: 0.06305143982172012\n",
      "Validation Loss: 0.03864141181111336\n",
      "Validation Loss: 0.04087761789560318\n",
      "Validation Loss: 0.03497699648141861\n",
      "Validation Loss: 0.028697049245238304\n",
      "Validation Loss: 0.05118149146437645\n",
      "Validation Loss: 0.01498307567089796\n",
      "Validation Loss: 0.0638047605752945\n",
      "Validation Loss: 0.058546584099531174\n",
      "Validation Loss: 0.04949597641825676\n",
      "Validation Loss: 0.046363841742277145\n",
      "Validation Loss: 0.028987308964133263\n",
      "Validation Loss: 0.022098099812865257\n",
      "Validation Loss: 0.05478234961628914\n",
      "Validation Loss: 0.03417700156569481\n",
      "Validation Loss: 0.04467165470123291\n",
      "Validation Loss: 0.01674310304224491\n",
      "Validation Loss: 0.03674844279885292\n",
      "Validation Loss: 0.06534971296787262\n",
      "Validation Loss: 0.08322383463382721\n",
      "Validation Loss: 0.04256148636341095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.02033158205449581\n",
      "Validation Loss: 0.04521290585398674\n",
      "Validation Loss: 0.035893648862838745\n",
      "Validation Loss: 0.032956186681985855\n",
      "Validation Loss: 0.05494484305381775\n",
      "Validation Loss: 0.01867855153977871\n",
      "Validation Loss: 0.018217748031020164\n",
      "Validation Loss: 0.013425939716398716\n",
      "Validation Loss: 0.0256867203861475\n",
      "Validation Loss: 0.03490762785077095\n",
      "Validation Loss: 0.05831078812479973\n",
      "Validation Loss: 0.07980229705572128\n",
      "Validation Loss: 0.10015231370925903\n",
      "Validation Loss: 0.02408963441848755\n",
      "Validation Loss: 0.09394349902868271\n",
      "Validation Loss: 0.02975780889391899\n",
      "Validation Loss: 0.05413131043314934\n",
      "Validation Loss: 0.03780997917056084\n",
      "Validation Loss: 0.0390956774353981\n",
      "Validation Loss: 0.03573887050151825\n",
      "Validation Loss: 0.0780981034040451\n",
      "Validation Loss: 0.0610479936003685\n",
      "Validation Loss: 0.04037787765264511\n",
      "Validation Loss: 0.02426040731370449\n",
      "Validation Loss: 0.07321903854608536\n",
      "Validation Loss: 0.04189622402191162\n",
      "Validation Loss: 0.03194581717252731\n",
      "Validation Loss: 0.054250795394182205\n",
      "Validation Loss: 0.15555834770202637\n",
      "Validation Loss: 0.03273995593190193\n",
      "Validation Loss: 0.027275530621409416\n",
      "Validation Loss: 0.13724641501903534\n",
      "Validation Loss: 0.05266005918383598\n",
      "Validation Loss: 0.014875559136271477\n",
      "Validation Loss: 0.039160821586847305\n",
      "Validation Loss: 0.048012398183345795\n",
      "Validation Loss: 0.11383916437625885\n",
      "Validation Loss: 0.034140586853027344\n",
      "Validation Loss: 0.03164685517549515\n",
      "Validation Loss: 0.04174579307436943\n",
      "Validation Loss: 0.07738253474235535\n",
      "Validation Loss: 0.033184897154569626\n",
      "Validation Loss: 0.34783366322517395\n",
      "Validation Loss: 0.05420083552598953\n",
      "Validation Loss: 0.026178717613220215\n",
      "Validation Loss: 0.045537061989307404\n",
      "Validation Loss: 0.05050479248166084\n",
      "Validation Loss: 0.06350763142108917\n",
      "Validation Loss: 0.19636663794517517\n",
      "Validation Loss: 0.053687162697315216\n",
      "Validation Loss: 0.05373105779290199\n",
      "Validation Loss: 0.041502781212329865\n",
      "Validation Loss: 0.11545132100582123\n",
      "Validation Loss: 0.3942175805568695\n",
      "Validation Loss: 0.22332556545734406\n",
      "Validation Loss: 0.07338398694992065\n",
      "Validation Loss: 0.05704951286315918\n",
      "Validation Loss: 0.09428248554468155\n",
      "Validation Loss: 0.1327880173921585\n",
      "Validation Loss: 0.05107799172401428\n",
      "Validation Loss: 0.029696790501475334\n",
      "Validation Loss: 0.05061226710677147\n",
      "Validation Loss: 0.16533751785755157\n",
      "Validation Loss: 0.06458353251218796\n",
      "Validation Loss: 0.023212676867842674\n",
      "Validation Loss: 0.3187670409679413\n",
      "Validation Loss: 0.025775671005249023\n",
      "Validation Loss: 0.031224766746163368\n",
      "Validation Loss: 0.027365943416953087\n",
      "Validation Loss: 0.046334605664014816\n",
      "Validation Loss: 0.17593106627464294\n",
      "Validation Loss: 0.15213926136493683\n",
      "Validation Loss: 0.1477625072002411\n",
      "Validation Loss: 0.03340581804513931\n",
      "Validation Loss: 0.06149667128920555\n",
      "Validation Loss: 0.10385739803314209\n",
      "Validation Loss: 0.031013665720820427\n",
      "Validation Loss: 0.021739928051829338\n",
      "Validation Loss: 0.12154056876897812\n",
      "Validation Loss: 0.03368654474616051\n",
      "Validation Loss: 0.051255326718091965\n",
      "Validation Loss: 0.06980308890342712\n",
      "Validation Loss: 0.0668163001537323\n",
      "Validation Loss: 0.0480586402118206\n",
      "Validation Loss: 0.045638129115104675\n",
      "Validation Loss: 0.06104900687932968\n",
      "Validation Loss: 0.04210190102458\n",
      "Validation Loss: 0.03401994705200195\n",
      "Validation Loss: 0.061221275478601456\n",
      "Validation Loss: 0.025472871959209442\n",
      "Validation Loss: 0.020239397883415222\n",
      "Validation Loss: 0.02990051917731762\n",
      "Validation Loss: 0.14994315803050995\n",
      "Validation Loss: 0.041510310024023056\n",
      "Validation Loss: 0.24642443656921387\n",
      "Validation Loss: 0.05990771949291229\n",
      "Validation Loss: 0.09908127039670944\n",
      "Validation Loss: 0.05421735718846321\n",
      "Validation Loss: 0.07903657108545303\n",
      "Validation Loss: 0.047485385090112686\n",
      "Validation Loss: 0.02628989703953266\n",
      "Validation Loss: 0.03682047501206398\n",
      "Validation Loss: 0.07671860605478287\n",
      "Validation Loss: 0.04907998442649841\n",
      "Validation Loss: 0.07643027603626251\n",
      "Validation Loss: 0.04290984198451042\n",
      "Validation Loss: 0.024924790486693382\n",
      "Validation Loss: 0.039415210485458374\n",
      "Validation Loss: 0.02294720895588398\n",
      "Validation Loss: 0.02486833743751049\n",
      "Validation Loss: 0.029946377500891685\n",
      "Validation Loss: 0.01577015593647957\n",
      "Validation Loss: 0.030109953135252\n",
      "Validation Loss: 0.0337253175675869\n",
      "Validation Loss: 0.0804370790719986\n",
      "Validation Loss: 0.055598184466362\n",
      "Validation Loss: 0.033579904586076736\n",
      "Validation Loss: 0.031436722725629807\n",
      "Validation Loss: 0.03183736279606819\n",
      "Validation Loss: 0.019113052636384964\n",
      "Validation Loss: 0.23997637629508972\n",
      "Validation Loss: 0.3520890772342682\n",
      "Validation Loss: 0.0865289494395256\n",
      "Validation Loss: 0.027888569980859756\n",
      "Validation Loss: 0.010006383061408997\n",
      "Validation Loss: 0.02660772018134594\n",
      "Validation Loss: 0.04009391739964485\n",
      "Validation Loss: 0.038897428661584854\n",
      "Validation Loss: 0.08378639072179794\n",
      "Validation Loss: 0.03854925185441971\n",
      "Validation Loss: 0.06567482650279999\n",
      "Validation Loss: 0.018489960581064224\n",
      "Validation Loss: 0.021419178694486618\n",
      "Validation Loss: 0.03634992986917496\n",
      "Validation Loss: 0.06266230344772339\n",
      "Validation Loss: 0.0434858612716198\n",
      "Validation Loss: 0.03166286647319794\n",
      "Validation Loss: 0.01001416239887476\n",
      "Validation Loss: 0.016491331160068512\n",
      "Validation Loss: 0.038016825914382935\n",
      "Validation Loss: 0.04220317304134369\n",
      "Validation Loss: 0.09072903543710709\n",
      "Validation Loss: 0.048524629324674606\n",
      "Validation Loss: 0.033861465752124786\n",
      "Validation Loss: 0.04998743534088135\n",
      "Validation Loss: 0.037290845066308975\n",
      "Validation Loss: 0.03610708937048912\n",
      "Validation Loss: 0.028200702741742134\n",
      "Validation Loss: 0.026550903916358948\n",
      "Validation Loss: 0.0654568299651146\n",
      "Validation Loss: 0.04968487098813057\n",
      "Validation Loss: 0.04682176932692528\n",
      "Validation Loss: 0.050099391490221024\n",
      "Validation Loss: 0.07252250611782074\n",
      "Validation Loss: 0.06481844931840897\n",
      "Validation Loss: 0.08478885889053345\n",
      "Validation Loss: 0.05953330546617508\n",
      "Validation Loss: 0.021765446290373802\n",
      "Validation Loss: 0.07153181731700897\n",
      "Validation Loss: 0.03130704164505005\n",
      "Validation Loss: 0.04024937376379967\n",
      "Validation Loss: 0.06077080965042114\n",
      "Validation Loss: 0.040588125586509705\n",
      "Validation Loss: 0.06488916277885437\n",
      "Validation Loss: 0.059033870697021484\n",
      "Validation Loss: 0.04024259001016617\n",
      "Validation Loss: 0.04217873141169548\n",
      "Validation Loss: 0.03827868402004242\n",
      "Validation Loss: 0.030109411105513573\n",
      "Validation Loss: 0.04497406259179115\n",
      "Validation Loss: 0.014354457147419453\n",
      "Validation Loss: 0.061814699321985245\n",
      "Validation Loss: 0.05798429995775223\n",
      "Validation Loss: 0.05171768367290497\n",
      "Validation Loss: 0.049171410501003265\n",
      "Validation Loss: 0.03044561669230461\n",
      "Validation Loss: 0.0222454983741045\n",
      "Validation Loss: 0.05319344624876976\n",
      "Validation Loss: 0.03483472764492035\n",
      "Validation Loss: 0.04646209254860878\n",
      "Validation Loss: 0.016441699117422104\n",
      "Validation Loss: 0.034371186047792435\n",
      "Validation Loss: 0.05758471041917801\n",
      "Validation Loss: 0.08196830749511719\n",
      "Validation Loss: 0.041445184499025345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.020878935232758522\n",
      "Validation Loss: 0.04313082993030548\n",
      "Validation Loss: 0.029452655464410782\n",
      "Validation Loss: 0.029520761221647263\n",
      "Validation Loss: 0.05478354170918465\n",
      "Validation Loss: 0.01722428947687149\n",
      "Validation Loss: 0.019079433754086494\n",
      "Validation Loss: 0.015356233343482018\n",
      "Validation Loss: 0.025021910667419434\n",
      "Validation Loss: 0.03176512569189072\n",
      "Validation Loss: 0.057947490364313126\n",
      "Validation Loss: 0.08087872713804245\n",
      "Validation Loss: 0.07655651867389679\n",
      "Validation Loss: 0.0252786036580801\n",
      "Validation Loss: 0.09124346822500229\n",
      "Validation Loss: 0.037098824977874756\n",
      "Validation Loss: 0.05913645774126053\n",
      "Validation Loss: 0.040358029305934906\n",
      "Validation Loss: 0.05032680556178093\n",
      "Validation Loss: 0.04386947676539421\n",
      "Validation Loss: 0.07815820723772049\n",
      "Validation Loss: 0.0604778453707695\n",
      "Validation Loss: 0.044741977006196976\n",
      "Validation Loss: 0.027599118649959564\n",
      "Validation Loss: 0.08953861892223358\n",
      "Validation Loss: 0.045544613152742386\n",
      "Validation Loss: 0.03481040894985199\n",
      "Validation Loss: 0.055903296917676926\n",
      "Validation Loss: 0.1140545979142189\n",
      "Validation Loss: 0.033350151032209396\n",
      "Validation Loss: 0.030892908573150635\n",
      "Validation Loss: 0.3341658413410187\n",
      "Validation Loss: 0.053114090114831924\n",
      "Validation Loss: 0.015811506658792496\n",
      "Validation Loss: 0.040321290493011475\n",
      "Validation Loss: 0.05195736140012741\n",
      "Validation Loss: 0.07489342987537384\n",
      "Validation Loss: 0.039595384150743484\n",
      "Validation Loss: 0.031578585505485535\n",
      "Validation Loss: 0.03886640444397926\n",
      "Validation Loss: 0.07552267611026764\n",
      "Validation Loss: 0.03246542066335678\n",
      "Validation Loss: 0.308973103761673\n",
      "Validation Loss: 0.05530279874801636\n",
      "Validation Loss: 0.03366488590836525\n",
      "Validation Loss: 0.0418340265750885\n",
      "Validation Loss: 0.05699194595217705\n",
      "Validation Loss: 0.05848007649183273\n",
      "Validation Loss: 0.1329699009656906\n",
      "Validation Loss: 0.05701112002134323\n",
      "Validation Loss: 0.05682036653161049\n",
      "Validation Loss: 0.04117680713534355\n",
      "Validation Loss: 0.1455070972442627\n",
      "Validation Loss: 0.18639209866523743\n",
      "Validation Loss: 0.2789123058319092\n",
      "Validation Loss: 0.07624036818742752\n",
      "Validation Loss: 0.05315198749303818\n",
      "Validation Loss: 0.09067672491073608\n",
      "Validation Loss: 0.09092485159635544\n",
      "Validation Loss: 0.05134851485490799\n",
      "Validation Loss: 0.02797321416437626\n",
      "Validation Loss: 0.04890250787138939\n",
      "Validation Loss: 0.15451577305793762\n",
      "Validation Loss: 0.06396561861038208\n",
      "Validation Loss: 0.021807536482810974\n",
      "Validation Loss: 0.33440425992012024\n",
      "Validation Loss: 0.02657063864171505\n",
      "Validation Loss: 0.03271722421050072\n",
      "Validation Loss: 0.029143869876861572\n",
      "Validation Loss: 0.04813302680850029\n",
      "Validation Loss: 0.15606850385665894\n",
      "Validation Loss: 0.11273951083421707\n",
      "Validation Loss: 0.1200060322880745\n",
      "Validation Loss: 0.03594093397259712\n",
      "Validation Loss: 0.06434530764818192\n",
      "Validation Loss: 0.106191486120224\n",
      "Validation Loss: 0.03599712997674942\n",
      "Validation Loss: 0.02638905867934227\n",
      "Validation Loss: 0.09658197313547134\n",
      "Validation Loss: 0.04046091064810753\n",
      "Validation Loss: 0.042952828109264374\n",
      "Validation Loss: 0.07102620601654053\n",
      "Validation Loss: 0.06672931462526321\n",
      "Validation Loss: 0.04351811483502388\n",
      "Validation Loss: 0.0926041230559349\n",
      "Validation Loss: 0.057926103472709656\n",
      "Validation Loss: 0.047941334545612335\n",
      "Validation Loss: 0.03462996706366539\n",
      "Validation Loss: 0.06431898474693298\n",
      "Validation Loss: 0.029729770496487617\n",
      "Validation Loss: 0.022503796964883804\n",
      "Validation Loss: 0.029959844425320625\n",
      "Validation Loss: 0.12666314840316772\n",
      "Validation Loss: 0.04905315116047859\n",
      "Validation Loss: 0.20469968020915985\n",
      "Validation Loss: 0.06117276847362518\n",
      "Validation Loss: 0.10267190635204315\n",
      "Validation Loss: 0.0522896833717823\n",
      "Validation Loss: 0.07510782778263092\n",
      "Validation Loss: 0.05109740421175957\n",
      "Validation Loss: 0.028297578915953636\n",
      "Validation Loss: 0.0423261821269989\n",
      "Validation Loss: 0.07605338096618652\n",
      "Validation Loss: 0.04990632086992264\n",
      "Validation Loss: 0.06771369278430939\n",
      "Validation Loss: 0.04150259494781494\n",
      "Validation Loss: 0.026829397305846214\n",
      "Validation Loss: 0.04072943329811096\n",
      "Validation Loss: 0.022280534729361534\n",
      "Validation Loss: 0.025700613856315613\n",
      "Validation Loss: 0.030147027224302292\n",
      "Validation Loss: 0.016481874510645866\n",
      "Validation Loss: 0.03187990188598633\n",
      "Validation Loss: 0.0370878204703331\n",
      "Validation Loss: 0.08607601374387741\n",
      "Validation Loss: 0.057669948786497116\n",
      "Validation Loss: 0.03877833113074303\n",
      "Validation Loss: 0.02958432212471962\n",
      "Validation Loss: 0.037280045449733734\n",
      "Validation Loss: 0.021937068551778793\n",
      "Validation Loss: 0.1509072333574295\n",
      "Validation Loss: 0.37358641624450684\n",
      "Validation Loss: 0.08257752656936646\n",
      "Validation Loss: 0.023778384551405907\n",
      "Validation Loss: 0.010658974759280682\n",
      "Validation Loss: 0.02923610620200634\n",
      "Validation Loss: 0.04131267964839935\n",
      "Validation Loss: 0.0384642668068409\n",
      "Validation Loss: 0.08346644788980484\n",
      "Validation Loss: 0.03771419823169708\n",
      "Validation Loss: 0.05981999263167381\n",
      "Validation Loss: 0.02041345275938511\n",
      "Validation Loss: 0.021101275458931923\n",
      "Validation Loss: 0.03854231908917427\n",
      "Validation Loss: 0.05522727593779564\n",
      "Validation Loss: 0.04233299568295479\n",
      "Validation Loss: 0.02989046834409237\n",
      "Validation Loss: 0.009138822555541992\n",
      "Validation Loss: 0.013652696274220943\n",
      "Validation Loss: 0.04098079726099968\n",
      "Validation Loss: 0.04198923334479332\n",
      "Validation Loss: 0.09068702906370163\n",
      "Validation Loss: 0.05268309637904167\n",
      "Validation Loss: 0.035374075174331665\n",
      "Validation Loss: 0.0465785451233387\n",
      "Validation Loss: 0.04014180228114128\n",
      "Validation Loss: 0.03937181085348129\n",
      "Validation Loss: 0.02937823161482811\n",
      "Validation Loss: 0.024991970509290695\n",
      "Validation Loss: 0.07125119119882584\n",
      "Validation Loss: 0.050226181745529175\n",
      "Validation Loss: 0.044566843658685684\n",
      "Validation Loss: 0.04857710376381874\n",
      "Validation Loss: 0.07950299233198166\n",
      "Validation Loss: 0.06266891956329346\n",
      "Validation Loss: 0.08311636745929718\n",
      "Validation Loss: 0.059141986072063446\n",
      "Validation Loss: 0.023573309183120728\n",
      "Validation Loss: 0.06960320472717285\n",
      "Validation Loss: 0.03443833440542221\n",
      "Validation Loss: 0.040995389223098755\n",
      "Validation Loss: 0.06035693734884262\n",
      "Validation Loss: 0.040123265236616135\n",
      "Validation Loss: 0.060356516391038895\n",
      "Validation Loss: 0.06546782702207565\n",
      "Validation Loss: 0.036868587136268616\n",
      "Validation Loss: 0.044354792684316635\n",
      "Validation Loss: 0.03582993149757385\n",
      "Validation Loss: 0.028290007263422012\n",
      "Validation Loss: 0.044917285442352295\n",
      "Validation Loss: 0.015305169858038425\n",
      "Validation Loss: 0.06937242299318314\n",
      "Validation Loss: 0.061125051230192184\n",
      "Validation Loss: 0.05213632434606552\n",
      "Validation Loss: 0.048720646649599075\n",
      "Validation Loss: 0.034508444368839264\n",
      "Validation Loss: 0.023568056523799896\n",
      "Validation Loss: 0.05698966979980469\n",
      "Validation Loss: 0.035611748695373535\n",
      "Validation Loss: 0.04730977863073349\n",
      "Validation Loss: 0.01801108755171299\n",
      "Validation Loss: 0.032123588025569916\n",
      "Validation Loss: 0.06398804485797882\n",
      "Validation Loss: 0.08066368848085403\n",
      "Validation Loss: 0.04307248070836067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.024106621742248535\n",
      "Validation Loss: 0.03961963206529617\n",
      "Validation Loss: 0.03090541623532772\n",
      "Validation Loss: 0.03172551468014717\n",
      "Validation Loss: 0.0602639839053154\n",
      "Validation Loss: 0.017969205975532532\n",
      "Validation Loss: 0.01855810359120369\n",
      "Validation Loss: 0.013865792192518711\n",
      "Validation Loss: 0.028426047414541245\n",
      "Validation Loss: 0.037408336997032166\n",
      "Validation Loss: 0.059563279151916504\n",
      "Validation Loss: 0.08627539873123169\n",
      "Validation Loss: 0.08768638223409653\n",
      "Validation Loss: 0.02495630830526352\n",
      "Validation Loss: 0.09053363651037216\n",
      "Validation Loss: 0.028415702283382416\n",
      "Validation Loss: 0.05743671581149101\n",
      "Validation Loss: 0.038699228316545486\n",
      "Validation Loss: 0.040266282856464386\n",
      "Validation Loss: 0.0370357409119606\n",
      "Validation Loss: 0.0803745687007904\n",
      "Validation Loss: 0.06520457565784454\n",
      "Validation Loss: 0.039317816495895386\n",
      "Validation Loss: 0.02583247236907482\n",
      "Validation Loss: 0.07477306574583054\n",
      "Validation Loss: 0.03945083171129227\n",
      "Validation Loss: 0.03284481540322304\n",
      "Validation Loss: 0.05007483810186386\n",
      "Validation Loss: 0.1019681841135025\n",
      "Validation Loss: 0.03709416091442108\n",
      "Validation Loss: 0.02827383764088154\n",
      "Validation Loss: 0.17709346115589142\n",
      "Validation Loss: 0.05030538886785507\n",
      "Validation Loss: 0.017600592225790024\n",
      "Validation Loss: 0.03706410527229309\n",
      "Validation Loss: 0.049439769238233566\n",
      "Validation Loss: 0.09565109014511108\n",
      "Validation Loss: 0.0360572375357151\n",
      "Validation Loss: 0.03187418729066849\n",
      "Validation Loss: 0.04035364091396332\n",
      "Validation Loss: 0.07269255071878433\n",
      "Validation Loss: 0.03068346157670021\n",
      "Validation Loss: 0.34057992696762085\n",
      "Validation Loss: 0.05178401991724968\n",
      "Validation Loss: 0.026566823944449425\n",
      "Validation Loss: 0.04064149037003517\n",
      "Validation Loss: 0.05319147929549217\n",
      "Validation Loss: 0.062055736780166626\n",
      "Validation Loss: 0.14101067185401917\n",
      "Validation Loss: 0.05113114044070244\n",
      "Validation Loss: 0.051534637808799744\n",
      "Validation Loss: 0.04109427332878113\n",
      "Validation Loss: 0.12084506452083588\n",
      "Validation Loss: 0.2743391990661621\n",
      "Validation Loss: 0.2399749755859375\n",
      "Validation Loss: 0.07045001536607742\n",
      "Validation Loss: 0.05557003989815712\n",
      "Validation Loss: 0.08134835958480835\n",
      "Validation Loss: 0.09904694557189941\n",
      "Validation Loss: 0.046643126755952835\n",
      "Validation Loss: 0.034223772585392\n",
      "Validation Loss: 0.04716923087835312\n",
      "Validation Loss: 0.15461057424545288\n",
      "Validation Loss: 0.06198173388838768\n",
      "Validation Loss: 0.02268054336309433\n",
      "Validation Loss: 0.33278122544288635\n",
      "Validation Loss: 0.0252460278570652\n",
      "Validation Loss: 0.031636592000722885\n",
      "Validation Loss: 0.029752813279628754\n",
      "Validation Loss: 0.05011884868144989\n",
      "Validation Loss: 0.12768115103244781\n",
      "Validation Loss: 0.12386965751647949\n",
      "Validation Loss: 0.12063225358724594\n",
      "Validation Loss: 0.03221861645579338\n",
      "Validation Loss: 0.06488427519798279\n",
      "Validation Loss: 0.10305864363908768\n",
      "Validation Loss: 0.030443698167800903\n",
      "Validation Loss: 0.020453497767448425\n",
      "Validation Loss: 0.09599278122186661\n",
      "Validation Loss: 0.04218029975891113\n",
      "Validation Loss: 0.043613508343696594\n",
      "Validation Loss: 0.06968773901462555\n",
      "Validation Loss: 0.06438718736171722\n",
      "Validation Loss: 0.05009998753666878\n",
      "Validation Loss: 0.05490151047706604\n",
      "Validation Loss: 0.05475914105772972\n",
      "Validation Loss: 0.04381236433982849\n",
      "Validation Loss: 0.03198011592030525\n",
      "Validation Loss: 0.06191724166274071\n",
      "Validation Loss: 0.026088010519742966\n",
      "Validation Loss: 0.021237198263406754\n",
      "Validation Loss: 0.035722896456718445\n",
      "Validation Loss: 0.12185432761907578\n",
      "Validation Loss: 0.0399654246866703\n",
      "Validation Loss: 0.19891390204429626\n",
      "Validation Loss: 0.060578856617212296\n",
      "Validation Loss: 0.10056421905755997\n",
      "Validation Loss: 0.059654347598552704\n",
      "Validation Loss: 0.07815733551979065\n",
      "Validation Loss: 0.049870770424604416\n",
      "Validation Loss: 0.026455501094460487\n",
      "Validation Loss: 0.035669952630996704\n",
      "Validation Loss: 0.07317838817834854\n",
      "Validation Loss: 0.05283406749367714\n",
      "Validation Loss: 0.07675623893737793\n",
      "Validation Loss: 0.041767094284296036\n",
      "Validation Loss: 0.023901283740997314\n",
      "Validation Loss: 0.03897180035710335\n",
      "Validation Loss: 0.02272571064531803\n",
      "Validation Loss: 0.025609906762838364\n",
      "Validation Loss: 0.030090676620602608\n",
      "Validation Loss: 0.015415552072227001\n",
      "Validation Loss: 0.03219526261091232\n",
      "Validation Loss: 0.036533012986183167\n",
      "Validation Loss: 0.08520185947418213\n",
      "Validation Loss: 0.05264168232679367\n",
      "Validation Loss: 0.036420226097106934\n",
      "Validation Loss: 0.03029823862016201\n",
      "Validation Loss: 0.030380938202142715\n",
      "Validation Loss: 0.019349757581949234\n",
      "Validation Loss: 0.18648289144039154\n",
      "Validation Loss: 0.30704575777053833\n",
      "Validation Loss: 0.0837768092751503\n",
      "Validation Loss: 0.028018241748213768\n",
      "Validation Loss: 0.009727025404572487\n",
      "Validation Loss: 0.029422257095575333\n",
      "Validation Loss: 0.041202057152986526\n",
      "Validation Loss: 0.03804948925971985\n",
      "Validation Loss: 0.08434911072254181\n",
      "Validation Loss: 0.038350414484739304\n",
      "Validation Loss: 0.06315284222364426\n",
      "Validation Loss: 0.01936119794845581\n",
      "Validation Loss: 0.02123241126537323\n",
      "Validation Loss: 0.037350546568632126\n",
      "Validation Loss: 0.0590473935008049\n",
      "Validation Loss: 0.046490687876939774\n",
      "Validation Loss: 0.03193045035004616\n",
      "Validation Loss: 0.010985007509589195\n",
      "Validation Loss: 0.015859592705965042\n",
      "Validation Loss: 0.03911067545413971\n",
      "Validation Loss: 0.04240482673048973\n",
      "Validation Loss: 0.09074821323156357\n",
      "Validation Loss: 0.04482825845479965\n",
      "Validation Loss: 0.03436512127518654\n",
      "Validation Loss: 0.050873395055532455\n",
      "Validation Loss: 0.0385638102889061\n",
      "Validation Loss: 0.035801734775304794\n",
      "Validation Loss: 0.028546512126922607\n",
      "Validation Loss: 0.02778887376189232\n",
      "Validation Loss: 0.06754598766565323\n",
      "Validation Loss: 0.048609357327222824\n",
      "Validation Loss: 0.051203083246946335\n",
      "Validation Loss: 0.04862501099705696\n",
      "Validation Loss: 0.06746890395879745\n",
      "Validation Loss: 0.06782309710979462\n",
      "Validation Loss: 0.08160964399576187\n",
      "Validation Loss: 0.057095155119895935\n",
      "Validation Loss: 0.02237844280898571\n",
      "Validation Loss: 0.07227015495300293\n",
      "Validation Loss: 0.03294394165277481\n",
      "Validation Loss: 0.03706010803580284\n",
      "Validation Loss: 0.06115203723311424\n",
      "Validation Loss: 0.03938227891921997\n",
      "Validation Loss: 0.0647423043847084\n",
      "Validation Loss: 0.05781431868672371\n",
      "Validation Loss: 0.041505418717861176\n",
      "Validation Loss: 0.04212016984820366\n",
      "Validation Loss: 0.037657059729099274\n",
      "Validation Loss: 0.03111962042748928\n",
      "Validation Loss: 0.04331357032060623\n",
      "Validation Loss: 0.01413872092962265\n",
      "Validation Loss: 0.06358363479375839\n",
      "Validation Loss: 0.058101873844861984\n",
      "Validation Loss: 0.05421576276421547\n",
      "Validation Loss: 0.04632873088121414\n",
      "Validation Loss: 0.028521796688437462\n",
      "Validation Loss: 0.021099330857396126\n",
      "Validation Loss: 0.05644606798887253\n",
      "Validation Loss: 0.033675193786621094\n",
      "Validation Loss: 0.04554015025496483\n",
      "Validation Loss: 0.018112553283572197\n",
      "Validation Loss: 0.03221571445465088\n",
      "Validation Loss: 0.06016164273023605\n",
      "Validation Loss: 0.0800977349281311\n",
      "Validation Loss: 0.03846648707985878\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.022557513788342476\n",
      "Validation Loss: 0.04516449570655823\n",
      "Validation Loss: 0.024984875693917274\n",
      "Validation Loss: 0.026951363310217857\n",
      "Validation Loss: 0.06168060004711151\n",
      "Validation Loss: 0.018684295937418938\n",
      "Validation Loss: 0.01913115754723549\n",
      "Validation Loss: 0.01569516584277153\n",
      "Validation Loss: 0.02808341197669506\n",
      "Validation Loss: 0.03230183571577072\n",
      "Validation Loss: 0.057559143751859665\n",
      "Validation Loss: 0.086514413356781\n",
      "Validation Loss: 0.11133988946676254\n",
      "Validation Loss: 0.02524111047387123\n",
      "Validation Loss: 0.0940365195274353\n",
      "Validation Loss: 0.028848797082901\n",
      "Validation Loss: 0.05415705218911171\n",
      "Validation Loss: 0.03580300882458687\n",
      "Validation Loss: 0.0433744341135025\n",
      "Validation Loss: 0.040093932300806046\n",
      "Validation Loss: 0.08163733035326004\n",
      "Validation Loss: 0.06495898962020874\n",
      "Validation Loss: 0.040473468601703644\n",
      "Validation Loss: 0.02635749988257885\n",
      "Validation Loss: 0.06885123252868652\n",
      "Validation Loss: 0.04002239182591438\n",
      "Validation Loss: 0.03546563535928726\n",
      "Validation Loss: 0.048317354172468185\n",
      "Validation Loss: 0.10556041449308395\n",
      "Validation Loss: 0.037220779806375504\n",
      "Validation Loss: 0.027281103655695915\n",
      "Validation Loss: 0.19241270422935486\n",
      "Validation Loss: 0.051894307136535645\n",
      "Validation Loss: 0.016904547810554504\n",
      "Validation Loss: 0.038155365735292435\n",
      "Validation Loss: 0.05447959899902344\n",
      "Validation Loss: 0.09771490097045898\n",
      "Validation Loss: 0.0342472679913044\n",
      "Validation Loss: 0.03173515945672989\n",
      "Validation Loss: 0.038108814507722855\n",
      "Validation Loss: 0.07944633811712265\n",
      "Validation Loss: 0.0320003516972065\n",
      "Validation Loss: 0.272053062915802\n",
      "Validation Loss: 0.05305851623415947\n",
      "Validation Loss: 0.027545448392629623\n",
      "Validation Loss: 0.04847871884703636\n",
      "Validation Loss: 0.05377243459224701\n",
      "Validation Loss: 0.07161938399076462\n",
      "Validation Loss: 0.13361181318759918\n",
      "Validation Loss: 0.054248712956905365\n",
      "Validation Loss: 0.0515296570956707\n",
      "Validation Loss: 0.04011576250195503\n",
      "Validation Loss: 0.12524619698524475\n",
      "Validation Loss: 0.3594147264957428\n",
      "Validation Loss: 0.23089058697223663\n",
      "Validation Loss: 0.07087094336748123\n",
      "Validation Loss: 0.05413603037595749\n",
      "Validation Loss: 0.09967702627182007\n",
      "Validation Loss: 0.13980460166931152\n",
      "Validation Loss: 0.05082117021083832\n",
      "Validation Loss: 0.03117828629910946\n",
      "Validation Loss: 0.04914699122309685\n",
      "Validation Loss: 0.14762696623802185\n",
      "Validation Loss: 0.06328475475311279\n",
      "Validation Loss: 0.02398076094686985\n",
      "Validation Loss: 0.22348369657993317\n",
      "Validation Loss: 0.027989396825432777\n",
      "Validation Loss: 0.032304197549819946\n",
      "Validation Loss: 0.02890857867896557\n",
      "Validation Loss: 0.05148018151521683\n",
      "Validation Loss: 0.14413362741470337\n",
      "Validation Loss: 0.12275461852550507\n",
      "Validation Loss: 0.10303773730993271\n",
      "Validation Loss: 0.03426818549633026\n",
      "Validation Loss: 0.06191539391875267\n",
      "Validation Loss: 0.10169633477926254\n",
      "Validation Loss: 0.031283363699913025\n",
      "Validation Loss: 0.020777368918061256\n",
      "Validation Loss: 0.1256513148546219\n",
      "Validation Loss: 0.036698758602142334\n",
      "Validation Loss: 0.03757175803184509\n",
      "Validation Loss: 0.0677863135933876\n",
      "Validation Loss: 0.06322671473026276\n",
      "Validation Loss: 0.052251849323511124\n",
      "Validation Loss: 0.049853283911943436\n",
      "Validation Loss: 0.05400831252336502\n",
      "Validation Loss: 0.04348239302635193\n",
      "Validation Loss: 0.03311862796545029\n",
      "Validation Loss: 0.060120485723018646\n",
      "Validation Loss: 0.023662492632865906\n",
      "Validation Loss: 0.02158123441040516\n",
      "Validation Loss: 0.031481631100177765\n",
      "Validation Loss: 0.1317666620016098\n",
      "Validation Loss: 0.040635846555233\n",
      "Validation Loss: 0.21888551115989685\n",
      "Validation Loss: 0.0621565505862236\n",
      "Validation Loss: 0.09961819648742676\n",
      "Validation Loss: 0.056175362318754196\n",
      "Validation Loss: 0.07980537414550781\n",
      "Validation Loss: 0.048442959785461426\n",
      "Validation Loss: 0.0268380269408226\n",
      "Validation Loss: 0.036479316651821136\n",
      "Validation Loss: 0.07361674308776855\n",
      "Validation Loss: 0.054263077676296234\n",
      "Validation Loss: 0.06992214918136597\n",
      "Validation Loss: 0.042303625494241714\n",
      "Validation Loss: 0.023774389177560806\n",
      "Validation Loss: 0.040782827883958817\n",
      "Validation Loss: 0.021539142355322838\n",
      "Validation Loss: 0.024031775072216988\n",
      "Validation Loss: 0.030238011851906776\n",
      "Validation Loss: 0.014736243523657322\n",
      "Validation Loss: 0.030010513961315155\n",
      "Validation Loss: 0.0358530655503273\n",
      "Validation Loss: 0.08276806026697159\n",
      "Validation Loss: 0.048589013516902924\n",
      "Validation Loss: 0.028154850006103516\n",
      "Validation Loss: 0.030932627618312836\n",
      "Validation Loss: 0.03253032639622688\n",
      "Validation Loss: 0.020355045795440674\n",
      "Validation Loss: 0.2335309386253357\n",
      "Validation Loss: 0.3486274778842926\n",
      "Validation Loss: 0.08623158931732178\n",
      "Validation Loss: 0.030265038833022118\n",
      "Validation Loss: 0.00911109708249569\n",
      "Validation Loss: 0.0279652439057827\n",
      "Validation Loss: 0.040170807391405106\n",
      "Validation Loss: 0.03581566363573074\n",
      "Validation Loss: 0.07951901108026505\n",
      "Validation Loss: 0.0392451174557209\n",
      "Validation Loss: 0.06158993020653725\n",
      "Validation Loss: 0.018253663554787636\n",
      "Validation Loss: 0.020032713189721107\n",
      "Validation Loss: 0.0397503636777401\n",
      "Validation Loss: 0.06550686061382294\n",
      "Validation Loss: 0.04838186129927635\n",
      "Validation Loss: 0.03137760981917381\n",
      "Validation Loss: 0.010118480771780014\n",
      "Validation Loss: 0.0169829111546278\n",
      "Validation Loss: 0.038188766688108444\n",
      "Validation Loss: 0.04228454828262329\n",
      "Validation Loss: 0.09165060520172119\n",
      "Validation Loss: 0.04817982763051987\n",
      "Validation Loss: 0.03562254086136818\n",
      "Validation Loss: 0.048809897154569626\n",
      "Validation Loss: 0.03568131849169731\n",
      "Validation Loss: 0.03529337793588638\n",
      "Validation Loss: 0.02880704402923584\n",
      "Validation Loss: 0.032252199947834015\n",
      "Validation Loss: 0.07205314934253693\n",
      "Validation Loss: 0.04980553314089775\n",
      "Validation Loss: 0.04936324432492256\n",
      "Validation Loss: 0.049877285957336426\n",
      "Validation Loss: 0.06865689903497696\n",
      "Validation Loss: 0.0657249465584755\n",
      "Validation Loss: 0.08522927016019821\n",
      "Validation Loss: 0.05596080422401428\n",
      "Validation Loss: 0.02484842948615551\n",
      "Validation Loss: 0.07881204038858414\n",
      "Validation Loss: 0.03362110257148743\n",
      "Validation Loss: 0.03834718465805054\n",
      "Validation Loss: 0.058337900787591934\n",
      "Validation Loss: 0.03998720645904541\n",
      "Validation Loss: 0.0715024471282959\n",
      "Validation Loss: 0.05854155868291855\n",
      "Validation Loss: 0.039997342973947525\n",
      "Validation Loss: 0.048199307173490524\n",
      "Validation Loss: 0.03684457391500473\n",
      "Validation Loss: 0.026534108445048332\n",
      "Validation Loss: 0.04822862893342972\n",
      "Validation Loss: 0.016435405239462852\n",
      "Validation Loss: 0.06318904459476471\n",
      "Validation Loss: 0.05996778979897499\n",
      "Validation Loss: 0.05204382538795471\n",
      "Validation Loss: 0.04262493550777435\n",
      "Validation Loss: 0.028584757819771767\n",
      "Validation Loss: 0.02153848297894001\n",
      "Validation Loss: 0.05817018076777458\n",
      "Validation Loss: 0.03612520173192024\n",
      "Validation Loss: 0.04366382211446762\n",
      "Validation Loss: 0.01792125590145588\n",
      "Validation Loss: 0.03184055909514427\n",
      "Validation Loss: 0.06505183130502701\n",
      "Validation Loss: 0.08141863346099854\n",
      "Validation Loss: 0.0373612642288208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.01991906203329563\n",
      "Validation Loss: 0.04703469201922417\n",
      "Validation Loss: 0.037046097218990326\n",
      "Validation Loss: 0.03282788768410683\n",
      "Validation Loss: 0.05853511020541191\n",
      "Validation Loss: 0.01730584353208542\n",
      "Validation Loss: 0.01995965838432312\n",
      "Validation Loss: 0.015467851422727108\n",
      "Validation Loss: 0.027159377932548523\n",
      "Validation Loss: 0.03776974976062775\n",
      "Validation Loss: 0.05938779562711716\n",
      "Validation Loss: 0.08037101477384567\n",
      "Validation Loss: 0.07629185914993286\n",
      "Validation Loss: 0.024963991716504097\n",
      "Validation Loss: 0.09735530614852905\n",
      "Validation Loss: 0.03880855813622475\n",
      "Validation Loss: 0.057613808661699295\n",
      "Validation Loss: 0.04448091611266136\n",
      "Validation Loss: 0.047008953988552094\n",
      "Validation Loss: 0.04185080528259277\n",
      "Validation Loss: 0.07893676310777664\n",
      "Validation Loss: 0.06365572661161423\n",
      "Validation Loss: 0.039560750126838684\n",
      "Validation Loss: 0.027693048119544983\n",
      "Validation Loss: 0.07384626567363739\n",
      "Validation Loss: 0.03956305980682373\n",
      "Validation Loss: 0.03958076238632202\n",
      "Validation Loss: 0.053258463740348816\n",
      "Validation Loss: 0.1442788988351822\n",
      "Validation Loss: 0.03765235096216202\n",
      "Validation Loss: 0.029576806351542473\n",
      "Validation Loss: 0.16436968743801117\n",
      "Validation Loss: 0.051363978534936905\n",
      "Validation Loss: 0.017684653401374817\n",
      "Validation Loss: 0.03891982510685921\n",
      "Validation Loss: 0.05281796306371689\n",
      "Validation Loss: 0.10503467917442322\n",
      "Validation Loss: 0.0423397533595562\n",
      "Validation Loss: 0.036031194031238556\n",
      "Validation Loss: 0.04603167250752449\n",
      "Validation Loss: 0.08230360597372055\n",
      "Validation Loss: 0.034548886120319366\n",
      "Validation Loss: 0.34396299719810486\n",
      "Validation Loss: 0.05378713458776474\n",
      "Validation Loss: 0.028539519757032394\n",
      "Validation Loss: 0.041614484041929245\n",
      "Validation Loss: 0.05797449126839638\n",
      "Validation Loss: 0.06293117254972458\n",
      "Validation Loss: 0.2714989185333252\n",
      "Validation Loss: 0.056729719042778015\n",
      "Validation Loss: 0.05644821375608444\n",
      "Validation Loss: 0.0447113923728466\n",
      "Validation Loss: 0.11956638097763062\n",
      "Validation Loss: 0.4496021866798401\n",
      "Validation Loss: 0.2624795138835907\n",
      "Validation Loss: 0.07231981307268143\n",
      "Validation Loss: 0.0491124726831913\n",
      "Validation Loss: 0.08017583936452866\n",
      "Validation Loss: 0.12924447655677795\n",
      "Validation Loss: 0.05511343106627464\n",
      "Validation Loss: 0.03195422887802124\n",
      "Validation Loss: 0.04761117324233055\n",
      "Validation Loss: 0.1574408859014511\n",
      "Validation Loss: 0.062170132994651794\n",
      "Validation Loss: 0.024119382724165916\n",
      "Validation Loss: 0.35248804092407227\n",
      "Validation Loss: 0.023016849532723427\n",
      "Validation Loss: 0.029006628319621086\n",
      "Validation Loss: 0.03179582580924034\n",
      "Validation Loss: 0.05222582072019577\n",
      "Validation Loss: 0.17185650765895844\n",
      "Validation Loss: 0.14430516958236694\n",
      "Validation Loss: 0.156337171792984\n",
      "Validation Loss: 0.030871301889419556\n",
      "Validation Loss: 0.0675419494509697\n",
      "Validation Loss: 0.10530415922403336\n",
      "Validation Loss: 0.030136864632368088\n",
      "Validation Loss: 0.02373371459543705\n",
      "Validation Loss: 0.11034512519836426\n",
      "Validation Loss: 0.03736963868141174\n",
      "Validation Loss: 0.046097204089164734\n",
      "Validation Loss: 0.07104308158159256\n",
      "Validation Loss: 0.07015756517648697\n",
      "Validation Loss: 0.04554370045661926\n",
      "Validation Loss: 0.05020381882786751\n",
      "Validation Loss: 0.05883903056383133\n",
      "Validation Loss: 0.044093139469623566\n",
      "Validation Loss: 0.03087787516415119\n",
      "Validation Loss: 0.05612329766154289\n",
      "Validation Loss: 0.023595845326781273\n",
      "Validation Loss: 0.0193509329110384\n",
      "Validation Loss: 0.030741622671484947\n",
      "Validation Loss: 0.1318538933992386\n",
      "Validation Loss: 0.04748128727078438\n",
      "Validation Loss: 0.21992671489715576\n",
      "Validation Loss: 0.06211937591433525\n",
      "Validation Loss: 0.10266318172216415\n",
      "Validation Loss: 0.06042477488517761\n",
      "Validation Loss: 0.06878203898668289\n",
      "Validation Loss: 0.04827146232128143\n",
      "Validation Loss: 0.02897852659225464\n",
      "Validation Loss: 0.03204846382141113\n",
      "Validation Loss: 0.07684660702943802\n",
      "Validation Loss: 0.05611224099993706\n",
      "Validation Loss: 0.07571260631084442\n",
      "Validation Loss: 0.04788369685411453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0241930540651083\n",
      "Validation Loss: 0.0407274067401886\n",
      "Validation Loss: 0.023255830630660057\n",
      "Validation Loss: 0.026588086038827896\n",
      "Validation Loss: 0.030264703556895256\n",
      "Validation Loss: 0.01730334199965\n",
      "Validation Loss: 0.03086857497692108\n",
      "Validation Loss: 0.03664743900299072\n",
      "Validation Loss: 0.09494487196207047\n",
      "Validation Loss: 0.06236562132835388\n",
      "Validation Loss: 0.03820749744772911\n",
      "Validation Loss: 0.03410409390926361\n",
      "Validation Loss: 0.031864166259765625\n",
      "Validation Loss: 0.022941075265407562\n",
      "Validation Loss: 0.21155264973640442\n",
      "Validation Loss: 0.3739306926727295\n",
      "Validation Loss: 0.08282119035720825\n",
      "Validation Loss: 0.02928859367966652\n",
      "Validation Loss: 0.011288709938526154\n",
      "Validation Loss: 0.028414247557520866\n",
      "Validation Loss: 0.0407157726585865\n",
      "Validation Loss: 0.03598395735025406\n",
      "Validation Loss: 0.09035992622375488\n",
      "Validation Loss: 0.039944637566804886\n",
      "Validation Loss: 0.07138731330633163\n",
      "Validation Loss: 0.017857879400253296\n",
      "Validation Loss: 0.022525008767843246\n",
      "Validation Loss: 0.04141361638903618\n",
      "Validation Loss: 0.06730296462774277\n",
      "Validation Loss: 0.04463239014148712\n",
      "Validation Loss: 0.0346764400601387\n",
      "Validation Loss: 0.010821767151355743\n",
      "Validation Loss: 0.015169450081884861\n",
      "Validation Loss: 0.039193637669086456\n",
      "Validation Loss: 0.04331864044070244\n",
      "Validation Loss: 0.08704381436109543\n",
      "Validation Loss: 0.049712881445884705\n",
      "Validation Loss: 0.035473380237817764\n",
      "Validation Loss: 0.04584736377000809\n",
      "Validation Loss: 0.03745295852422714\n",
      "Validation Loss: 0.03725690394639969\n",
      "Validation Loss: 0.026965564116835594\n",
      "Validation Loss: 0.027333347126841545\n",
      "Validation Loss: 0.06512071192264557\n",
      "Validation Loss: 0.048428721725940704\n",
      "Validation Loss: 0.0495746023952961\n",
      "Validation Loss: 0.05004509538412094\n",
      "Validation Loss: 0.0696708932518959\n",
      "Validation Loss: 0.06234869733452797\n",
      "Validation Loss: 0.08032481372356415\n",
      "Validation Loss: 0.05851916968822479\n",
      "Validation Loss: 0.0209799837321043\n",
      "Validation Loss: 0.06853542476892471\n",
      "Validation Loss: 0.032459888607263565\n",
      "Validation Loss: 0.03892561048269272\n",
      "Validation Loss: 0.06042849272489548\n",
      "Validation Loss: 0.04211084917187691\n",
      "Validation Loss: 0.07177011668682098\n",
      "Validation Loss: 0.0630229115486145\n",
      "Validation Loss: 0.043559253215789795\n",
      "Validation Loss: 0.045323751866817474\n",
      "Validation Loss: 0.039178021252155304\n",
      "Validation Loss: 0.026777029037475586\n",
      "Validation Loss: 0.04459197446703911\n",
      "Validation Loss: 0.014899798668920994\n",
      "Validation Loss: 0.06752771884202957\n",
      "Validation Loss: 0.0575878843665123\n",
      "Validation Loss: 0.04925355315208435\n",
      "Validation Loss: 0.045300453901290894\n",
      "Validation Loss: 0.03070823848247528\n",
      "Validation Loss: 0.022665617987513542\n",
      "Validation Loss: 0.056222353130578995\n",
      "Validation Loss: 0.03751123696565628\n",
      "Validation Loss: 0.04561492055654526\n",
      "Validation Loss: 0.0171967763453722\n",
      "Validation Loss: 0.033002693206071854\n",
      "Validation Loss: 0.06218517944216728\n",
      "Validation Loss: 0.0733952522277832\n",
      "Validation Loss: 0.038311999291181564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/p/parshvam/.local/perlmutter/python-3.11/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f78ac492a744e22a08769f17cd399cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.0693124383687973\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0693124383687973}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = WeatherDataset(X_train, y_train)\n",
    "val_dataset = WeatherDataset(X_val, y_val)\n",
    "test_dataset = WeatherDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hyperparameters for SegRNN\n",
    "input_size = X.shape[2]  # Number of features\n",
    "hidden_size = 512  # Based on the SEGRNN paper\n",
    "output_size = X.shape[2]  # Predict all features\n",
    "segment_length = 8  # Based on the SEGRNN paper\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize SegRNNModel\n",
    "model = SegRNNModel(\n",
    "   input_size=input_size,\n",
    "   hidden_size=hidden_size,\n",
    "   output_size=output_size,\n",
    "   segment_length=segment_length,\n",
    "   learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger(\"logs\", name=\"segrnn_experiment\")\n",
    "\n",
    "# Checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "   dirpath=\"checkpoints/\",\n",
    "   filename=\"segrnn-{epoch:02d}-{val_loss:.4f}\",\n",
    "   save_top_k=1,\n",
    "   monitor=\"val_loss\",  # Monitor validation loss\n",
    "   mode=\"min\"\n",
    ")\n",
    "\n",
    "# Trainer with logging and checkpointing\n",
    "trainer = Trainer(\n",
    "   max_epochs=25,\n",
    "   accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "   devices=1,\n",
    "   logger=logger,\n",
    "   callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Train the model, including validation loader\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Optional: Evaluate on the test set\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-de53e04588687827\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-de53e04588687827\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
