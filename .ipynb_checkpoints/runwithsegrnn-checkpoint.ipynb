{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16a89be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from segrnn import SegRNNModel\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800f972e-509e-40f2-bb51-5d590cffee2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Replace 'your_dataset.csv' with your actual data file\n",
    "df = pd.read_csv('JRB.csv', low_memory=False)\n",
    "\n",
    "# Step 1: Ensure 'valid' column is datetime and sort the DataFrame\n",
    "df['valid'] = pd.to_datetime(df['valid'])\n",
    "df = df.sort_values(by=['station', 'valid']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0dbc87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>dwpf</th>\n",
       "      <th>relh</th>\n",
       "      <th>drct</th>\n",
       "      <th>sknt</th>\n",
       "      <th>p01i</th>\n",
       "      <th>alti</th>\n",
       "      <th>mslp</th>\n",
       "      <th>...</th>\n",
       "      <th>wxcodes</th>\n",
       "      <th>ice_accretion_1hr</th>\n",
       "      <th>ice_accretion_3hr</th>\n",
       "      <th>ice_accretion_6hr</th>\n",
       "      <th>peak_wind_gust</th>\n",
       "      <th>peak_wind_drct</th>\n",
       "      <th>peak_wind_time</th>\n",
       "      <th>feel</th>\n",
       "      <th>metar</th>\n",
       "      <th>snowdepth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 08:15:00</td>\n",
       "      <td>73.40</td>\n",
       "      <td>66.20</td>\n",
       "      <td>78.19</td>\n",
       "      <td>240.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>73.40</td>\n",
       "      <td>KJRB 211215Z 24005KT 10SM CLR 23/19 A3017 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 08:35:00</td>\n",
       "      <td>73.40</td>\n",
       "      <td>66.20</td>\n",
       "      <td>78.19</td>\n",
       "      <td>240.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>73.40</td>\n",
       "      <td>KJRB 211235Z 24005KT 10SM CLR 23/19 A3017 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 08:55:00</td>\n",
       "      <td>75.20</td>\n",
       "      <td>66.20</td>\n",
       "      <td>73.61</td>\n",
       "      <td>240.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>75.20</td>\n",
       "      <td>KJRB 211255Z 24006KT 10SM CLR 24/19 A3017 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 09:15:00</td>\n",
       "      <td>75.20</td>\n",
       "      <td>66.20</td>\n",
       "      <td>73.61</td>\n",
       "      <td>240.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.17</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>75.20</td>\n",
       "      <td>KJRB 211315Z 24005KT 10SM CLR 24/19 A3017 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2016-07-21 09:35:00</td>\n",
       "      <td>78.80</td>\n",
       "      <td>66.20</td>\n",
       "      <td>65.33</td>\n",
       "      <td>240.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.16</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>80.82</td>\n",
       "      <td>KJRB 211335Z 24005KT 10SM CLR 26/19 A3016 RMK AO1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  station               valid   tmpf   dwpf   relh    drct  sknt  p01i   alti  \\\n",
       "0     JRB 2016-07-21 08:15:00  73.40  66.20  78.19  240.00  5.00  0.00  30.17   \n",
       "1     JRB 2016-07-21 08:35:00  73.40  66.20  78.19  240.00  5.00  0.00  30.17   \n",
       "2     JRB 2016-07-21 08:55:00  75.20  66.20  73.61  240.00  6.00  0.00  30.17   \n",
       "3     JRB 2016-07-21 09:15:00  75.20  66.20  73.61  240.00  5.00  0.00  30.17   \n",
       "4     JRB 2016-07-21 09:35:00  78.80  66.20  65.33  240.00  5.00  0.00  30.16   \n",
       "\n",
       "  mslp  ... wxcodes ice_accretion_1hr ice_accretion_3hr ice_accretion_6hr  \\\n",
       "0    M  ...       M                 M                 M                 M   \n",
       "1    M  ...       M                 M                 M                 M   \n",
       "2    M  ...       M                 M                 M                 M   \n",
       "3    M  ...       M                 M                 M                 M   \n",
       "4    M  ...       M                 M                 M                 M   \n",
       "\n",
       "  peak_wind_gust peak_wind_drct peak_wind_time   feel  \\\n",
       "0              M              M              M  73.40   \n",
       "1              M              M              M  73.40   \n",
       "2              M              M              M  75.20   \n",
       "3              M              M              M  75.20   \n",
       "4              M              M              M  80.82   \n",
       "\n",
       "                                               metar snowdepth  \n",
       "0  KJRB 211215Z 24005KT 10SM CLR 23/19 A3017 RMK AO1         M  \n",
       "1  KJRB 211235Z 24005KT 10SM CLR 23/19 A3017 RMK AO1         M  \n",
       "2  KJRB 211255Z 24006KT 10SM CLR 24/19 A3017 RMK AO1         M  \n",
       "3  KJRB 211315Z 24005KT 10SM CLR 24/19 A3017 RMK AO1         M  \n",
       "4  KJRB 211335Z 24005KT 10SM CLR 26/19 A3016 RMK AO1         M  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c993893a-b1e6-41b5-8243-6799fb89d8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2124503/2860399940.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Replace placeholders with np.nan in continuous columns\n",
    "continuous_cols = ['tmpf', 'dwpf', 'relh', 'feel', 'drct', 'sknt', 'gust',\n",
    "                   'peak_wind_gust', 'peak_wind_drct', 'alti', 'mslp', 'vsby',\n",
    "                   'p01i', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr',\n",
    "                   'skyl1', 'skyl2', 'skyl3', 'skyl4', 'snowdepth', 'peak_wind_time']\n",
    "\n",
    "# List of placeholders to replace\n",
    "placeholders = ['M', 'T', '', 'NaN', 'NULL', 'None']\n",
    "\n",
    "# Replace placeholders with np.nan\n",
    "df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n",
    "\n",
    "# Convert continuous columns to numeric, coercing errors to np.nan\n",
    "for col in continuous_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d200400f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                   6865\n",
      "dwpf                   7015\n",
      "relh                   7112\n",
      "feel                   7125\n",
      "drct                  25052\n",
      "sknt                   5024\n",
      "gust                 101714\n",
      "peak_wind_gust       108345\n",
      "peak_wind_drct       108345\n",
      "alti                  12732\n",
      "mslp                  37235\n",
      "vsby                   9941\n",
      "p01i                   7730\n",
      "ice_accretion_1hr    114664\n",
      "ice_accretion_3hr    114664\n",
      "ice_accretion_6hr    114664\n",
      "skyl1                 54223\n",
      "skyl2                 93650\n",
      "skyl3                107296\n",
      "skyl4                114664\n",
      "snowdepth            114664\n",
      "peak_wind_time       114664\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in continuous columns before processing:\")\n",
    "print(df[continuous_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd125b17-a291-4804-9adc-259aa99af2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan thresh is 57332.0\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "Remaining continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Handle missing values in continuous variables\n",
    "\n",
    "\n",
    "# Identify columns to drop due to high NaN count\n",
    "nan_threshold = df.shape[0] / 2                     # Remove columns with more than 50% missing values\n",
    "print(f\"nan thresh is {nan_threshold}\")\n",
    "bad_columns = [col for col in df.columns if df[col].isnull().sum() >= nan_threshold]\n",
    "print(f\"bad columns are {bad_columns}\")\n",
    "\n",
    "# Add less relevant and irrelevant features to the removal list\n",
    "irrelevant_features = [\n",
    "    'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr',  # Fully NaN\n",
    "    'skyl1', 'skyl2', 'skyl3', 'skyl4',  # Less relevant (Sky level altitudes)\n",
    "    'skyc1', 'skyc2', 'skyc3', 'skyc4',  # Less relevant (Sky coverage)\n",
    "    'wxcodes',  # Categorical, redundant with precipitation/visibility\n",
    "    'metar'  # Text format, unusable directly\n",
    "]\n",
    "\n",
    "# Combine both lists and ensure no duplicates\n",
    "columns_to_remove = list(set(bad_columns + irrelevant_features))\n",
    "df.drop(columns=columns_to_remove, inplace=True)\n",
    "\n",
    "# Update continuous columns to exclude removed columns\n",
    "continuous_cols = list(set(continuous_cols) - set(columns_to_remove))\n",
    "print(f\"Remaining continuous columns: {continuous_cols}\")\n",
    "\n",
    "\n",
    "# Apply linear interpolation within each station group using transform\n",
    "df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
    "    lambda group: group.interpolate(method='linear')\n",
    ")\n",
    "\n",
    "# Handle any remaining missing values with forward and backward fill using transform\n",
    "df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
    "    lambda group: group.ffill().bfill()\n",
    ")\n",
    "\n",
    "\n",
    "# Verify missing values are filled\n",
    "print(\"Missing values in continuous columns after processing:\")\n",
    "print(df[continuous_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22d77192-039b-4a7e-8e4b-f543ce63b026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114664, 10)\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Feature scaling\n",
    "# List of all features (excluding 'valid' and 'metar')\n",
    "feature_cols = continuous_cols #+ categorical_cols\n",
    "print(df[feature_cols].shape)\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "678bb536-b26d-4e1f-9521-baf8eaa878f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(114640, 24, 10)\n",
      "(114640, 10)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Prepare sequences for LSTM input\n",
    "# Assuming we are predicting 'tmpf' (temperature) as the target variable\n",
    "# and using previous 24 time steps/8 hours (n_steps_in) to predict the next time step/20 minutes from now (n_steps_out)\n",
    "# create sliding window sequences X: (114640, 24, 10), y: (114640, 10)\n",
    "\n",
    "n_steps_in = 24  # Number of past time steps\n",
    "n_steps_out = 1  # Number of future time steps to predict\n",
    "\n",
    "# We'll create sequences for each station separately\n",
    "def create_sequences(data, n_steps_in, n_steps_out):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - n_steps_in - n_steps_out + 1):\n",
    "        X.append(data[i:(i + n_steps_in), :])\n",
    "        y.append(data[(i + n_steps_in):(i + n_steps_in + n_steps_out), :])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare data for each station\n",
    "X_list = []\n",
    "y_list = []\n",
    "stations = df['station'].unique()\n",
    "\n",
    "for station in stations:\n",
    "    station_data = df[df['station'] == station]\n",
    "    station_data = station_data.reset_index(drop=True)\n",
    "    data_values = station_data[feature_cols].values\n",
    "    # target_col_index = feature_cols.index('tmpf')  # Index of target variable in features\n",
    "\n",
    "    X_station, y_station = create_sequences(data_values, n_steps_in, n_steps_out)\n",
    "    X_list.append(X_station)\n",
    "    y_list.append(y_station)\n",
    "\n",
    "\n",
    "# Concatenate data from all stations\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "\n",
    "if n_steps_out == 1:\n",
    "    y = y.squeeze(1)  # Shape becomes (num_samples, num_features) = (114640, 10) for JRB\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c60c4d2-3530-4638-baa3-d182686746da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 7: Split the data into training and testing sets\n",
    "# Since it's time-series data, we'll use the first 80% for training and the rest for testing\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Now the data is ready for training the LSTM model\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b82caf3-0b75-4599-80b7-ed39d935ad3f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:19604 (errno: 98 - Address already in use).\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:19604 (errno: 98 - Address already in use).\n",
      "[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:19604 (errno: 98 - Address already in use).\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to 0.0.0.0:19604 (errno: 98 - Address already in use).\n",
      "[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.\n",
      "W1202 17:22:41.099000 140562186750848 torch/multiprocessing/spawn.py:145] Terminating process 2124937 via signal SIGTERM\n",
      "W1202 17:22:41.100000 140562186750848 torch/multiprocessing/spawn.py:145] Terminating process 2124938 via signal SIGTERM\n",
      "W1202 17:22:41.101000 140562186750848 torch/multiprocessing/spawn.py:145] Terminating process 2124939 via signal SIGTERM\n"
     ]
    },
    {
     "ename": "ProcessRaisedException",
     "evalue": "\n\n-- Process 3 terminated with the following error:\nTraceback (most recent call last):\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 75, in _wrap\n    fn(i, *args)\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 943, in _run\n    self.strategy.setup_environment()\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/strategies/ddp.py\", line 154, in setup_environment\n    self.setup_distributed()\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/strategies/ddp.py\", line 203, in setup_distributed\n    _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/lightning_fabric/utilities/distributed.py\", line 291, in _init_dist_connection\n    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 75, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 89, in wrapper\n    func_return = func(*args, **kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 1305, in init_process_group\n    store, rank, world_size = next(rendezvous_iterator)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/rendezvous.py\", line 246, in _env_rendezvous_handler\n    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/rendezvous.py\", line 174, in _create_c10d_store\n    return TCPStore(\n           ^^^^^^^^^\ntorch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:19604 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:19604 (errno: 98 - Address already in use).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 53\u001b[0m\n\u001b[1;32m     44\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     45\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     46\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_callback]\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Optional: Evaluate on the test set\u001b[39;00m\n\u001b[1;32m     56\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtest(model, test_loader)\n",
      "File \u001b[0;32m/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:43\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py:144\u001b[0m, in \u001b[0;36m_MultiProcessingLauncher.launch\u001b[0;34m(self, function, trainer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m process_context \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mstart_processes(\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapping_function,\n\u001b[1;32m    138\u001b[0m     args\u001b[38;5;241m=\u001b[39mprocess_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     join\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# we will join ourselves to get the process references\u001b[39;00m\n\u001b[1;32m    142\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocs \u001b[38;5;241m=\u001b[39m process_context\u001b[38;5;241m.\u001b[39mprocesses\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mprocess_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    147\u001b[0m worker_output \u001b[38;5;241m=\u001b[39m return_queue\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/multiprocessing/spawn.py:188\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    186\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-- Process \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m terminated with the following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m error_index\n\u001b[1;32m    187\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 3 terminated with the following error:\nTraceback (most recent call last):\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/multiprocessing/spawn.py\", line 75, in _wrap\n    fn(i, *args)\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 580, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path)\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py\", line 943, in _run\n    self.strategy.setup_environment()\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/strategies/ddp.py\", line 154, in setup_environment\n    self.setup_distributed()\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/pytorch_lightning/strategies/ddp.py\", line 203, in setup_distributed\n    _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/lightning_fabric/utilities/distributed.py\", line 291, in _init_dist_connection\n    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 75, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/c10d_logger.py\", line 89, in wrapper\n    func_return = func(*args, **kwargs)\n                  ^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/distributed_c10d.py\", line 1305, in init_process_group\n    store, rank, world_size = next(rendezvous_iterator)\n                              ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/rendezvous.py\", line 246, in _env_rendezvous_handler\n    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout, use_libuv)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/global/common/software/nersc9/pytorch/2.3.1/lib/python3.11/site-packages/torch/distributed/rendezvous.py\", line 174, in _create_c10d_store\n    return TCPStore(\n           ^^^^^^^^^\ntorch.distributed.DistNetworkError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:19604 (errno: 98 - Address already in use). The server socket has failed to bind to 0.0.0.0:19604 (errno: 98 - Address already in use).\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = WeatherDataset(X_train, y_train)\n",
    "test_dataset = WeatherDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hyperparameters for SegRNN\n",
    "input_size = X.shape[2]  # Number of features\n",
    "hidden_size = 512  # Based on the SEGRNN paper\n",
    "output_size = X.shape[2]  # Predict all features\n",
    "segment_length = 8  # Based on the SEGRNN paper\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize SegRNNModel\n",
    "model = SegRNNModel(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    "    segment_length=segment_length,\n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger(\"logs\", name=\"segrnn_experiment\")\n",
    "\n",
    "# Checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=\"segrnn-{epoch:02d}-{val_loss:.4f}\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Trainer with logging and checkpointing\n",
    "trainer = Trainer(\n",
    "    max_epochs=100,\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=4,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader)\n",
    "\n",
    "# Optional: Evaluate on the test set\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726626c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nersc_tensorboard_helper\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cfff12-bed5-4ab6-abdb-732fd095a395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c768ac4e-11a1-439d-8087-be85e6a6500b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list() # View open TensorBoard instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddda39-1d2b-4bb4-9d83-b538f426112c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nersc_tensorboard_helper.tb_address()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.3.1",
   "language": "python",
   "name": "pytorch-2.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
