{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from segrnn import SegRNNModel\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from utils import preprocess_and_save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                    1\n",
      "dwpf                    1\n",
      "relh                    1\n",
      "feel                    2\n",
      "drct                  132\n",
      "sknt                    3\n",
      "gust                 8162\n",
      "peak_wind_gust       9053\n",
      "peak_wind_drct       9053\n",
      "alti                    0\n",
      "mslp                 1907\n",
      "vsby                    0\n",
      "p01i                 1739\n",
      "ice_accretion_1hr    9886\n",
      "ice_accretion_3hr    9890\n",
      "ice_accretion_6hr    9886\n",
      "skyl1                 723\n",
      "skyl2                4099\n",
      "skyl3                6972\n",
      "skyl4                9526\n",
      "snowdepth            9774\n",
      "peak_wind_time       9892\n",
      "dtype: int64\n",
      "nan thresh is 4946.0\n",
      "bad columns are ['gust', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['p01i', 'drct', 'alti', 'relh', 'feel', 'dwpf', 'sknt', 'mslp', 'vsby', 'tmpf']\n",
      "Missing values in continuous columns after processing:\n",
      "p01i    0\n",
      "drct    0\n",
      "alti    0\n",
      "relh    0\n",
      "feel    0\n",
      "dwpf    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "vsby    0\n",
      "tmpf    0\n",
      "dtype: int64\n",
      "(9892, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\ROC_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                  158\n",
      "dwpf                  185\n",
      "relh                  185\n",
      "feel                  185\n",
      "drct                 2076\n",
      "sknt                   77\n",
      "gust                 8500\n",
      "peak_wind_gust       8819\n",
      "peak_wind_drct       8819\n",
      "alti                    4\n",
      "mslp                 1937\n",
      "vsby                    5\n",
      "p01i                    0\n",
      "ice_accretion_1hr    9699\n",
      "ice_accretion_3hr    9699\n",
      "ice_accretion_6hr    9699\n",
      "skyl1                4189\n",
      "skyl2                7621\n",
      "skyl3                8931\n",
      "skyl4                9699\n",
      "snowdepth            9699\n",
      "peak_wind_time       9699\n",
      "dtype: int64\n",
      "nan thresh is 4849.5\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['p01i', 'drct', 'alti', 'relh', 'feel', 'dwpf', 'sknt', 'mslp', 'vsby', 'tmpf']\n",
      "Missing values in continuous columns after processing:\n",
      "p01i    0\n",
      "drct    0\n",
      "alti    0\n",
      "relh    0\n",
      "feel    0\n",
      "dwpf    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "vsby    0\n",
      "tmpf    0\n",
      "dtype: int64\n",
      "(9699, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\JRB_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                    17\n",
      "dwpf                    17\n",
      "relh                    17\n",
      "feel                    21\n",
      "drct                   294\n",
      "sknt                    49\n",
      "gust                  9340\n",
      "peak_wind_gust       10857\n",
      "peak_wind_drct       10857\n",
      "alti                     1\n",
      "mslp                  3709\n",
      "vsby                    19\n",
      "p01i                  1628\n",
      "ice_accretion_1hr    11542\n",
      "ice_accretion_3hr    11575\n",
      "ice_accretion_6hr    11574\n",
      "skyl1                 3157\n",
      "skyl2                 7148\n",
      "skyl3                 9487\n",
      "skyl4                11580\n",
      "snowdepth            11580\n",
      "peak_wind_time       11580\n",
      "dtype: int64\n",
      "nan thresh is 5790.0\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['p01i', 'drct', 'alti', 'relh', 'feel', 'dwpf', 'sknt', 'mslp', 'vsby', 'tmpf']\n",
      "Missing values in continuous columns after processing:\n",
      "p01i    0\n",
      "drct    0\n",
      "alti    0\n",
      "relh    0\n",
      "feel    0\n",
      "dwpf    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "vsby    0\n",
      "tmpf    0\n",
      "dtype: int64\n",
      "(11580, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\BGM_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                     1\n",
      "dwpf                     1\n",
      "relh                     1\n",
      "feel                    16\n",
      "drct                   714\n",
      "sknt                    49\n",
      "gust                  8960\n",
      "peak_wind_gust       10299\n",
      "peak_wind_drct       10299\n",
      "alti                     0\n",
      "mslp                  2995\n",
      "vsby                     2\n",
      "p01i                  1782\n",
      "ice_accretion_1hr    10941\n",
      "ice_accretion_3hr    10951\n",
      "ice_accretion_6hr    10950\n",
      "skyl1                 3412\n",
      "skyl2                 7151\n",
      "skyl3                 9214\n",
      "skyl4                10953\n",
      "snowdepth            10953\n",
      "peak_wind_time       10953\n",
      "dtype: int64\n",
      "nan thresh is 5476.5\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['p01i', 'drct', 'alti', 'relh', 'feel', 'dwpf', 'sknt', 'mslp', 'vsby', 'tmpf']\n",
      "Missing values in continuous columns after processing:\n",
      "p01i    0\n",
      "drct    0\n",
      "alti    0\n",
      "relh    0\n",
      "feel    0\n",
      "dwpf    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "vsby    0\n",
      "tmpf    0\n",
      "dtype: int64\n",
      "(10953, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\PEO_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                     0\n",
      "dwpf                     0\n",
      "relh                     0\n",
      "feel                     1\n",
      "drct                   272\n",
      "sknt                    17\n",
      "gust                  9605\n",
      "peak_wind_gust       10334\n",
      "peak_wind_drct       10334\n",
      "alti                     0\n",
      "mslp                  2916\n",
      "vsby                     3\n",
      "p01i                  1374\n",
      "ice_accretion_1hr    10841\n",
      "ice_accretion_3hr    10843\n",
      "ice_accretion_6hr    10841\n",
      "skyl1                 3226\n",
      "skyl2                 6727\n",
      "skyl3                 8968\n",
      "skyl4                10844\n",
      "snowdepth            10844\n",
      "peak_wind_time       10844\n",
      "dtype: int64\n",
      "nan thresh is 5422.0\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['p01i', 'drct', 'alti', 'relh', 'feel', 'dwpf', 'sknt', 'mslp', 'vsby', 'tmpf']\n",
      "Missing values in continuous columns after processing:\n",
      "p01i    0\n",
      "drct    0\n",
      "alti    0\n",
      "relh    0\n",
      "feel    0\n",
      "dwpf    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "vsby    0\n",
      "tmpf    0\n",
      "dtype: int64\n",
      "(10844, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\RME_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:68: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "tmpf                     2\n",
      "dwpf                    40\n",
      "relh                    40\n",
      "feel                    46\n",
      "drct                   182\n",
      "sknt                    39\n",
      "gust                  9526\n",
      "peak_wind_gust       10533\n",
      "peak_wind_drct       10533\n",
      "alti                     0\n",
      "mslp                  3289\n",
      "vsby                     2\n",
      "p01i                  1748\n",
      "ice_accretion_1hr    11114\n",
      "ice_accretion_3hr    11196\n",
      "ice_accretion_6hr    11185\n",
      "skyl1                 3700\n",
      "skyl2                 7756\n",
      "skyl3                 9777\n",
      "skyl4                11205\n",
      "snowdepth            11205\n",
      "peak_wind_time       11205\n",
      "dtype: int64\n",
      "nan thresh is 5602.5\n",
      "bad columns are ['gust', 'skyl2', 'skyl3', 'skyl4', 'ice_accretion_1hr', 'ice_accretion_3hr', 'ice_accretion_6hr', 'peak_wind_gust', 'peak_wind_drct', 'peak_wind_time', 'snowdepth']\n",
      "10 remaining continuous columns: ['p01i', 'drct', 'alti', 'relh', 'feel', 'dwpf', 'sknt', 'mslp', 'vsby', 'tmpf']\n",
      "Missing values in continuous columns after processing:\n",
      "p01i    0\n",
      "drct    0\n",
      "alti    0\n",
      "relh    0\n",
      "feel    0\n",
      "dwpf    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "vsby    0\n",
      "tmpf    0\n",
      "dtype: int64\n",
      "(11205, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\MSS_processed.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['p01i',\n",
       " 'drct',\n",
       " 'alti',\n",
       " 'relh',\n",
       " 'feel',\n",
       " 'dwpf',\n",
       " 'sknt',\n",
       " 'mslp',\n",
       " 'vsby',\n",
       " 'tmpf']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_and_save_data('./csvs/ROC.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/JRB.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/BGM.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/PEO.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/RME.csv', normalize=True)\n",
    "preprocess_and_save_data('./csvs/MSS.csv', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stid</th>\n",
       "      <th>station_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elev</th>\n",
       "      <th>begints</th>\n",
       "      <th>endts</th>\n",
       "      <th>iem_network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6B9</td>\n",
       "      <td>Skaneateles</td>\n",
       "      <td>42.9140</td>\n",
       "      <td>-76.4408</td>\n",
       "      <td>304.324520</td>\n",
       "      <td>2016-07-22 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALB</td>\n",
       "      <td>ALBANY COUNTY ARPT</td>\n",
       "      <td>42.7576</td>\n",
       "      <td>-73.8036</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1945-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ART</td>\n",
       "      <td>WATERTOWN INTL ARPT</td>\n",
       "      <td>43.9888</td>\n",
       "      <td>-76.0262</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1949-04-30 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BGM</td>\n",
       "      <td>BINGHAMTON/BROOME</td>\n",
       "      <td>42.2086</td>\n",
       "      <td>-75.9797</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>1948-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUF</td>\n",
       "      <td>BUFFALO INTL ARPT</td>\n",
       "      <td>42.9408</td>\n",
       "      <td>-78.7358</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>1942-01-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DKK</td>\n",
       "      <td>DUNKIRK AIRPORT</td>\n",
       "      <td>42.4933</td>\n",
       "      <td>-79.2720</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DSV</td>\n",
       "      <td>DANSVILLE MUNICIPAL</td>\n",
       "      <td>42.5709</td>\n",
       "      <td>-77.7130</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELM</td>\n",
       "      <td>Elmira / Corning</td>\n",
       "      <td>42.1571</td>\n",
       "      <td>-76.8994</td>\n",
       "      <td>287.125370</td>\n",
       "      <td>1949-02-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ELZ</td>\n",
       "      <td>Wellsville Municipal</td>\n",
       "      <td>42.1078</td>\n",
       "      <td>-77.9842</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>1978-06-13 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FOK</td>\n",
       "      <td>WESTHAMPTON BEACH</td>\n",
       "      <td>40.8436</td>\n",
       "      <td>-72.6318</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1943-07-18 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRG</td>\n",
       "      <td>FARMINGDALE/REPUBLC</td>\n",
       "      <td>40.7288</td>\n",
       "      <td>-73.4134</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1943-04-12 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FZY</td>\n",
       "      <td>Oswego County</td>\n",
       "      <td>43.3504</td>\n",
       "      <td>-76.3831</td>\n",
       "      <td>141.826460</td>\n",
       "      <td>1997-05-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GFL</td>\n",
       "      <td>GLEN FALLS/WARREN</td>\n",
       "      <td>43.3412</td>\n",
       "      <td>-73.6103</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1949-01-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GTB</td>\n",
       "      <td>FORT DRUM/WHEELER</td>\n",
       "      <td>44.0556</td>\n",
       "      <td>-75.7195</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>1942-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GVQ</td>\n",
       "      <td>Batavia</td>\n",
       "      <td>43.0317</td>\n",
       "      <td>-78.1675</td>\n",
       "      <td>275.450840</td>\n",
       "      <td>2009-06-28 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HPN</td>\n",
       "      <td>WHITE PLAINS</td>\n",
       "      <td>41.0669</td>\n",
       "      <td>-73.7075</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HTO</td>\n",
       "      <td>EAST HAMPTON</td>\n",
       "      <td>40.9600</td>\n",
       "      <td>-72.2500</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2000-01-07 00:00</td>\n",
       "      <td>2022-03-02 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HWV</td>\n",
       "      <td>BROOKHAVEN AIRPORT/SHIRLEY</td>\n",
       "      <td>40.8217</td>\n",
       "      <td>-72.8689</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1999-09-30 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IAG</td>\n",
       "      <td>NIAGARA FALLS INTL</td>\n",
       "      <td>43.1073</td>\n",
       "      <td>-78.9462</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1951-06-12 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ISP</td>\n",
       "      <td>ISLIP/MACARTHUR</td>\n",
       "      <td>40.7939</td>\n",
       "      <td>-73.1017</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1972-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ITH</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>42.4910</td>\n",
       "      <td>-76.4584</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1972-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IUA</td>\n",
       "      <td>Canandaigua</td>\n",
       "      <td>42.9089</td>\n",
       "      <td>-77.3252</td>\n",
       "      <td>244.597890</td>\n",
       "      <td>2021-10-14 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JFK</td>\n",
       "      <td>NEW YORK/JF KENNEDY</td>\n",
       "      <td>40.6386</td>\n",
       "      <td>-73.7622</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1948-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JHW</td>\n",
       "      <td>JAMESTOWN (AWOS)</td>\n",
       "      <td>42.1534</td>\n",
       "      <td>-79.2580</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>1972-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JPX</td>\n",
       "      <td>East Hampton</td>\n",
       "      <td>40.9594</td>\n",
       "      <td>-72.2517</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1996-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JRB</td>\n",
       "      <td>Manhattan - Wall Street</td>\n",
       "      <td>40.7012</td>\n",
       "      <td>-74.0090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016-07-21 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LGA</td>\n",
       "      <td>New York/LaGuardia</td>\n",
       "      <td>40.7794</td>\n",
       "      <td>-73.8803</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1948-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MGJ</td>\n",
       "      <td>ORANGE COUNTY AIRPORT</td>\n",
       "      <td>41.5092</td>\n",
       "      <td>-74.2650</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>1997-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MSS</td>\n",
       "      <td>MASSENA/RICHARDS</td>\n",
       "      <td>44.9358</td>\n",
       "      <td>-74.8456</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1949-02-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MSV</td>\n",
       "      <td>MONTICELLO(AWOS)</td>\n",
       "      <td>41.7016</td>\n",
       "      <td>-74.7950</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>1981-02-12 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MTP</td>\n",
       "      <td>MONTAUK AIRPORT</td>\n",
       "      <td>41.0731</td>\n",
       "      <td>-71.9233</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1975-10-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>N03</td>\n",
       "      <td>Cortland</td>\n",
       "      <td>42.5929</td>\n",
       "      <td>-76.2174</td>\n",
       "      <td>356.635200</td>\n",
       "      <td>2013-10-24 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NY0</td>\n",
       "      <td>Johnstown</td>\n",
       "      <td>42.9982</td>\n",
       "      <td>-74.3296</td>\n",
       "      <td>263.009900</td>\n",
       "      <td>2014-08-20 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NEW YORK CITY</td>\n",
       "      <td>40.7790</td>\n",
       "      <td>-73.9692</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1943-12-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>OGS</td>\n",
       "      <td>OGDENSBURG INTL</td>\n",
       "      <td>44.6819</td>\n",
       "      <td>-75.4655</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1977-05-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OIC</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>42.5666</td>\n",
       "      <td>-75.5241</td>\n",
       "      <td>306.802000</td>\n",
       "      <td>2007-12-17 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OLE</td>\n",
       "      <td>Olean</td>\n",
       "      <td>42.2412</td>\n",
       "      <td>-78.3714</td>\n",
       "      <td>649.319760</td>\n",
       "      <td>1987-08-13 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PBG</td>\n",
       "      <td>Plattsburgh AFB</td>\n",
       "      <td>44.6382</td>\n",
       "      <td>-73.4624</td>\n",
       "      <td>46.954082</td>\n",
       "      <td>1956-01-14 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PEO</td>\n",
       "      <td>Penn Yan</td>\n",
       "      <td>42.6441</td>\n",
       "      <td>-77.0529</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>1997-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PLB</td>\n",
       "      <td>PLATTSBURGH/CLINTON</td>\n",
       "      <td>44.6875</td>\n",
       "      <td>-73.5245</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1978-08-22 00:00</td>\n",
       "      <td>2007-05-22 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>POU</td>\n",
       "      <td>POUGHKEEPSIE</td>\n",
       "      <td>41.6266</td>\n",
       "      <td>-73.8842</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PTD</td>\n",
       "      <td>Potsdam</td>\n",
       "      <td>44.6757</td>\n",
       "      <td>-74.9469</td>\n",
       "      <td>140.470340</td>\n",
       "      <td>2018-02-03 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RME</td>\n",
       "      <td>Griffiss AFB / Rome</td>\n",
       "      <td>43.2239</td>\n",
       "      <td>-75.3953</td>\n",
       "      <td>143.616610</td>\n",
       "      <td>1942-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ROC</td>\n",
       "      <td>ROCHESTER/MONROE CO</td>\n",
       "      <td>43.1167</td>\n",
       "      <td>-77.6767</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>1948-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SCH</td>\n",
       "      <td>SCHENECTADY AIRPORT</td>\n",
       "      <td>42.8500</td>\n",
       "      <td>-73.9300</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1950-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SDC</td>\n",
       "      <td>Williamson</td>\n",
       "      <td>43.2346</td>\n",
       "      <td>-77.1195</td>\n",
       "      <td>127.863280</td>\n",
       "      <td>2017-12-08 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SLK</td>\n",
       "      <td>SARANAC LAKE/ADIRON</td>\n",
       "      <td>44.3853</td>\n",
       "      <td>-74.2062</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>1973-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SWF</td>\n",
       "      <td>NEWBURGH/STEWART</td>\n",
       "      <td>41.5041</td>\n",
       "      <td>-74.1048</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>1942-08-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SYR</td>\n",
       "      <td>SYRACUSE/HANCOCK</td>\n",
       "      <td>43.1112</td>\n",
       "      <td>-76.1063</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1942-10-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UCA</td>\n",
       "      <td>UTICA/ONEIDA CO.</td>\n",
       "      <td>43.1451</td>\n",
       "      <td>-75.3839</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>1947-12-31 00:00</td>\n",
       "      <td>2010-12-31 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>VGC</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>42.8434</td>\n",
       "      <td>-75.5612</td>\n",
       "      <td>342.825680</td>\n",
       "      <td>2020-08-06 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>XNT</td>\n",
       "      <td>Springville - Bertrand Chaffee</td>\n",
       "      <td>42.5084</td>\n",
       "      <td>-78.6581</td>\n",
       "      <td>423.819000</td>\n",
       "      <td>2016-08-24 00:00</td>\n",
       "      <td>2017-07-05 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stid                    station_name      lat      lon        elev  \\\n",
       "0   6B9                     Skaneateles  42.9140 -76.4408  304.324520   \n",
       "1   ALB              ALBANY COUNTY ARPT  42.7576 -73.8036   89.000000   \n",
       "2   ART             WATERTOWN INTL ARPT  43.9888 -76.0262   99.000000   \n",
       "3   BGM               BINGHAMTON/BROOME  42.2086 -75.9797  497.000000   \n",
       "4   BUF               BUFFALO INTL ARPT  42.9408 -78.7358  215.000000   \n",
       "5   DKK                 DUNKIRK AIRPORT  42.4933 -79.2720  203.000000   \n",
       "6   DSV             DANSVILLE MUNICIPAL  42.5709 -77.7130  209.000000   \n",
       "7   ELM                Elmira / Corning  42.1571 -76.8994  287.125370   \n",
       "8   ELZ            Wellsville Municipal  42.1078 -77.9842  639.000000   \n",
       "9   FOK               WESTHAMPTON BEACH  40.8436 -72.6318   20.000000   \n",
       "10  FRG             FARMINGDALE/REPUBLC  40.7288 -73.4134   25.000000   \n",
       "11  FZY                   Oswego County  43.3504 -76.3831  141.826460   \n",
       "12  GFL               GLEN FALLS/WARREN  43.3412 -73.6103  100.000000   \n",
       "13  GTB               FORT DRUM/WHEELER  44.0556 -75.7195  207.000000   \n",
       "14  GVQ                         Batavia  43.0317 -78.1675  275.450840   \n",
       "15  HPN                    WHITE PLAINS  41.0669 -73.7075  134.000000   \n",
       "16  HTO                    EAST HAMPTON  40.9600 -72.2500   17.000000   \n",
       "17  HWV      BROOKHAVEN AIRPORT/SHIRLEY  40.8217 -72.8689   25.000000   \n",
       "18  IAG              NIAGARA FALLS INTL  43.1073 -78.9462  180.000000   \n",
       "19  ISP                 ISLIP/MACARTHUR  40.7939 -73.1017   30.000000   \n",
       "20  ITH                          Ithaca  42.4910 -76.4584  335.000000   \n",
       "21  IUA                     Canandaigua  42.9089 -77.3252  244.597890   \n",
       "22  JFK             NEW YORK/JF KENNEDY  40.6386 -73.7622    7.000000   \n",
       "23  JHW                JAMESTOWN (AWOS)  42.1534 -79.2580  525.000000   \n",
       "24  JPX                    East Hampton  40.9594 -72.2517   11.000000   \n",
       "25  JRB         Manhattan - Wall Street  40.7012 -74.0090    0.000000   \n",
       "26  LGA              New York/LaGuardia  40.7794 -73.8803    9.000000   \n",
       "27  MGJ           ORANGE COUNTY AIRPORT  41.5092 -74.2650  111.000000   \n",
       "28  MSS                MASSENA/RICHARDS  44.9358 -74.8456   65.000000   \n",
       "29  MSV                MONTICELLO(AWOS)  41.7016 -74.7950  428.000000   \n",
       "30  MTP                 MONTAUK AIRPORT  41.0731 -71.9233    6.000000   \n",
       "31  N03                        Cortland  42.5929 -76.2174  356.635200   \n",
       "32  NY0                       Johnstown  42.9982 -74.3296  263.009900   \n",
       "33  NYC                   NEW YORK CITY  40.7790 -73.9692   27.000000   \n",
       "34  OGS                 OGDENSBURG INTL  44.6819 -75.4655   91.000000   \n",
       "35  OIC                         Norwich  42.5666 -75.5241  306.802000   \n",
       "36  OLE                           Olean  42.2412 -78.3714  649.319760   \n",
       "37  PBG                 Plattsburgh AFB  44.6382 -73.4624   46.954082   \n",
       "38  PEO                        Penn Yan  42.6441 -77.0529  267.000000   \n",
       "39  PLB             PLATTSBURGH/CLINTON  44.6875 -73.5245  113.000000   \n",
       "40  POU                    POUGHKEEPSIE  41.6266 -73.8842   51.000000   \n",
       "41  PTD                         Potsdam  44.6757 -74.9469  140.470340   \n",
       "42  RME             Griffiss AFB / Rome  43.2239 -75.3953  143.616610   \n",
       "43  ROC             ROCHESTER/MONROE CO  43.1167 -77.6767  169.000000   \n",
       "44  SCH             SCHENECTADY AIRPORT  42.8500 -73.9300  115.000000   \n",
       "45  SDC                      Williamson  43.2346 -77.1195  127.863280   \n",
       "46  SLK             SARANAC LAKE/ADIRON  44.3853 -74.2062  507.000000   \n",
       "47  SWF                NEWBURGH/STEWART  41.5041 -74.1048  150.000000   \n",
       "48  SYR                SYRACUSE/HANCOCK  43.1112 -76.1063  124.000000   \n",
       "49  UCA                UTICA/ONEIDA CO.  43.1451 -75.3839  226.000000   \n",
       "50  VGC                        Hamilton  42.8434 -75.5612  342.825680   \n",
       "51  XNT  Springville - Bertrand Chaffee  42.5084 -78.6581  423.819000   \n",
       "\n",
       "             begints             endts iem_network  \n",
       "0   2016-07-22 00:00               NaN     NY_ASOS  \n",
       "1   1945-01-01 00:00               NaN     NY_ASOS  \n",
       "2   1949-04-30 00:00               NaN     NY_ASOS  \n",
       "3   1948-01-01 00:00               NaN     NY_ASOS  \n",
       "4   1942-01-31 00:00               NaN     NY_ASOS  \n",
       "5   1948-12-31 00:00               NaN     NY_ASOS  \n",
       "6   1948-12-31 00:00               NaN     NY_ASOS  \n",
       "7   1949-02-01 00:00               NaN     NY_ASOS  \n",
       "8   1978-06-13 00:00               NaN     NY_ASOS  \n",
       "9   1943-07-18 00:00               NaN     NY_ASOS  \n",
       "10  1943-04-12 00:00               NaN     NY_ASOS  \n",
       "11  1997-05-31 00:00               NaN     NY_ASOS  \n",
       "12  1949-01-31 00:00               NaN     NY_ASOS  \n",
       "13  1942-01-01 00:00               NaN     NY_ASOS  \n",
       "14  2009-06-28 00:00               NaN     NY_ASOS  \n",
       "15  1948-12-31 00:00               NaN     NY_ASOS  \n",
       "16  2000-01-07 00:00  2022-03-02 00:00     NY_ASOS  \n",
       "17  1999-09-30 00:00               NaN     NY_ASOS  \n",
       "18  1951-06-12 00:00               NaN     NY_ASOS  \n",
       "19  1972-12-31 00:00               NaN     NY_ASOS  \n",
       "20  1972-12-31 00:00               NaN     NY_ASOS  \n",
       "21  2021-10-14 00:00               NaN     NY_ASOS  \n",
       "22  1948-07-01 00:00               NaN     NY_ASOS  \n",
       "23  1972-12-31 00:00               NaN     NY_ASOS  \n",
       "24  1996-07-01 00:00               NaN     NY_ASOS  \n",
       "25  2016-07-21 00:00               NaN     NY_ASOS  \n",
       "26  1948-07-01 00:00               NaN     NY_ASOS  \n",
       "27  1997-12-31 00:00               NaN     NY_ASOS  \n",
       "28  1949-02-01 00:00               NaN     NY_ASOS  \n",
       "29  1981-02-12 00:00               NaN     NY_ASOS  \n",
       "30  1975-10-01 00:00               NaN     NY_ASOS  \n",
       "31  2013-10-24 00:00               NaN     NY_ASOS  \n",
       "32  2014-08-20 00:00               NaN     NY_ASOS  \n",
       "33  1943-12-01 00:00               NaN     NY_ASOS  \n",
       "34  1977-05-01 00:00               NaN     NY_ASOS  \n",
       "35  2007-12-17 00:00               NaN     NY_ASOS  \n",
       "36  1987-08-13 00:00               NaN     NY_ASOS  \n",
       "37  1956-01-14 00:00               NaN     NY_ASOS  \n",
       "38  1997-12-31 00:00               NaN     NY_ASOS  \n",
       "39  1978-08-22 00:00  2007-05-22 00:00     NY_ASOS  \n",
       "40  1948-12-31 00:00               NaN     NY_ASOS  \n",
       "41  2018-02-03 00:00               NaN     NY_ASOS  \n",
       "42  1942-07-01 00:00               NaN     NY_ASOS  \n",
       "43  1948-01-01 00:00               NaN     NY_ASOS  \n",
       "44  1950-01-01 00:00               NaN     NY_ASOS  \n",
       "45  2017-12-08 00:00               NaN     NY_ASOS  \n",
       "46  1973-01-01 00:00               NaN     NY_ASOS  \n",
       "47  1942-08-01 00:00               NaN     NY_ASOS  \n",
       "48  1942-10-01 00:00               NaN     NY_ASOS  \n",
       "49  1947-12-31 00:00  2010-12-31 00:00     NY_ASOS  \n",
       "50  2020-08-06 00:00               NaN     NY_ASOS  \n",
       "51  2016-08-24 00:00  2017-07-05 00:00     NY_ASOS  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nylocations = './csvs/_nylocations.csv'\n",
    "latlongs = pd.read_csv(nylocations)\n",
    "latlongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>dwpf</th>\n",
       "      <th>relh</th>\n",
       "      <th>drct</th>\n",
       "      <th>sknt</th>\n",
       "      <th>p01i</th>\n",
       "      <th>alti</th>\n",
       "      <th>mslp</th>\n",
       "      <th>vsby</th>\n",
       "      <th>feel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-01-01 00:11:00</td>\n",
       "      <td>-1.187030</td>\n",
       "      <td>-0.927562</td>\n",
       "      <td>0.803586</td>\n",
       "      <td>-0.980217</td>\n",
       "      <td>-0.300193</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>0.087353</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.143572</td>\n",
       "      <td>-1.168495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-01-01 00:54:00</td>\n",
       "      <td>-1.187030</td>\n",
       "      <td>-0.927562</td>\n",
       "      <td>0.803586</td>\n",
       "      <td>-0.980217</td>\n",
       "      <td>-0.086351</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>0.087353</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.143572</td>\n",
       "      <td>-1.204129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-01-01 01:54:00</td>\n",
       "      <td>-1.130031</td>\n",
       "      <td>-0.927562</td>\n",
       "      <td>0.590945</td>\n",
       "      <td>-1.074090</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>0.087353</td>\n",
       "      <td>0.168066</td>\n",
       "      <td>0.143572</td>\n",
       "      <td>-1.023110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-01-01 02:54:00</td>\n",
       "      <td>-1.187030</td>\n",
       "      <td>-0.927562</td>\n",
       "      <td>0.803586</td>\n",
       "      <td>-0.980217</td>\n",
       "      <td>-0.727875</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>0.087353</td>\n",
       "      <td>0.180937</td>\n",
       "      <td>-1.944840</td>\n",
       "      <td>-1.078698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-01-01 03:04:00</td>\n",
       "      <td>-1.187030</td>\n",
       "      <td>-0.927562</td>\n",
       "      <td>0.803586</td>\n",
       "      <td>-1.074090</td>\n",
       "      <td>-0.514034</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>0.131318</td>\n",
       "      <td>0.180937</td>\n",
       "      <td>-2.292908</td>\n",
       "      <td>-1.127160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9887</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 19:54:00</td>\n",
       "      <td>-0.788042</td>\n",
       "      <td>-0.505809</td>\n",
       "      <td>0.831515</td>\n",
       "      <td>1.178877</td>\n",
       "      <td>0.341331</td>\n",
       "      <td>-0.008612</td>\n",
       "      <td>-1.143678</td>\n",
       "      <td>-1.119017</td>\n",
       "      <td>0.491640</td>\n",
       "      <td>-0.850642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 20:54:00</td>\n",
       "      <td>-0.788042</td>\n",
       "      <td>-0.505809</td>\n",
       "      <td>0.831515</td>\n",
       "      <td>1.085004</td>\n",
       "      <td>-0.514034</td>\n",
       "      <td>-0.115499</td>\n",
       "      <td>-1.011782</td>\n",
       "      <td>-0.977438</td>\n",
       "      <td>0.491640</td>\n",
       "      <td>-0.732338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 21:54:00</td>\n",
       "      <td>-0.845040</td>\n",
       "      <td>-0.566059</td>\n",
       "      <td>0.827072</td>\n",
       "      <td>0.615635</td>\n",
       "      <td>-0.300193</td>\n",
       "      <td>-0.222385</td>\n",
       "      <td>-0.879886</td>\n",
       "      <td>-0.822988</td>\n",
       "      <td>0.491640</td>\n",
       "      <td>-0.824986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9890</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 22:54:00</td>\n",
       "      <td>-0.845040</td>\n",
       "      <td>-0.566059</td>\n",
       "      <td>0.827072</td>\n",
       "      <td>0.427888</td>\n",
       "      <td>-0.086351</td>\n",
       "      <td>-0.222385</td>\n",
       "      <td>-0.791955</td>\n",
       "      <td>-0.758634</td>\n",
       "      <td>0.491640</td>\n",
       "      <td>-0.856819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9891</th>\n",
       "      <td>ROC</td>\n",
       "      <td>2024-11-28 23:54:00</td>\n",
       "      <td>-0.845040</td>\n",
       "      <td>-0.686560</td>\n",
       "      <td>0.409407</td>\n",
       "      <td>0.521762</td>\n",
       "      <td>0.127490</td>\n",
       "      <td>-0.222385</td>\n",
       "      <td>-0.791955</td>\n",
       "      <td>-0.732892</td>\n",
       "      <td>0.491640</td>\n",
       "      <td>-0.884851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9892 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     station                valid      tmpf      dwpf      relh      drct  \\\n",
       "0        ROC  2024-01-01 00:11:00 -1.187030 -0.927562  0.803586 -0.980217   \n",
       "1        ROC  2024-01-01 00:54:00 -1.187030 -0.927562  0.803586 -0.980217   \n",
       "2        ROC  2024-01-01 01:54:00 -1.130031 -0.927562  0.590945 -1.074090   \n",
       "3        ROC  2024-01-01 02:54:00 -1.187030 -0.927562  0.803586 -0.980217   \n",
       "4        ROC  2024-01-01 03:04:00 -1.187030 -0.927562  0.803586 -1.074090   \n",
       "...      ...                  ...       ...       ...       ...       ...   \n",
       "9887     ROC  2024-11-28 19:54:00 -0.788042 -0.505809  0.831515  1.178877   \n",
       "9888     ROC  2024-11-28 20:54:00 -0.788042 -0.505809  0.831515  1.085004   \n",
       "9889     ROC  2024-11-28 21:54:00 -0.845040 -0.566059  0.827072  0.615635   \n",
       "9890     ROC  2024-11-28 22:54:00 -0.845040 -0.566059  0.827072  0.427888   \n",
       "9891     ROC  2024-11-28 23:54:00 -0.845040 -0.686560  0.409407  0.521762   \n",
       "\n",
       "          sknt      p01i      alti      mslp      vsby      feel  \n",
       "0    -0.300193 -0.008612  0.087353  0.155196  0.143572 -1.168495  \n",
       "1    -0.086351 -0.008612  0.087353  0.155196  0.143572 -1.204129  \n",
       "2    -0.727875 -0.008612  0.087353  0.168066  0.143572 -1.023110  \n",
       "3    -0.727875 -0.008612  0.087353  0.180937 -1.944840 -1.078698  \n",
       "4    -0.514034 -0.008612  0.131318  0.180937 -2.292908 -1.127160  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "9887  0.341331 -0.008612 -1.143678 -1.119017  0.491640 -0.850642  \n",
       "9888 -0.514034 -0.115499 -1.011782 -0.977438  0.491640 -0.732338  \n",
       "9889 -0.300193 -0.222385 -0.879886 -0.822988  0.491640 -0.824986  \n",
       "9890 -0.086351 -0.222385 -0.791955 -0.758634  0.491640 -0.856819  \n",
       "9891  0.127490 -0.222385 -0.791955 -0.732892  0.491640 -0.884851  \n",
       "\n",
       "[9892 rows x 12 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc = './csvs/ROC_processed.csv'\n",
    "roc_p = pd.read_csv(roc)\n",
    "roc_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BGM': {'lat': 42.2086, 'lon': -75.9797}, 'JRB': {'lat': 40.7012, 'lon': -74.009}, 'MSS': {'lat': 44.9358, 'lon': -74.8456}, 'PEO': {'lat': 42.6441, 'lon': -77.0529}, 'RME': {'lat': 43.2239, 'lon': -75.3953}, 'ROC': {'lat': 43.1167, 'lon': -77.6767}}\n",
      "{'JRB': './csvs/JRB_processed.csv', 'ROC': './csvs/ROC_processed.csv', 'BGM': './csvs/BGM_processed.csv', 'MSS': './csvs/MSS_processed.csv', 'PEO': './csvs/PEO_processed.csv', 'RME': './csvs/RME_processed.csv'}\n",
      "latlong is tensor([0.7261, 0.2944])\n",
      "latlong is tensor([0.7395, 0.2842])\n",
      "latlong is tensor([0.7345, 0.2889])\n",
      "latlong is tensor([0.7496, 0.2921])\n",
      "latlong is tensor([0.7369, 0.2860])\n",
      "latlong is tensor([0.7401, 0.2906])\n",
      "n latlongs: [[0.7261177777777778, 0.29441944444444446], [0.7395372222222223, 0.2842313888888889], [0.7344922222222222, 0.2889452777777778], [0.7496433333333333, 0.29209555555555555], [0.7369116666666667, 0.2859641666666667], [0.7401327777777779, 0.2905686111111111]]\n",
      "torch.Size([6, 12])\n",
      "tensor([[ 2.6720e-03,  1.4051e-02,  4.1073e-04, -1.5940e-02, -1.1278e-02,\n",
      "          1.2260e-02,  9.5479e-03, -6.2468e-03,  9.2966e-03, -1.5987e-02,\n",
      "          7.3745e-01,  2.9870e-01],\n",
      "        [ 1.2554e-02,  2.4606e-03, -5.1303e-03,  9.4225e-04, -4.9927e-03,\n",
      "          1.5065e-02,  1.6832e-03,  1.6354e-03, -2.0832e-03,  6.0357e-03,\n",
      "          7.2955e-01,  2.9155e-01],\n",
      "        [ 9.3792e-03, -1.3457e-02, -1.7432e-03, -8.0511e-03, -1.4753e-02,\n",
      "          6.1840e-03, -1.1577e-02, -5.7243e-03,  2.3542e-02, -1.0927e-02,\n",
      "          7.2810e-01,  2.7582e-01],\n",
      "        [ 1.0637e-02,  4.0305e-03, -5.5601e-03,  3.6892e-03, -6.8113e-03,\n",
      "          1.7689e-03, -1.5302e-02, -3.6702e-03,  9.8116e-03,  4.5644e-03,\n",
      "          7.6571e-01,  2.7776e-01],\n",
      "        [ 3.1063e-03, -3.6737e-03, -5.1258e-03,  1.4668e-02,  5.1689e-03,\n",
      "          1.3921e-02, -2.9843e-04,  2.6301e-03,  1.1501e-03,  2.8310e-03,\n",
      "          7.3868e-01,  2.9058e-01],\n",
      "        [-1.4273e-02, -5.6218e-03,  9.9063e-03, -3.5478e-03,  9.5862e-03,\n",
      "         -1.3305e-02,  1.3297e-02,  1.2639e-02,  2.3583e-03,  1.7908e-02,\n",
      "          7.3782e-01,  2.7979e-01]])\n",
      "tensor([9.6522e-05, 8.9022e-05, 3.5222e-05, 1.0996e-04, 8.9200e-05, 1.1494e-04,\n",
      "        1.2758e-04, 5.0864e-05, 8.4872e-05, 1.5154e-04, 1.8470e-04, 8.4558e-05])\n",
      "Distance Matrix:\n",
      "[[0.         0.01684868 0.01000489 0.02364006 0.0137113  0.01453441]\n",
      " [0.01684868 0.         0.00690455 0.01280541 0.0031458  0.00636515]\n",
      " [0.01000489 0.00690455 0.         0.01547515 0.00383937 0.0058695 ]\n",
      " [0.02364006 0.01280541 0.01547515 0.         0.01413115 0.00963235]\n",
      " [0.0137113  0.0031458  0.00383937 0.01413115 0.         0.00561929]\n",
      " [0.01453441 0.00636515 0.0058695  0.00963235 0.00561929 0.        ]]\n",
      "Edge Index:\n",
      "tensor([[0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5],\n",
      "        [2, 4, 5, 2, 3, 4, 5, 0, 1, 4, 5, 1, 4, 5, 0, 1, 2, 3, 5, 0, 1, 2, 3, 4]])\n",
      "Data(x=[6, 12], edge_index=[2, 24])\n"
     ]
    }
   ],
   "source": [
    "required_stations = ['JRB', 'ROC', 'BGM', 'MSS', 'PEO', 'RME']\n",
    "\n",
    "### first get the locations of stations\n",
    "# Filter the DataFrame for the required stations\n",
    "stations_df = latlongs[latlongs['stid'].isin(required_stations)]\n",
    "# Create a dictionary from the filtered DataFrame\n",
    "stations_latlong = stations_df.set_index('stid')[['lat', 'lon']].T.to_dict()\n",
    "\n",
    "print(stations_latlong)\n",
    "\n",
    "### now get station data itself\n",
    "processed_data_paths = {station:f'./csvs/{station}_processed.csv' for station in required_stations}\n",
    "print(processed_data_paths)\n",
    "\n",
    "station_features = []\n",
    "normalized_latlongs = []\n",
    "for stid in required_stations:\n",
    "   station_data = pd.read_csv(processed_data_paths[stid])\n",
    "   features = torch.tensor(station_data.drop(columns=['station', 'valid']).values, dtype=torch.float)\n",
    "   mean_features = features.mean(dim=0)  # Mean of all the features to get \"average weather\"\n",
    "\n",
    "   # Append latitude and longitude to the feature vector\n",
    "   lat, long = stations_latlong[stid]['lat'], stations_latlong[stid]['lon']\n",
    "   nlat = (lat+90)/ (180)\n",
    "   nlong = (long+180)/ (360) \n",
    "   lat_long = torch.tensor([nlat,nlong], dtype=torch.float)\n",
    "   print(f\"latlong is {lat_long}\")\n",
    "   combined_features = torch.cat((mean_features, lat_long))  # Concatenate features with lat/lon\n",
    "\n",
    "   station_features.append(combined_features)\n",
    "   normalized_latlongs.append([nlat, nlong])\n",
    "\n",
    "print(f'n latlongs: {normalized_latlongs}')\n",
    "\n",
    "node_features = torch.stack(station_features)\n",
    "node_features += torch.randn_like(node_features) * 0.01  # noise\n",
    "print(node_features.shape)\n",
    "print(node_features)\n",
    "print(torch.var(node_features, dim=0))\n",
    "\n",
    "def calculate_distances(latlongs):\n",
    "   num_stations = len(latlongs)\n",
    "   distances = np.zeros((num_stations, num_stations))\n",
    "   for i, coord1 in enumerate(latlongs):\n",
    "      for j, coord2 in enumerate(latlongs):\n",
    "         # Calculate Euclidean distance for normalized coordinates\n",
    "         distances[i, j] = np.linalg.norm(np.array(coord1) - np.array(coord2))\n",
    "   return distances\n",
    "\n",
    "distances = calculate_distances(normalized_latlongs)\n",
    "print(\"Distance Matrix:\")\n",
    "print(distances)\n",
    "\n",
    "distance_threshold = 0.015  # Adjust this threshold based on your scale and data\n",
    "edges = []\n",
    "\n",
    "for i in range(len(distances)):\n",
    "   for j in range(len(distances)):\n",
    "      if i != j and distances[i, j] <= distance_threshold:\n",
    "         edges.append((i, j))\n",
    "\n",
    "# Define edges \n",
    "edge_index = torch.tensor(edges, dtype=torch.long).T  # Transpose to match edge_index format\n",
    "print(\"Edge Index:\")\n",
    "print(edge_index)\n",
    "\n",
    "# Create the graph data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNN(torch.nn.Module):\n",
    "   def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "      super(SimpleGNN, self).__init__()\n",
    "      self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "      self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "   def forward(self, data):\n",
    "      x, edge_index = data.x, data.edge_index\n",
    "      x = self.conv1(x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      x = self.conv2(x, edge_index)\n",
    "      return x  # Embeddings for each node\n",
    "\n",
    "# Initialize the GNN\n",
    "input_dim = node_features.shape[1]  # Latitude and longitude plus features\n",
    "hidden_dim = 14\n",
    "output_dim = 12  # Embedding size\n",
    "gnn = SimpleGNN(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial embeddings for each station:\n",
      "tensor([[ 0.0684,  0.0852,  0.1688,  0.2278,  0.0418,  0.0956, -0.1624,  0.0038,\n",
      "          0.1482, -0.0409,  0.0031,  0.0531],\n",
      "        [ 0.0751,  0.0930,  0.1893,  0.2534,  0.0484,  0.1060, -0.1807,  0.0052,\n",
      "          0.1662, -0.0466,  0.0058,  0.0577],\n",
      "        [ 0.0759,  0.0943,  0.1887,  0.2539,  0.0473,  0.1064, -0.1810,  0.0046,\n",
      "          0.1657, -0.0459,  0.0042,  0.0587],\n",
      "        [ 0.0670,  0.0830,  0.1700,  0.2271,  0.0437,  0.0949, -0.1619,  0.0049,\n",
      "          0.1492, -0.0421,  0.0057,  0.0514],\n",
      "        [ 0.0824,  0.1021,  0.2068,  0.2771,  0.0525,  0.1160, -0.1977,  0.0056,\n",
      "          0.1815, -0.0506,  0.0056,  0.0635],\n",
      "        [ 0.0824,  0.1021,  0.2068,  0.2771,  0.0525,  0.1160, -0.1977,  0.0056,\n",
      "          0.1815, -0.0506,  0.0056,  0.0635]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embeddings = gnn(data)\n",
    "\n",
    "# Print embeddings\n",
    "print(\"initial embeddings for each station:\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity matrix is tensor([[0.6343, 0.6253, 0.6198, 0.6477, 0.6313, 0.6271],\n",
      "        [0.6253, 0.6177, 0.6117, 0.6398, 0.6239, 0.6195],\n",
      "        [0.6198, 0.6117, 0.6076, 0.6346, 0.6179, 0.6137],\n",
      "        [0.6477, 0.6398, 0.6346, 0.6640, 0.6464, 0.6422],\n",
      "        [0.6313, 0.6239, 0.6179, 0.6464, 0.6306, 0.6261],\n",
      "        [0.6271, 0.6195, 0.6137, 0.6422, 0.6261, 0.6239]])\n",
      "Epoch 1, Loss: 0.0073\n",
      "Epoch 2, Loss: 0.0060\n",
      "Epoch 3, Loss: 0.0055\n",
      "Epoch 4, Loss: 0.0055\n",
      "Epoch 5, Loss: 0.0058\n",
      "Epoch 6, Loss: 0.0060\n",
      "Epoch 7, Loss: 0.0060\n",
      "Epoch 8, Loss: 0.0058\n",
      "Epoch 9, Loss: 0.0056\n",
      "Epoch 10, Loss: 0.0055\n",
      "Epoch 11, Loss: 0.0054\n",
      "Epoch 12, Loss: 0.0054\n",
      "Epoch 13, Loss: 0.0055\n",
      "Epoch 14, Loss: 0.0056\n",
      "Epoch 15, Loss: 0.0056\n",
      "Epoch 16, Loss: 0.0056\n",
      "Epoch 17, Loss: 0.0055\n",
      "Epoch 18, Loss: 0.0054\n",
      "Epoch 19, Loss: 0.0053\n",
      "Epoch 20, Loss: 0.0053\n",
      "Epoch 21, Loss: 0.0053\n",
      "Epoch 22, Loss: 0.0054\n",
      "Epoch 23, Loss: 0.0054\n",
      "Epoch 24, Loss: 0.0054\n",
      "Epoch 25, Loss: 0.0053\n",
      "Epoch 26, Loss: 0.0053\n",
      "Epoch 27, Loss: 0.0053\n",
      "Epoch 28, Loss: 0.0052\n",
      "Epoch 29, Loss: 0.0052\n",
      "Epoch 30, Loss: 0.0052\n",
      "Epoch 31, Loss: 0.0052\n",
      "Epoch 32, Loss: 0.0052\n",
      "Epoch 33, Loss: 0.0052\n",
      "Epoch 34, Loss: 0.0052\n",
      "Epoch 35, Loss: 0.0052\n",
      "Epoch 36, Loss: 0.0051\n",
      "Epoch 37, Loss: 0.0051\n",
      "Epoch 38, Loss: 0.0051\n",
      "Epoch 39, Loss: 0.0051\n",
      "Epoch 40, Loss: 0.0051\n",
      "Epoch 41, Loss: 0.0051\n",
      "Epoch 42, Loss: 0.0051\n",
      "Epoch 43, Loss: 0.0051\n",
      "Epoch 44, Loss: 0.0050\n",
      "Epoch 45, Loss: 0.0050\n",
      "Epoch 46, Loss: 0.0050\n",
      "Epoch 47, Loss: 0.0050\n",
      "Epoch 48, Loss: 0.0050\n",
      "Epoch 49, Loss: 0.0050\n",
      "Epoch 50, Loss: 0.0050\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "# Compute similarity matrix from node features\n",
    "similarity_matrix = torch.mm(node_features, node_features.T)\n",
    "print(f'similarity matrix is {similarity_matrix}')\n",
    "\n",
    "# Define unsupervised loss function with regularization\n",
    "def contrastive_loss(embeddings, similarity_matrix, distance_matrix, lambda_diversity=0.1, lambda_distance=0.1):\n",
    "   pred_similarity = torch.mm(embeddings, embeddings.T)\n",
    "   mse_loss = torch.nn.functional.mse_loss(pred_similarity, similarity_matrix)\n",
    "\n",
    "   diversity_loss = -torch.var(embeddings, dim=0).mean()  # Penalize low variance\n",
    "\n",
    "   pred_distance_matrix = torch.cdist(embeddings, embeddings, p=2)\n",
    "   distance_loss = torch.nn.functional.mse_loss(pred_distance_matrix, distance_matrix)\n",
    "\n",
    "   total_loss = mse_loss + lambda_diversity * diversity_loss + lambda_distance * distance_loss\n",
    "   return total_loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "optimizer = torch.optim.Adam(gnn.parameters(), lr=0.001)\n",
    "\n",
    "gnn.train()\n",
    "for epoch in range(epochs):\n",
    "   optimizer.zero_grad()  # Reset gradients\n",
    "   embeddings = gnn(data)  # Forward pass\n",
    "\n",
    "   # Compute contrastive loss\n",
    "   loss = contrastive_loss(embeddings, similarity_matrix, torch.Tensor(distances))\n",
    "   \n",
    "   # Backward pass and optimization\n",
    "   loss.backward()\n",
    "   optimizer.step()\n",
    "\n",
    "   # Print loss and gradient information\n",
    "   print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "   # for name, param in gnn.named_parameters():\n",
    "   #    if param.grad is not None:\n",
    "   #       print(f\"Gradient for {name}: {param.grad.abs().mean().item():.6f}\")\n",
    "   #    else:\n",
    "   #       print(f\"No gradient for {name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned embeddings:\n",
      "tensor([[ 0.1667,  0.1649,  0.2706,  0.3670,  0.1308,  0.1921, -0.2734,  0.1110,\n",
      "          0.2683, -0.1271,  0.0816,  0.1544],\n",
      "        [ 0.1802,  0.1772,  0.2979,  0.4051,  0.1424,  0.2087, -0.3003,  0.1195,\n",
      "          0.2960, -0.1381,  0.0875,  0.1659],\n",
      "        [ 0.1807,  0.1784,  0.2975,  0.4050,  0.1414,  0.2093, -0.3004,  0.1188,\n",
      "          0.2952, -0.1371,  0.0858,  0.1669],\n",
      "        [ 0.1658,  0.1628,  0.2714,  0.3674,  0.1326,  0.1913, -0.2733,  0.1124,\n",
      "          0.2699, -0.1289,  0.0845,  0.1529],\n",
      "        [ 0.1935,  0.1903,  0.3223,  0.4398,  0.1515,  0.2248, -0.3251,  0.1263,\n",
      "          0.3201, -0.1464,  0.0899,  0.1781],\n",
      "        [ 0.1935,  0.1903,  0.3223,  0.4398,  0.1515,  0.2248, -0.3251,  0.1263,\n",
      "          0.3201, -0.1464,  0.0899,  0.1781]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learned_embeddings = gnn(data)  # Get final embeddings\n",
    "print(\"Learned embeddings:\")\n",
    "print(learned_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JRB\n",
      "(9699, 12)\n",
      "ROC\n",
      "(9892, 12)\n",
      "BGM\n",
      "(11580, 12)\n",
      "MSS\n",
      "(11205, 12)\n",
      "PEO\n",
      "(10953, 12)\n",
      "RME\n",
      "(10844, 12)\n"
     ]
    }
   ],
   "source": [
    "for r in required_stations:\n",
    "   df = pd.read_csv(f'./csvs/{r}_processed.csv')\n",
    "   print(r)\n",
    "   print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each station, add on the static embedding that we just learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9699, 12)\n",
      "(9699, 24)\n",
      "(9892, 12)\n",
      "(9892, 24)\n",
      "(11580, 12)\n",
      "(11580, 24)\n",
      "(11205, 12)\n",
      "(11205, 24)\n",
      "(10953, 12)\n",
      "(10953, 24)\n",
      "(10844, 12)\n",
      "(10844, 24)\n",
      "(64173, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>valid</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>dwpf</th>\n",
       "      <th>relh</th>\n",
       "      <th>drct</th>\n",
       "      <th>sknt</th>\n",
       "      <th>p01i</th>\n",
       "      <th>alti</th>\n",
       "      <th>mslp</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>embedding_10</th>\n",
       "      <th>embedding_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2024-01-01 00:56:00</td>\n",
       "      <td>-1.145898</td>\n",
       "      <td>-1.254430</td>\n",
       "      <td>-0.580240</td>\n",
       "      <td>1.168285</td>\n",
       "      <td>0.073238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084109</td>\n",
       "      <td>0.070262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270572</td>\n",
       "      <td>0.367036</td>\n",
       "      <td>0.130773</td>\n",
       "      <td>0.192087</td>\n",
       "      <td>-0.273424</td>\n",
       "      <td>0.110965</td>\n",
       "      <td>0.268316</td>\n",
       "      <td>-0.127137</td>\n",
       "      <td>0.081605</td>\n",
       "      <td>0.154424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2024-01-01 01:56:00</td>\n",
       "      <td>-1.145898</td>\n",
       "      <td>-1.191784</td>\n",
       "      <td>-0.449190</td>\n",
       "      <td>1.168285</td>\n",
       "      <td>-0.198038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084109</td>\n",
       "      <td>0.070262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270572</td>\n",
       "      <td>0.367036</td>\n",
       "      <td>0.130773</td>\n",
       "      <td>0.192087</td>\n",
       "      <td>-0.273424</td>\n",
       "      <td>0.110965</td>\n",
       "      <td>0.268316</td>\n",
       "      <td>-0.127137</td>\n",
       "      <td>0.081605</td>\n",
       "      <td>0.154424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2024-01-01 02:56:00</td>\n",
       "      <td>-1.145898</td>\n",
       "      <td>-1.129138</td>\n",
       "      <td>-0.312656</td>\n",
       "      <td>1.070846</td>\n",
       "      <td>-0.198038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084109</td>\n",
       "      <td>0.070262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270572</td>\n",
       "      <td>0.367036</td>\n",
       "      <td>0.130773</td>\n",
       "      <td>0.192087</td>\n",
       "      <td>-0.273424</td>\n",
       "      <td>0.110965</td>\n",
       "      <td>0.268316</td>\n",
       "      <td>-0.127137</td>\n",
       "      <td>0.081605</td>\n",
       "      <td>0.154424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2024-01-01 03:56:00</td>\n",
       "      <td>-1.145898</td>\n",
       "      <td>-1.066491</td>\n",
       "      <td>-0.171735</td>\n",
       "      <td>1.168285</td>\n",
       "      <td>-0.198038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084109</td>\n",
       "      <td>0.083014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270572</td>\n",
       "      <td>0.367036</td>\n",
       "      <td>0.130773</td>\n",
       "      <td>0.192087</td>\n",
       "      <td>-0.273424</td>\n",
       "      <td>0.110965</td>\n",
       "      <td>0.268316</td>\n",
       "      <td>-0.127137</td>\n",
       "      <td>0.081605</td>\n",
       "      <td>0.154424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JRB</td>\n",
       "      <td>2024-01-01 04:56:00</td>\n",
       "      <td>-1.145898</td>\n",
       "      <td>-1.066491</td>\n",
       "      <td>-0.171735</td>\n",
       "      <td>1.070846</td>\n",
       "      <td>0.615791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084109</td>\n",
       "      <td>0.108517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270572</td>\n",
       "      <td>0.367036</td>\n",
       "      <td>0.130773</td>\n",
       "      <td>0.192087</td>\n",
       "      <td>-0.273424</td>\n",
       "      <td>0.110965</td>\n",
       "      <td>0.268316</td>\n",
       "      <td>-0.127137</td>\n",
       "      <td>0.081605</td>\n",
       "      <td>0.154424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  station                valid      tmpf      dwpf      relh      drct  \\\n",
       "0     JRB  2024-01-01 00:56:00 -1.145898 -1.254430 -0.580240  1.168285   \n",
       "1     JRB  2024-01-01 01:56:00 -1.145898 -1.191784 -0.449190  1.168285   \n",
       "2     JRB  2024-01-01 02:56:00 -1.145898 -1.129138 -0.312656  1.070846   \n",
       "3     JRB  2024-01-01 03:56:00 -1.145898 -1.066491 -0.171735  1.168285   \n",
       "4     JRB  2024-01-01 04:56:00 -1.145898 -1.066491 -0.171735  1.070846   \n",
       "\n",
       "       sknt  p01i      alti      mslp  ...  embedding_2  embedding_3  \\\n",
       "0  0.073238   0.0  0.084109  0.070262  ...     0.270572     0.367036   \n",
       "1 -0.198038   0.0  0.084109  0.070262  ...     0.270572     0.367036   \n",
       "2 -0.198038   0.0  0.084109  0.070262  ...     0.270572     0.367036   \n",
       "3 -0.198038   0.0  0.084109  0.083014  ...     0.270572     0.367036   \n",
       "4  0.615791   0.0  0.084109  0.108517  ...     0.270572     0.367036   \n",
       "\n",
       "   embedding_4  embedding_5  embedding_6  embedding_7  embedding_8  \\\n",
       "0     0.130773     0.192087    -0.273424     0.110965     0.268316   \n",
       "1     0.130773     0.192087    -0.273424     0.110965     0.268316   \n",
       "2     0.130773     0.192087    -0.273424     0.110965     0.268316   \n",
       "3     0.130773     0.192087    -0.273424     0.110965     0.268316   \n",
       "4     0.130773     0.192087    -0.273424     0.110965     0.268316   \n",
       "\n",
       "   embedding_9  embedding_10  embedding_11  \n",
       "0    -0.127137      0.081605      0.154424  \n",
       "1    -0.127137      0.081605      0.154424  \n",
       "2    -0.127137      0.081605      0.154424  \n",
       "3    -0.127137      0.081605      0.154424  \n",
       "4    -0.127137      0.081605      0.154424  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "for idx, (station, path) in enumerate(processed_data_paths.items()):\n",
    "   # Load the CSV into a DataFrame\n",
    "   df = pd.read_csv(path)\n",
    "   print(df.shape)\n",
    "   \n",
    "   # Get the corresponding embedding for this station\n",
    "   embedding = learned_embeddings[idx].detach().numpy()\n",
    "   \n",
    "   # Add the embedding as new columns to the DataFrame\n",
    "   for i, value in enumerate(embedding):\n",
    "      df[f'embedding_{i}'] = value\n",
    "\n",
    "   print(df.shape)\n",
    "   \n",
    "   # Append to the list of all data\n",
    "   all_data.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Display the result\n",
    "print(combined_df.shape)\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10820, 24, 22)\n",
      "(10820, 22)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Prepare sequences for LSTM input\n",
    "# Assuming we are predicting 'tmpf' (temperature) as the target variable\n",
    "# and using previous 24 time steps/8 hours (n_steps_in) to predict the next time step/20 minutes from now (n_steps_out)\n",
    "# create sliding window sequences X: (114640, 24, 10), y: (114640, 10)\n",
    "feature_cols = list(set(df.columns) - set(['station', 'valid']))\n",
    "\n",
    "n_steps_in = 24  # Number of past time steps\n",
    "n_steps_out = 1  # Number of future time steps to predict\n",
    "\n",
    "# We'll create sequences for each station separately\n",
    "def create_sequences(data, n_steps_in, n_steps_out):\n",
    "   X, y = [], []\n",
    "   for i in range(len(data) - n_steps_in - n_steps_out + 1):\n",
    "      X.append(data[i:(i + n_steps_in), :])\n",
    "      y.append(data[(i + n_steps_in):(i + n_steps_in + n_steps_out), :])\n",
    "   return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare data for each station\n",
    "X_list = []\n",
    "y_list = []\n",
    "stations = df['station'].unique()\n",
    "\n",
    "for station in stations:\n",
    "   station_data = df[df['station'] == station]\n",
    "   station_data = station_data.reset_index(drop=True)\n",
    "   data_values = station_data[feature_cols].values\n",
    "   # target_col_index = feature_cols.index('tmpf')  # Index of target variable in features\n",
    "\n",
    "   X_station, y_station = create_sequences(data_values, n_steps_in, n_steps_out)\n",
    "   X_list.append(X_station)\n",
    "   y_list.append(y_station)\n",
    "\n",
    "\n",
    "# Concatenate data from all stations\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "\n",
    "if n_steps_out == 1:\n",
    "   y = y.squeeze(1)  # Shape becomes (num_samples, num_features) = (114640, 10) for JRB\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Split the data into training and testing sets\n",
    "# Since it's time-series data, we'll use the first 80% for training and the rest for testing\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Now the data is ready for training the LSTM model\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class WeatherDataset(Dataset):\n",
    "   def __init__(self, X, y):\n",
    "      self.X = X\n",
    "      self.y = y\n",
    "   def __len__(self):\n",
    "      return len(self.X)\n",
    "   def __getitem__(self, idx):\n",
    "      return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model     | SegRNN  | 2.4 M  | train\n",
      "1 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.642     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf63433689ba4d1e91af822f51458ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.493105947971344\n",
      "Train Loss: 0.4144764542579651\n",
      "Train Loss: 0.34679508209228516\n",
      "Train Loss: 0.25418820977211\n",
      "Train Loss: 0.2302674949169159\n",
      "Train Loss: 0.17468594014644623\n",
      "Train Loss: 0.17893333733081818\n",
      "Train Loss: 0.17039082944393158\n",
      "Train Loss: 0.17804650962352753\n",
      "Train Loss: 0.15777702629566193\n",
      "Train Loss: 0.1397632658481598\n",
      "Train Loss: 0.16257230937480927\n",
      "Train Loss: 0.16951799392700195\n",
      "Train Loss: 0.14495372772216797\n",
      "Train Loss: 0.14141404628753662\n",
      "Train Loss: 0.12969093024730682\n",
      "Train Loss: 0.14675498008728027\n",
      "Train Loss: 0.12434204667806625\n",
      "Train Loss: 0.12029087543487549\n",
      "Train Loss: 0.12323443591594696\n",
      "Train Loss: 0.11878649890422821\n",
      "Train Loss: 0.11114782840013504\n",
      "Train Loss: 0.09644042700529099\n",
      "Train Loss: 0.10359539091587067\n",
      "Train Loss: 0.2443937212228775\n",
      "Train Loss: 0.10298041999340057\n",
      "Train Loss: 0.09228543937206268\n",
      "Train Loss: 0.10065064579248428\n",
      "Train Loss: 0.11743097007274628\n",
      "Train Loss: 0.073731429874897\n",
      "Train Loss: 0.12144314497709274\n",
      "Train Loss: 0.0830845832824707\n",
      "Train Loss: 0.089964359998703\n",
      "Train Loss: 0.09290669113397598\n",
      "Train Loss: 0.11967577040195465\n",
      "Train Loss: 0.06277433782815933\n",
      "Train Loss: 0.07565958797931671\n",
      "Train Loss: 0.06419433653354645\n",
      "Train Loss: 0.09219540655612946\n",
      "Train Loss: 0.09345191717147827\n",
      "Train Loss: 0.0800706222653389\n",
      "Train Loss: 0.20715488493442535\n",
      "Train Loss: 0.08783292770385742\n",
      "Train Loss: 0.06396910548210144\n",
      "Train Loss: 0.09813479334115982\n",
      "Train Loss: 0.045872073620557785\n",
      "Train Loss: 0.04936780408024788\n",
      "Train Loss: 0.24782347679138184\n",
      "Train Loss: 0.06256214529275894\n",
      "Train Loss: 0.11149309575557709\n",
      "Train Loss: 0.08452023565769196\n",
      "Train Loss: 0.10136706382036209\n",
      "Train Loss: 0.05289485305547714\n",
      "Train Loss: 0.17448139190673828\n",
      "Train Loss: 0.08246058970689774\n",
      "Train Loss: 0.06972649693489075\n",
      "Train Loss: 0.07518458366394043\n",
      "Train Loss: 0.10555428266525269\n",
      "Train Loss: 0.15316398441791534\n",
      "Train Loss: 0.07689637690782547\n",
      "Train Loss: 0.08744422346353531\n",
      "Train Loss: 0.06600045412778854\n",
      "Train Loss: 0.07395361363887787\n",
      "Train Loss: 0.04998355731368065\n",
      "Train Loss: 0.08306416869163513\n",
      "Train Loss: 0.07301938533782959\n",
      "Train Loss: 0.07658401876688004\n",
      "Train Loss: 0.39289233088493347\n",
      "Train Loss: 0.06052704527974129\n",
      "Train Loss: 0.05569644644856453\n",
      "Train Loss: 0.06603703647851944\n",
      "Train Loss: 0.05326734110713005\n",
      "Train Loss: 0.08271584659814835\n",
      "Train Loss: 0.05903330817818642\n",
      "Train Loss: 0.07647525519132614\n",
      "Train Loss: 0.04136831685900688\n",
      "Train Loss: 0.08312826603651047\n",
      "Train Loss: 0.12853215634822845\n",
      "Train Loss: 0.05335361510515213\n",
      "Train Loss: 0.04862639307975769\n",
      "Train Loss: 0.05010639503598213\n",
      "Train Loss: 0.07322318106889725\n",
      "Train Loss: 0.055118974298238754\n",
      "Train Loss: 0.11133831739425659\n",
      "Train Loss: 0.07938370853662491\n",
      "Train Loss: 0.10314783453941345\n",
      "Train Loss: 0.05876079574227333\n",
      "Train Loss: 0.03683697059750557\n",
      "Train Loss: 0.04259626567363739\n",
      "Train Loss: 0.08764901757240295\n",
      "Train Loss: 0.07858098298311234\n",
      "Train Loss: 0.05752648040652275\n",
      "Train Loss: 0.0944301038980484\n",
      "Train Loss: 0.08078411221504211\n",
      "Train Loss: 0.04852708429098129\n",
      "Train Loss: 0.04699065536260605\n",
      "Train Loss: 0.04618574306368828\n",
      "Train Loss: 0.07102639973163605\n",
      "Train Loss: 0.23707139492034912\n",
      "Train Loss: 0.048306673765182495\n",
      "Train Loss: 0.051347117871046066\n",
      "Train Loss: 0.05239611491560936\n",
      "Train Loss: 0.051626164466142654\n",
      "Train Loss: 0.061740659177303314\n",
      "Train Loss: 0.10064927488565445\n",
      "Train Loss: 0.06524181365966797\n",
      "Train Loss: 0.09617237001657486\n",
      "Train Loss: 0.0868382528424263\n",
      "Train Loss: 0.06377442181110382\n",
      "Train Loss: 0.07872766256332397\n",
      "Train Loss: 0.0675198957324028\n",
      "Train Loss: 0.04611225798726082\n",
      "Train Loss: 0.06803184747695923\n",
      "Train Loss: 0.06858845055103302\n",
      "Train Loss: 0.06971249729394913\n",
      "Train Loss: 0.03842753916978836\n",
      "Train Loss: 0.052171699702739716\n",
      "Train Loss: 0.054449256509542465\n",
      "Train Loss: 0.05374918505549431\n",
      "Train Loss: 0.0810842514038086\n",
      "Train Loss: 0.056070227175951004\n",
      "Train Loss: 0.06740030646324158\n",
      "Train Loss: 0.06178184226155281\n",
      "Train Loss: 0.039020709693431854\n",
      "Train Loss: 0.06700431555509567\n",
      "Train Loss: 0.06908518075942993\n",
      "Train Loss: 0.07584930956363678\n",
      "Train Loss: 0.042099107056856155\n",
      "Train Loss: 0.08477099239826202\n",
      "Train Loss: 0.06610088795423508\n",
      "Train Loss: 0.04901694133877754\n",
      "Train Loss: 0.06352070719003677\n",
      "Train Loss: 0.08704789727926254\n",
      "Train Loss: 0.04007210582494736\n",
      "Train Loss: 0.06733030080795288\n",
      "Train Loss: 0.07916609942913055\n",
      "Train Loss: 0.09512106329202652\n",
      "Train Loss: 0.031155135482549667\n",
      "Train Loss: 0.03316957503557205\n",
      "Train Loss: 0.06236681342124939\n",
      "Train Loss: 0.04409981146454811\n",
      "Train Loss: 0.19935792684555054\n",
      "Train Loss: 0.07615236192941666\n",
      "Train Loss: 0.07441788911819458\n",
      "Train Loss: 0.08265379071235657\n",
      "Train Loss: 0.08322185277938843\n",
      "Train Loss: 0.06590545177459717\n",
      "Train Loss: 0.08963034301996231\n",
      "Train Loss: 0.07192499935626984\n",
      "Train Loss: 0.07939417660236359\n",
      "Train Loss: 0.05379316210746765\n",
      "Train Loss: 0.08517469465732574\n",
      "Train Loss: 0.06649690866470337\n",
      "Train Loss: 0.11638973653316498\n",
      "Train Loss: 0.041617512702941895\n",
      "Train Loss: 0.06791239976882935\n",
      "Train Loss: 0.0664491280913353\n",
      "Train Loss: 0.05963443964719772\n",
      "Train Loss: 0.1887376308441162\n",
      "Train Loss: 0.06571359187364578\n",
      "Train Loss: 0.050012726336717606\n",
      "Train Loss: 0.05396624282002449\n",
      "Train Loss: 0.04258166626095772\n",
      "Train Loss: 0.05196511372923851\n",
      "Train Loss: 0.10946409404277802\n",
      "Train Loss: 0.05729144439101219\n",
      "Train Loss: 0.08040980994701385\n",
      "Train Loss: 0.2443367838859558\n",
      "Train Loss: 0.07974404096603394\n",
      "Train Loss: 0.20289601385593414\n",
      "Train Loss: 0.05415507033467293\n",
      "Train Loss: 0.10865940898656845\n",
      "Train Loss: 0.050046857446432114\n",
      "Train Loss: 0.09343674033880234\n",
      "Train Loss: 0.04220796748995781\n",
      "Train Loss: 0.06554611027240753\n",
      "Train Loss: 0.07474131137132645\n",
      "Train Loss: 0.08872093260288239\n",
      "Train Loss: 0.06183440238237381\n",
      "Train Loss: 0.1037936806678772\n",
      "Train Loss: 0.08232652395963669\n",
      "Train Loss: 0.053381167352199554\n",
      "Train Loss: 0.05327918380498886\n",
      "Train Loss: 0.05304064601659775\n",
      "Train Loss: 0.07175874710083008\n",
      "Train Loss: 0.05561330169439316\n",
      "Train Loss: 0.05608832836151123\n",
      "Train Loss: 0.04866817966103554\n",
      "Train Loss: 0.07491699606180191\n",
      "Train Loss: 0.061969026923179626\n",
      "Train Loss: 0.03997384384274483\n",
      "Train Loss: 0.05296611785888672\n",
      "Train Loss: 0.029868250712752342\n",
      "Train Loss: 0.05988483130931854\n",
      "Train Loss: 0.0481121651828289\n",
      "Train Loss: 0.04880857095122337\n",
      "Train Loss: 0.05287989228963852\n",
      "Train Loss: 0.027470936998724937\n",
      "Train Loss: 0.0648219883441925\n",
      "Train Loss: 0.17446976900100708\n",
      "Train Loss: 0.037936411798000336\n",
      "Train Loss: 0.0639108195900917\n",
      "Train Loss: 0.07122299820184708\n",
      "Train Loss: 0.05745633319020271\n",
      "Train Loss: 0.053035616874694824\n",
      "Train Loss: 0.04857441037893295\n",
      "Train Loss: 0.03831925988197327\n",
      "Train Loss: 0.045462604612112045\n",
      "Train Loss: 0.05987517163157463\n",
      "Train Loss: 0.05653245002031326\n",
      "Train Loss: 0.06219738349318504\n",
      "Train Loss: 0.06144420802593231\n",
      "Train Loss: 0.16923105716705322\n",
      "Train Loss: 0.05411003157496452\n",
      "Train Loss: 0.06433004140853882\n",
      "Train Loss: 0.05377810448408127\n",
      "Train Loss: 0.08667488396167755\n",
      "Train Loss: 0.26656970381736755\n",
      "Train Loss: 0.14904285967350006\n",
      "Train Loss: 0.0997689887881279\n",
      "Train Loss: 0.07183689624071121\n",
      "Train Loss: 0.07167122513055801\n",
      "Train Loss: 0.04636837914586067\n",
      "Train Loss: 0.10002832114696503\n",
      "Train Loss: 0.06752359867095947\n",
      "Train Loss: 0.058486972004175186\n",
      "Train Loss: 0.12935423851013184\n",
      "Train Loss: 0.06802627444267273\n",
      "Train Loss: 0.044629089534282684\n",
      "Train Loss: 0.11529099196195602\n",
      "Train Loss: 0.07655598223209381\n",
      "Train Loss: 0.07402346283197403\n",
      "Train Loss: 0.0509752482175827\n",
      "Train Loss: 0.7981908321380615\n",
      "Train Loss: 0.06019246578216553\n",
      "Train Loss: 0.063400998711586\n",
      "Train Loss: 0.06199202314019203\n",
      "Train Loss: 0.05170820280909538\n",
      "Train Loss: 0.10011068731546402\n",
      "Train Loss: 0.043844807893037796\n",
      "Train Loss: 0.0711488425731659\n",
      "Train Loss: 0.09957591444253922\n",
      "Train Loss: 0.06882154941558838\n",
      "Train Loss: 0.05322721600532532\n",
      "Train Loss: 0.16776998341083527\n",
      "Train Loss: 0.09702173620462418\n",
      "Train Loss: 0.09513846784830093\n",
      "Train Loss: 0.20795688033103943\n",
      "Train Loss: 0.0685095563530922\n",
      "Train Loss: 0.07425069063901901\n",
      "Train Loss: 0.05307241156697273\n",
      "Train Loss: 0.04286031052470207\n",
      "Train Loss: 0.0785505473613739\n",
      "Train Loss: 0.1367829144001007\n",
      "Train Loss: 0.058479778468608856\n",
      "Train Loss: 0.08672955632209778\n",
      "Train Loss: 0.031229078769683838\n",
      "Train Loss: 0.05642298236489296\n",
      "Train Loss: 0.06387146562337875\n",
      "Train Loss: 0.035919226706027985\n",
      "Train Loss: 0.03306557610630989\n",
      "Train Loss: 0.04375104233622551\n",
      "Train Loss: 0.0461520291864872\n",
      "Train Loss: 0.06182651221752167\n",
      "Train Loss: 0.03945222869515419\n",
      "Train Loss: 0.04655579850077629\n",
      "Train Loss: 2.3074581623077393\n",
      "Train Loss: 0.06731681525707245\n",
      "Train Loss: 0.052001118659973145\n",
      "Train Loss: 0.05915597453713417\n",
      "Train Loss: 0.06381881982088089\n",
      "Train Loss: 0.040375206619501114\n",
      "Train Loss: 0.04869229719042778\n",
      "Train Loss: 0.09352399408817291\n",
      "Train Loss: 0.050609953701496124\n",
      "Train Loss: 0.10790855437517166\n",
      "Train Loss: 0.07855567336082458\n",
      "Train Loss: 0.056429702788591385\n",
      "Train Loss: 0.046577226370573044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:384: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['train_loss', 'epoch', 'step']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07047335058450699\n",
      "Train Loss: 0.05333167314529419\n",
      "Train Loss: 0.07986544072628021\n",
      "Train Loss: 0.07371044158935547\n",
      "Train Loss: 0.03721301257610321\n",
      "Train Loss: 0.07225953787565231\n",
      "Train Loss: 0.05510362237691879\n",
      "Train Loss: 0.03936866670846939\n",
      "Train Loss: 0.05492657050490379\n",
      "Train Loss: 0.08432330936193466\n",
      "Train Loss: 0.03691588342189789\n",
      "Train Loss: 0.05276528000831604\n",
      "Train Loss: 0.051505718380212784\n",
      "Train Loss: 0.042562615126371384\n",
      "Train Loss: 0.036678314208984375\n",
      "Train Loss: 0.07124004513025284\n",
      "Train Loss: 0.04386189952492714\n",
      "Train Loss: 0.04809940978884697\n",
      "Train Loss: 0.0901201069355011\n",
      "Train Loss: 0.058993931859731674\n",
      "Train Loss: 0.10471037775278091\n",
      "Train Loss: 0.07012633234262466\n",
      "Train Loss: 0.0696418359875679\n",
      "Train Loss: 0.16390573978424072\n",
      "Train Loss: 0.07807870209217072\n",
      "Train Loss: 0.023498108610510826\n",
      "Train Loss: 0.05143878981471062\n",
      "Train Loss: 0.06038970872759819\n",
      "Train Loss: 0.03757967799901962\n",
      "Train Loss: 0.06288834661245346\n",
      "Train Loss: 0.08170296251773834\n",
      "Train Loss: 0.05086703971028328\n",
      "Train Loss: 0.06323018670082092\n",
      "Train Loss: 0.03397472947835922\n",
      "Train Loss: 0.11041776835918427\n",
      "Train Loss: 0.0504416786134243\n",
      "Train Loss: 0.0340980626642704\n",
      "Train Loss: 0.05412862077355385\n",
      "Train Loss: 0.054823074489831924\n",
      "Train Loss: 0.05066914111375809\n",
      "Train Loss: 0.05129265785217285\n",
      "Train Loss: 0.04055182263255119\n",
      "Train Loss: 0.06606481224298477\n",
      "Train Loss: 0.04605947062373161\n",
      "Train Loss: 0.04382665082812309\n",
      "Train Loss: 0.06525225937366486\n",
      "Train Loss: 0.04494485259056091\n",
      "Train Loss: 0.12598374485969543\n",
      "Train Loss: 0.038185182958841324\n",
      "Train Loss: 0.05359858274459839\n",
      "Train Loss: 0.11811275035142899\n",
      "Train Loss: 2.279932737350464\n",
      "Train Loss: 0.04160894453525543\n",
      "Train Loss: 0.06484894454479218\n",
      "Train Loss: 0.06492743641138077\n",
      "Train Loss: 0.16230440139770508\n",
      "Train Loss: 0.04345152899622917\n",
      "Train Loss: 0.048871539533138275\n",
      "Train Loss: 0.04268357530236244\n",
      "Train Loss: 0.05064604803919792\n",
      "Train Loss: 0.09073428809642792\n",
      "Train Loss: 0.19042320549488068\n",
      "Train Loss: 0.05954861640930176\n",
      "Train Loss: 0.06850615888834\n",
      "Train Loss: 0.13239580392837524\n",
      "Train Loss: 0.039677225053310394\n",
      "Train Loss: 0.05034923553466797\n",
      "Train Loss: 0.07669685781002045\n",
      "Train Loss: 0.07472005486488342\n",
      "Train Loss: 0.03949257358908653\n",
      "Train Loss: 0.06762844324111938\n",
      "Train Loss: 0.0565226674079895\n",
      "Train Loss: 0.10417377203702927\n",
      "Train Loss: 0.05191071704030037\n",
      "Train Loss: 0.0398976169526577\n",
      "Train Loss: 0.04070177674293518\n",
      "Train Loss: 0.04488898441195488\n",
      "Train Loss: 0.043000269681215286\n",
      "Train Loss: 0.0721125602722168\n",
      "Train Loss: 0.07728740572929382\n",
      "Train Loss: 0.12498604506254196\n",
      "Train Loss: 0.08973195403814316\n",
      "Train Loss: 0.03747023269534111\n",
      "Train Loss: 0.06468670815229416\n",
      "Train Loss: 0.046244680881500244\n",
      "Train Loss: 0.0492258183658123\n",
      "Train Loss: 0.06465236097574234\n",
      "Train Loss: 0.21428918838500977\n",
      "Train Loss: 0.4048360288143158\n",
      "Train Loss: 0.06472702324390411\n",
      "Train Loss: 0.03829435259103775\n",
      "Train Loss: 0.07402147352695465\n",
      "Train Loss: 0.053797442466020584\n",
      "Train Loss: 0.05097761005163193\n",
      "Train Loss: 0.07385239005088806\n",
      "Train Loss: 0.2647799253463745\n",
      "Train Loss: 0.14159831404685974\n",
      "Train Loss: 0.15105518698692322\n",
      "Train Loss: 0.07339264452457428\n",
      "Train Loss: 0.05071427300572395\n",
      "Train Loss: 0.08988848328590393\n",
      "Train Loss: 0.04504765197634697\n",
      "Train Loss: 0.06048424169421196\n",
      "Train Loss: 0.10184921324253082\n",
      "Train Loss: 0.04338880628347397\n",
      "Train Loss: 0.06501393020153046\n",
      "Train Loss: 0.10679896920919418\n",
      "Train Loss: 0.08059455454349518\n",
      "Train Loss: 0.07696616649627686\n",
      "Train Loss: 0.08453765511512756\n",
      "Train Loss: 0.19226090610027313\n",
      "Train Loss: 0.05156761407852173\n",
      "Train Loss: 0.15916849672794342\n",
      "Train Loss: 0.05946744605898857\n",
      "Train Loss: 0.08618694543838501\n",
      "Train Loss: 0.07116056978702545\n",
      "Train Loss: 0.05123503878712654\n",
      "Train Loss: 0.06661709398031235\n",
      "Train Loss: 0.08819596469402313\n",
      "Train Loss: 0.05314536765217781\n",
      "Train Loss: 0.8017309308052063\n",
      "Train Loss: 0.07403407245874405\n",
      "Train Loss: 0.055543433874845505\n",
      "Train Loss: 0.05616758391261101\n",
      "Train Loss: 0.0582549162209034\n",
      "Train Loss: 0.06843096017837524\n",
      "Train Loss: 0.06726231426000595\n",
      "Train Loss: 0.03924281895160675\n",
      "Train Loss: 0.041385263204574585\n",
      "Train Loss: 0.04254632070660591\n",
      "Train Loss: 0.05486159026622772\n",
      "Train Loss: 0.03468148782849312\n",
      "Train Loss: 0.05782938748598099\n",
      "Train Loss: 0.056915003806352615\n",
      "Train Loss: 0.06299404054880142\n",
      "Train Loss: 0.058399807661771774\n",
      "Train Loss: 0.07044258713722229\n",
      "Train Loss: 0.04478685185313225\n",
      "Train Loss: 0.14140276610851288\n",
      "Train Loss: 0.0505216009914875\n",
      "Train Loss: 0.05096130445599556\n",
      "Train Loss: 0.06429256498813629\n",
      "Train Loss: 0.06075797975063324\n",
      "Train Loss: 0.03749440610408783\n",
      "Train Loss: 0.06359177827835083\n",
      "Train Loss: 0.10358510911464691\n",
      "Train Loss: 0.20897142589092255\n",
      "Train Loss: 0.02961762435734272\n",
      "Train Loss: 0.04883895441889763\n",
      "Train Loss: 0.08343372493982315\n",
      "Train Loss: 0.09642111510038376\n",
      "Train Loss: 0.039613302797079086\n",
      "Train Loss: 0.07048473507165909\n",
      "Train Loss: 0.12263183295726776\n",
      "Train Loss: 0.1177980899810791\n",
      "Train Loss: 0.061569713056087494\n",
      "Train Loss: 0.050396233797073364\n",
      "Train Loss: 0.04232461750507355\n",
      "Train Loss: 0.05107049643993378\n",
      "Train Loss: 0.06677474826574326\n",
      "Train Loss: 0.048905644565820694\n",
      "Train Loss: 0.03745677322149277\n",
      "Train Loss: 0.053254518657922745\n",
      "Train Loss: 0.037637144327163696\n",
      "Train Loss: 0.07463894039392471\n",
      "Train Loss: 0.04788155108690262\n",
      "Train Loss: 0.07164541631937027\n",
      "Train Loss: 0.03883373364806175\n",
      "Train Loss: 0.042249370366334915\n",
      "Train Loss: 0.061486680060625076\n",
      "Train Loss: 0.0616694875061512\n",
      "Train Loss: 0.10518687963485718\n",
      "Train Loss: 0.06128070876002312\n",
      "Train Loss: 0.07315317541360855\n",
      "Train Loss: 0.02737666293978691\n",
      "Train Loss: 0.03243333846330643\n",
      "Train Loss: 0.10237361490726471\n",
      "Train Loss: 0.05142807960510254\n",
      "Train Loss: 0.03792985528707504\n",
      "Train Loss: 0.041048772633075714\n",
      "Train Loss: 0.029935726895928383\n",
      "Train Loss: 0.04997694492340088\n",
      "Train Loss: 0.06029348075389862\n",
      "Train Loss: 0.15397238731384277\n",
      "Train Loss: 0.052131883800029755\n",
      "Train Loss: 0.040623050183057785\n",
      "Train Loss: 0.0383220873773098\n",
      "Train Loss: 0.06828785687685013\n",
      "Train Loss: 0.08887165784835815\n",
      "Train Loss: 0.03470389544963837\n",
      "Train Loss: 0.03281685709953308\n",
      "Train Loss: 0.05706464499235153\n",
      "Train Loss: 0.04302224889397621\n",
      "Train Loss: 0.0772908627986908\n",
      "Train Loss: 0.04360063746571541\n",
      "Train Loss: 0.03185189887881279\n",
      "Train Loss: 0.04849933460354805\n",
      "Train Loss: 0.06075792759656906\n",
      "Train Loss: 0.09354130178689957\n",
      "Train Loss: 0.04371730610728264\n",
      "Train Loss: 0.04431722313165665\n",
      "Train Loss: 0.052412889897823334\n",
      "Train Loss: 0.06406641006469727\n",
      "Train Loss: 0.05764716491103172\n",
      "Train Loss: 0.038565393537282944\n",
      "Train Loss: 0.06687188148498535\n",
      "Train Loss: 0.06847520172595978\n",
      "Train Loss: 0.09255661815404892\n",
      "Train Loss: 0.06839299201965332\n",
      "Train Loss: 0.11183411628007889\n",
      "Train Loss: 0.05586417391896248\n",
      "Train Loss: 0.07125763595104218\n",
      "Train Loss: 0.07549416273832321\n",
      "Train Loss: 0.04598359391093254\n",
      "Train Loss: 0.16278553009033203\n",
      "Train Loss: 0.03891203925013542\n",
      "Train Loss: 0.2741474509239197\n",
      "Train Loss: 0.05393783748149872\n",
      "Train Loss: 0.0416417233645916\n",
      "Train Loss: 0.07313020527362823\n",
      "Train Loss: 0.03671044111251831\n",
      "Train Loss: 0.07239829748868942\n",
      "Train Loss: 0.03868262842297554\n",
      "Train Loss: 0.052273768931627274\n",
      "Train Loss: 0.06492111831903458\n",
      "Train Loss: 0.059862494468688965\n",
      "Train Loss: 0.07204899936914444\n",
      "Train Loss: 0.05739989131689072\n",
      "Train Loss: 0.06445930153131485\n",
      "Train Loss: 0.03864234313368797\n",
      "Train Loss: 0.04829701781272888\n",
      "Train Loss: 0.04039214923977852\n",
      "Train Loss: 0.07891428470611572\n",
      "Train Loss: 0.11155012995004654\n",
      "Train Loss: 0.03603464365005493\n",
      "Train Loss: 0.04791810363531113\n",
      "Train Loss: 0.04433566331863403\n",
      "Train Loss: 0.07889093458652496\n",
      "Train Loss: 0.03698975592851639\n",
      "Train Loss: 0.15635362267494202\n",
      "Train Loss: 0.037788987159729004\n",
      "Train Loss: 0.05155114457011223\n",
      "Train Loss: 0.05021166801452637\n",
      "Train Loss: 0.059363074600696564\n",
      "Train Loss: 0.09167587012052536\n",
      "Train Loss: 0.05229414626955986\n",
      "Train Loss: 0.042437419295310974\n",
      "Train Loss: 0.046980734914541245\n",
      "Train Loss: 0.04669227451086044\n",
      "Train Loss: 0.0466289259493351\n",
      "Train Loss: 0.060193710029125214\n",
      "Train Loss: 0.09243695437908173\n",
      "Train Loss: 0.0758424773812294\n",
      "Train Loss: 0.04702029749751091\n",
      "Train Loss: 0.03869105875492096\n",
      "Train Loss: 0.06697682291269302\n",
      "Train Loss: 0.05691993981599808\n",
      "Train Loss: 0.21795780956745148\n",
      "Train Loss: 0.06508032232522964\n",
      "Train Loss: 0.03645230084657669\n",
      "Train Loss: 0.05478256940841675\n",
      "Train Loss: 0.06362073868513107\n",
      "Train Loss: 0.02330874837934971\n",
      "Train Loss: 0.03810888156294823\n",
      "Train Loss: 0.02964080311357975\n",
      "Train Loss: 0.06615319103002548\n",
      "Train Loss: 0.053881965577602386\n",
      "Train Loss: 0.04231230542063713\n",
      "Train Loss: 0.06580370664596558\n",
      "Train Loss: 0.06713361293077469\n",
      "Train Loss: 0.05529268458485603\n",
      "Train Loss: 0.05859065800905228\n",
      "Train Loss: 0.0666877031326294\n",
      "Train Loss: 0.03881184011697769\n",
      "Train Loss: 0.05006030574440956\n",
      "Train Loss: 0.06640354543924332\n",
      "Train Loss: 0.039558589458465576\n",
      "Train Loss: 0.06663325428962708\n",
      "Train Loss: 0.07381125539541245\n",
      "Train Loss: 0.042966604232788086\n",
      "Train Loss: 0.033999212086200714\n",
      "Train Loss: 0.07318861782550812\n",
      "Train Loss: 0.09648832678794861\n",
      "Train Loss: 2.2814083099365234\n",
      "Train Loss: 0.1994636505842209\n",
      "Train Loss: 0.058665819466114044\n",
      "Train Loss: 0.06240560859441757\n",
      "Train Loss: 0.060148805379867554\n",
      "Train Loss: 0.06691163778305054\n",
      "Train Loss: 0.07772760838270187\n",
      "Train Loss: 0.10860129445791245\n",
      "Train Loss: 0.057381875813007355\n",
      "Train Loss: 0.04800352454185486\n",
      "Train Loss: 0.04213732108473778\n",
      "Train Loss: 0.04423200711607933\n",
      "Train Loss: 0.06241198256611824\n",
      "Train Loss: 0.09214518219232559\n",
      "Train Loss: 0.03886866942048073\n",
      "Train Loss: 0.2153446078300476\n",
      "Train Loss: 0.05396854877471924\n",
      "Train Loss: 0.042693715542554855\n",
      "Train Loss: 0.055424124002456665\n",
      "Train Loss: 0.05757012963294983\n",
      "Train Loss: 0.04693467170000076\n",
      "Train Loss: 0.06891089677810669\n",
      "Train Loss: 0.15575182437896729\n",
      "Train Loss: 0.048689112067222595\n",
      "Train Loss: 0.0760277509689331\n",
      "Train Loss: 0.06831447035074234\n",
      "Train Loss: 0.09463974088430405\n",
      "Train Loss: 0.8084090948104858\n",
      "Train Loss: 0.16275863349437714\n",
      "Train Loss: 0.05140596628189087\n",
      "Train Loss: 0.04627576842904091\n",
      "Train Loss: 0.04704660922288895\n",
      "Train Loss: 0.054482851177453995\n",
      "Train Loss: 0.03217850625514984\n",
      "Train Loss: 0.11426755040884018\n",
      "Train Loss: 0.05559157580137253\n",
      "Train Loss: 0.045007217675447464\n",
      "Train Loss: 0.06517620384693146\n",
      "Train Loss: 0.05833450332283974\n",
      "Train Loss: 0.05236406996846199\n",
      "Train Loss: 0.04855436831712723\n",
      "Train Loss: 0.04466341808438301\n",
      "Train Loss: 0.053449343889951706\n",
      "Train Loss: 0.04493587836623192\n",
      "Train Loss: 0.09035779535770416\n",
      "Train Loss: 0.05093970149755478\n",
      "Train Loss: 0.08117922395467758\n",
      "Train Loss: 0.043335430324077606\n",
      "Train Loss: 0.04529135301709175\n",
      "Train Loss: 0.059990882873535156\n",
      "Train Loss: 0.07187879830598831\n",
      "Train Loss: 0.025627104565501213\n",
      "Train Loss: 0.03522652015089989\n",
      "Train Loss: 0.0722300186753273\n",
      "Train Loss: 0.11844002455472946\n",
      "Train Loss: 0.04642723500728607\n",
      "Train Loss: 0.0527457594871521\n",
      "Train Loss: 0.08293072134256363\n",
      "Train Loss: 0.054796040058135986\n",
      "Train Loss: 0.048805803060531616\n",
      "Train Loss: 0.07421181350946426\n",
      "Train Loss: 0.044502515345811844\n",
      "Train Loss: 0.0599403902888298\n",
      "Train Loss: 0.03347010165452957\n",
      "Train Loss: 0.05770092457532883\n",
      "Train Loss: 0.05987191200256348\n",
      "Train Loss: 0.06665587425231934\n",
      "Train Loss: 0.040204089134931564\n",
      "Train Loss: 0.0355205312371254\n",
      "Train Loss: 0.0430295392870903\n",
      "Train Loss: 0.03972065821290016\n",
      "Train Loss: 0.04158630222082138\n",
      "Train Loss: 0.052779220044612885\n",
      "Train Loss: 0.04947992041707039\n",
      "Train Loss: 0.03486790135502815\n",
      "Train Loss: 0.04073553904891014\n",
      "Train Loss: 0.048821527510881424\n",
      "Train Loss: 0.058226343244314194\n",
      "Train Loss: 0.10267960280179977\n",
      "Train Loss: 0.05524253845214844\n",
      "Train Loss: 0.04493346065282822\n",
      "Train Loss: 0.056622061878442764\n",
      "Train Loss: 0.13140350580215454\n",
      "Train Loss: 0.0516817569732666\n",
      "Train Loss: 0.046276260167360306\n",
      "Train Loss: 0.04539503902196884\n",
      "Train Loss: 0.11748000979423523\n",
      "Train Loss: 0.05949841067194939\n",
      "Train Loss: 0.03658825159072876\n",
      "Train Loss: 0.03999174013733864\n",
      "Train Loss: 0.15869253873825073\n",
      "Train Loss: 0.04080278426408768\n",
      "Train Loss: 0.059764083474874496\n",
      "Train Loss: 0.044292230159044266\n",
      "Train Loss: 0.05535324290394783\n",
      "Train Loss: 0.0553777739405632\n",
      "Train Loss: 0.06716267764568329\n",
      "Train Loss: 0.03838673606514931\n",
      "Train Loss: 0.03797655925154686\n",
      "Train Loss: 0.05102722346782684\n",
      "Train Loss: 0.07270298153162003\n",
      "Train Loss: 0.04700702056288719\n",
      "Train Loss: 0.18304379284381866\n",
      "Train Loss: 0.051664192229509354\n",
      "Train Loss: 0.07540571689605713\n",
      "Train Loss: 0.05727025866508484\n",
      "Train Loss: 0.06051870062947273\n",
      "Train Loss: 0.05867096036672592\n",
      "Train Loss: 0.0451725609600544\n",
      "Train Loss: 0.05894605442881584\n",
      "Train Loss: 0.05924086272716522\n",
      "Train Loss: 0.04306917265057564\n",
      "Train Loss: 0.06259158998727798\n",
      "Train Loss: 0.06618677824735641\n",
      "Train Loss: 0.3245718479156494\n",
      "Train Loss: 0.05042140185832977\n",
      "Train Loss: 0.05080974102020264\n",
      "Train Loss: 0.07161588221788406\n",
      "Train Loss: 0.035071611404418945\n",
      "Train Loss: 0.05069395899772644\n",
      "Train Loss: 0.04509415477514267\n",
      "Train Loss: 0.0661921426653862\n",
      "Train Loss: 0.03566283360123634\n",
      "Train Loss: 0.034943658858537674\n",
      "Train Loss: 0.0730820894241333\n",
      "Train Loss: 0.0391896553337574\n",
      "Train Loss: 0.05723830312490463\n",
      "Train Loss: 0.06722187995910645\n",
      "Train Loss: 0.04314188286662102\n",
      "Train Loss: 0.0646478459239006\n",
      "Train Loss: 0.05582161992788315\n",
      "Train Loss: 0.05364581197500229\n",
      "Train Loss: 0.04943619295954704\n",
      "Train Loss: 0.04177040979266167\n",
      "Train Loss: 0.0449092872440815\n",
      "Train Loss: 0.06413476169109344\n",
      "Train Loss: 0.04231008142232895\n",
      "Train Loss: 0.06432094424962997\n",
      "Train Loss: 0.09014098346233368\n",
      "Train Loss: 0.10626798868179321\n",
      "Train Loss: 0.05346924811601639\n",
      "Train Loss: 0.052817802876234055\n",
      "Train Loss: 0.0452762134373188\n",
      "Train Loss: 0.19889147579669952\n",
      "Train Loss: 0.1079469621181488\n",
      "Train Loss: 0.08949106931686401\n",
      "Train Loss: 0.07737306505441666\n",
      "Train Loss: 0.15318524837493896\n",
      "Train Loss: 0.028063558042049408\n",
      "Train Loss: 0.0681786984205246\n",
      "Train Loss: 0.06271092593669891\n",
      "Train Loss: 0.03756578639149666\n",
      "Train Loss: 0.046941328793764114\n",
      "Train Loss: 0.052378665655851364\n",
      "Train Loss: 0.14822763204574585\n",
      "Train Loss: 0.03917064145207405\n",
      "Train Loss: 0.03634071350097656\n",
      "Train Loss: 0.03489043936133385\n",
      "Train Loss: 0.04490293189883232\n",
      "Train Loss: 0.058627527207136154\n",
      "Train Loss: 0.04390156269073486\n",
      "Train Loss: 0.0622955746948719\n",
      "Train Loss: 0.04032672569155693\n",
      "Train Loss: 0.08961661905050278\n",
      "Train Loss: 0.05143008753657341\n",
      "Train Loss: 0.04088481143116951\n",
      "Train Loss: 0.035615190863609314\n",
      "Train Loss: 0.06108013913035393\n",
      "Train Loss: 0.19440607726573944\n",
      "Train Loss: 0.06879350543022156\n",
      "Train Loss: 0.057992856949567795\n",
      "Train Loss: 0.03907235339283943\n",
      "Train Loss: 0.07307859510183334\n",
      "Train Loss: 0.05331483483314514\n",
      "Train Loss: 0.05800190940499306\n",
      "Train Loss: 0.11157142370939255\n",
      "Train Loss: 0.04019281640648842\n",
      "Train Loss: 0.04645410552620888\n",
      "Train Loss: 0.064618319272995\n",
      "Train Loss: 0.055315613746643066\n",
      "Train Loss: 0.056330353021621704\n",
      "Train Loss: 0.12103112787008286\n",
      "Train Loss: 0.04559721797704697\n",
      "Train Loss: 0.057317715138196945\n",
      "Train Loss: 0.06258773058652878\n",
      "Train Loss: 0.04790144041180611\n",
      "Train Loss: 0.07666142284870148\n",
      "Train Loss: 0.05758132413029671\n",
      "Train Loss: 0.045480187982320786\n",
      "Train Loss: 0.061097145080566406\n",
      "Train Loss: 0.08217569440603256\n",
      "Train Loss: 0.05200154334306717\n",
      "Train Loss: 0.06492877751588821\n",
      "Train Loss: 0.05622109770774841\n",
      "Train Loss: 0.03411531448364258\n",
      "Train Loss: 0.06596779823303223\n",
      "Train Loss: 0.040955960750579834\n",
      "Train Loss: 0.059295449405908585\n",
      "Train Loss: 0.0694945827126503\n",
      "Train Loss: 0.05565643310546875\n",
      "Train Loss: 0.060739271342754364\n",
      "Train Loss: 0.08173497766256332\n",
      "Train Loss: 0.05618942901492119\n",
      "Train Loss: 0.03408203274011612\n",
      "Train Loss: 0.06640955805778503\n",
      "Train Loss: 0.04877736046910286\n",
      "Train Loss: 0.09431349486112595\n",
      "Train Loss: 0.04340848699212074\n",
      "Train Loss: 0.24638737738132477\n",
      "Train Loss: 0.13955195248126984\n",
      "Train Loss: 0.0471077635884285\n",
      "Train Loss: 0.05872821807861328\n",
      "Train Loss: 0.0581626370549202\n",
      "Train Loss: 0.43510136008262634\n",
      "Train Loss: 0.06510169804096222\n",
      "Train Loss: 0.06045287102460861\n",
      "Train Loss: 0.04417532682418823\n",
      "Train Loss: 0.05617713928222656\n",
      "Train Loss: 0.05255503207445145\n",
      "Train Loss: 0.06946530193090439\n",
      "Train Loss: 0.09813279658555984\n",
      "Train Loss: 0.04225519299507141\n",
      "Train Loss: 0.04046604409813881\n",
      "Train Loss: 0.04435064271092415\n",
      "Train Loss: 0.054105423390865326\n",
      "Train Loss: 0.06253369152545929\n",
      "Train Loss: 0.0415547713637352\n",
      "Train Loss: 0.04911987856030464\n",
      "Train Loss: 0.06128918379545212\n",
      "Train Loss: 0.07240846008062363\n",
      "Train Loss: 0.05962014198303223\n",
      "Train Loss: 0.06676945835351944\n",
      "Train Loss: 0.05071340501308441\n",
      "Train Loss: 0.04216452315449715\n",
      "Train Loss: 0.05746857449412346\n",
      "Train Loss: 0.08711540699005127\n",
      "Train Loss: 0.05037036910653114\n",
      "Train Loss: 0.03377176448702812\n",
      "Train Loss: 0.05433323234319687\n",
      "Train Loss: 0.04243513569235802\n",
      "Train Loss: 0.053144630044698715\n",
      "Train Loss: 0.07451833784580231\n",
      "Train Loss: 0.0890233963727951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.057691533118486404\n",
      "Train Loss: 0.04575655981898308\n",
      "Train Loss: 0.0483672209084034\n",
      "Train Loss: 0.10465351492166519\n",
      "Train Loss: 0.05177747830748558\n",
      "Train Loss: 0.03623504564166069\n",
      "Train Loss: 0.12023012340068817\n",
      "Train Loss: 0.05959544703364372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfc88957c4a4bc994276cb546ce3de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.053827907890081406    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.053827907890081406   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.053827907890081406}]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = WeatherDataset(X_train, y_train)\n",
    "test_dataset = WeatherDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hyperparameters for SegRNN\n",
    "input_size = X.shape[2]  # Number of features\n",
    "hidden_size = 512  # Based on the SEGRNN paper\n",
    "output_size = X.shape[2]  # Predict all features\n",
    "segment_length = 8  # Based on the SEGRNN paper\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize SegRNNModel\n",
    "model = SegRNNModel(\n",
    "   input_size=input_size,\n",
    "   hidden_size=hidden_size,\n",
    "   output_size=output_size,\n",
    "   segment_length=segment_length,\n",
    "   learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger(\"logs\", name=\"segrnn_experiment\")\n",
    "\n",
    "# Checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "   dirpath=\"checkpoints/\",\n",
    "   filename=\"segrnn-{epoch:02d}-{val_loss:.4f}\",\n",
    "   save_top_k=1,\n",
    "   monitor=\"val_loss\",\n",
    "   mode=\"min\"\n",
    ")\n",
    "\n",
    "# Trainer with logging and checkpointing\n",
    "trainer = Trainer(\n",
    "   max_epochs=3,\n",
    "   accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "   devices=1,\n",
    "   logger=logger,\n",
    "   callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, train_loader)\n",
    "\n",
    "# Optional: Evaluate on the test set\n",
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23700), started 5:38:35 ago. (Use '!kill 23700' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8bb55dd0bec7a28a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8bb55dd0bec7a28a\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_projects",
   "language": "python",
   "name": "torch_projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
