{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from segrnn import SegRNNModel\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from utils import preprocess_and_save_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code 6B9: ./csvs/6B9.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel      1131\n",
      "relh       165\n",
      "tmpf        29\n",
      "vsby      1347\n",
      "sknt      1049\n",
      "mslp    126039\n",
      "p01i         0\n",
      "alti        10\n",
      "dwpf        29\n",
      "drct     27828\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel         0\n",
      "relh         0\n",
      "tmpf         0\n",
      "vsby         0\n",
      "sknt         0\n",
      "mslp    126039\n",
      "p01i         0\n",
      "alti         0\n",
      "dwpf         0\n",
      "drct         0\n",
      "dtype: int64\n",
      "(126039, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\6B9_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code ALB: ./csvs/ALB.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      19\n",
      "relh      13\n",
      "tmpf       4\n",
      "vsby       8\n",
      "sknt      29\n",
      "mslp    9882\n",
      "p01i    6962\n",
      "alti       1\n",
      "dwpf      13\n",
      "drct    1260\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(53649, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\ALB_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code ART: ./csvs/ART.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      125\n",
      "relh       92\n",
      "tmpf       87\n",
      "vsby      657\n",
      "sknt      210\n",
      "mslp    15717\n",
      "p01i     9670\n",
      "alti        2\n",
      "dwpf       92\n",
      "drct     1413\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(59240, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\ART_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code BGM: ./csvs/BGM.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel       77\n",
      "relh       44\n",
      "tmpf       44\n",
      "vsby       59\n",
      "sknt      181\n",
      "mslp    21729\n",
      "p01i    10542\n",
      "alti        1\n",
      "dwpf       44\n",
      "drct     1383\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(64987, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\BGM_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code BUF: ./csvs/BUF.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel       35\n",
      "relh       21\n",
      "tmpf       15\n",
      "vsby        7\n",
      "sknt       45\n",
      "mslp    13622\n",
      "p01i    10522\n",
      "alti       13\n",
      "dwpf       21\n",
      "drct      680\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(56629, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\BUF_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code DKK: ./csvs/DKK.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      421\n",
      "relh      357\n",
      "tmpf      133\n",
      "vsby      643\n",
      "sknt      388\n",
      "mslp    14869\n",
      "p01i    11662\n",
      "alti        0\n",
      "dwpf      357\n",
      "drct     1178\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(57779, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\DKK_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code DSV: ./csvs/DSV.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      296\n",
      "relh      134\n",
      "tmpf       49\n",
      "vsby      283\n",
      "sknt      518\n",
      "mslp    11878\n",
      "p01i     7756\n",
      "alti        1\n",
      "dwpf      134\n",
      "drct     3710\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(55154, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\DSV_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code ELM: ./csvs/ELM.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      236\n",
      "relh      104\n",
      "tmpf       43\n",
      "vsby      126\n",
      "sknt      443\n",
      "mslp    18285\n",
      "p01i     7779\n",
      "alti        3\n",
      "dwpf      104\n",
      "drct     2988\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(61800, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\ELM_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code ELZ: ./csvs/ELZ.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel     1278\n",
      "relh      207\n",
      "tmpf       94\n",
      "vsby      371\n",
      "sknt     1669\n",
      "mslp    27706\n",
      "p01i    14613\n",
      "alti        0\n",
      "dwpf      207\n",
      "drct     4691\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(71175, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\ELZ_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code FOK: ./csvs/FOK.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      424\n",
      "relh      405\n",
      "tmpf      351\n",
      "vsby      273\n",
      "sknt      332\n",
      "mslp    16630\n",
      "p01i     3914\n",
      "alti        2\n",
      "dwpf      405\n",
      "drct     1594\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(59241, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\FOK_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code FRG: ./csvs/FRG.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      162\n",
      "relh      124\n",
      "tmpf       95\n",
      "vsby      155\n",
      "sknt      841\n",
      "mslp    11510\n",
      "p01i     4061\n",
      "alti        0\n",
      "dwpf      124\n",
      "drct     1640\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(54766, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\FRG_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code FZY: ./csvs/FZY.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      817\n",
      "relh      632\n",
      "tmpf      500\n",
      "vsby     2358\n",
      "sknt      842\n",
      "mslp    19619\n",
      "p01i    11623\n",
      "alti        2\n",
      "dwpf      632\n",
      "drct     6902\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(61412, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\FZY_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code GFL: ./csvs/GFL.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      174\n",
      "relh       85\n",
      "tmpf       72\n",
      "vsby      426\n",
      "sknt      219\n",
      "mslp    18374\n",
      "p01i     5642\n",
      "alti        0\n",
      "dwpf       85\n",
      "drct     1508\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(60691, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\GFL_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code GTB: ./csvs/GTB.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel     128\n",
      "relh     109\n",
      "tmpf     106\n",
      "vsby      64\n",
      "sknt      69\n",
      "mslp    2788\n",
      "p01i    5725\n",
      "alti      57\n",
      "dwpf     107\n",
      "drct     264\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(81886, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\GTB_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code GVQ: ./csvs/GVQ.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel     1806\n",
      "relh     1773\n",
      "tmpf     1732\n",
      "vsby       10\n",
      "sknt     2553\n",
      "mslp    17865\n",
      "p01i    14263\n",
      "alti       28\n",
      "dwpf     1773\n",
      "drct     3468\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(58242, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\GVQ_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code HPN: ./csvs/HPN.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel     102\n",
      "relh      77\n",
      "tmpf      54\n",
      "vsby      42\n",
      "sknt     135\n",
      "mslp    4651\n",
      "p01i    4124\n",
      "alti       5\n",
      "dwpf      69\n",
      "drct    2340\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(47561, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\HPN_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code HTO: ./csvs/HTO.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      0\n",
      "relh      0\n",
      "tmpf      0\n",
      "vsby      0\n",
      "sknt      0\n",
      "mslp    110\n",
      "p01i      0\n",
      "alti      0\n",
      "dwpf      0\n",
      "drct      0\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel      0\n",
      "relh      0\n",
      "tmpf      0\n",
      "vsby      0\n",
      "sknt      0\n",
      "mslp    110\n",
      "p01i      0\n",
      "alti      0\n",
      "dwpf      0\n",
      "drct      0\n",
      "dtype: int64\n",
      "(110, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\HTO_processed.csv\n",
      "File exists for airport code HWV: ./csvs/HWV.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n",
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel      270\n",
      "relh      152\n",
      "tmpf       16\n",
      "vsby       29\n",
      "sknt      391\n",
      "mslp    13725\n",
      "p01i     4431\n",
      "alti        0\n",
      "dwpf      152\n",
      "drct     5526\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(57076, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\HWV_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code IAG: ./csvs/IAG.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      536\n",
      "relh      487\n",
      "tmpf      282\n",
      "vsby      237\n",
      "sknt      200\n",
      "mslp    15106\n",
      "p01i     9845\n",
      "alti      137\n",
      "dwpf      487\n",
      "drct      826\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(58294, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\IAG_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code ISP: ./csvs/ISP.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      26\n",
      "relh      17\n",
      "tmpf      17\n",
      "vsby      31\n",
      "sknt      38\n",
      "mslp    7033\n",
      "p01i    3818\n",
      "alti      10\n",
      "dwpf      17\n",
      "drct     552\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(50376, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\ISP_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code ITH: ./csvs/ITH.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      440\n",
      "relh      273\n",
      "tmpf      224\n",
      "vsby      971\n",
      "sknt      307\n",
      "mslp    10920\n",
      "p01i    10047\n",
      "alti       60\n",
      "dwpf      272\n",
      "drct     1409\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(53994, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\ITH_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code IUA: ./csvs/IUA.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel       30\n",
      "relh       30\n",
      "tmpf       30\n",
      "vsby      407\n",
      "sknt       26\n",
      "mslp    81772\n",
      "p01i        0\n",
      "alti       25\n",
      "dwpf       30\n",
      "drct       26\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel        0\n",
      "relh        0\n",
      "tmpf        0\n",
      "vsby        0\n",
      "sknt        0\n",
      "mslp    81772\n",
      "p01i        0\n",
      "alti        0\n",
      "dwpf        0\n",
      "drct        0\n",
      "dtype: int64\n",
      "(81772, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\IUA_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code JFK: ./csvs/JFK.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      26\n",
      "relh       7\n",
      "tmpf       6\n",
      "vsby       9\n",
      "sknt      39\n",
      "mslp    5083\n",
      "p01i    3910\n",
      "alti       1\n",
      "dwpf       7\n",
      "drct     381\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(48688, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\JFK_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code JHW: ./csvs/JHW.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel     2603\n",
      "relh     1455\n",
      "tmpf     1425\n",
      "vsby       20\n",
      "sknt     2749\n",
      "mslp    28130\n",
      "p01i    18774\n",
      "alti       24\n",
      "dwpf     1455\n",
      "drct     4497\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(70760, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\JHW_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code JPX: ./csvs/JPX.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel      2913\n",
      "relh      2913\n",
      "tmpf      2913\n",
      "vsby        30\n",
      "sknt        13\n",
      "mslp    127665\n",
      "p01i         1\n",
      "alti        13\n",
      "dwpf      2913\n",
      "drct        13\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel         0\n",
      "relh         0\n",
      "tmpf         0\n",
      "vsby         0\n",
      "sknt         0\n",
      "mslp    127665\n",
      "p01i         0\n",
      "alti         0\n",
      "dwpf         0\n",
      "drct         0\n",
      "dtype: int64\n",
      "(127665, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\JPX_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code JRB: ./csvs/JRB.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel     5249\n",
      "relh     5249\n",
      "tmpf     5085\n",
      "vsby     1846\n",
      "sknt      127\n",
      "mslp    13153\n",
      "p01i     3098\n",
      "alti       10\n",
      "dwpf     5249\n",
      "drct     9444\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(48555, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\JRB_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code LGA: ./csvs/LGA.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      10\n",
      "relh       3\n",
      "tmpf       3\n",
      "vsby       5\n",
      "sknt      21\n",
      "mslp    7154\n",
      "p01i    4439\n",
      "alti       3\n",
      "dwpf       3\n",
      "drct     860\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(50944, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\LGA_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code MGJ: ./csvs/MGJ.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel       93\n",
      "relh       39\n",
      "tmpf       39\n",
      "vsby       48\n",
      "sknt      286\n",
      "mslp    13551\n",
      "p01i     5533\n",
      "alti        1\n",
      "dwpf       39\n",
      "drct     1738\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(56171, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\MGJ_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code MSS: ./csvs/MSS.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      320\n",
      "relh      290\n",
      "tmpf      142\n",
      "vsby      192\n",
      "sknt      254\n",
      "mslp    16938\n",
      "p01i     9791\n",
      "alti        0\n",
      "dwpf      290\n",
      "drct      998\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(59579, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\MSS_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code MSV: ./csvs/MSV.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      625\n",
      "relh      584\n",
      "tmpf      392\n",
      "vsby       27\n",
      "sknt      105\n",
      "mslp    14922\n",
      "p01i     8867\n",
      "alti      365\n",
      "dwpf      583\n",
      "drct     1361\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(44144, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\MSV_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code MTP: ./csvs/MTP.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      302\n",
      "relh      219\n",
      "tmpf      169\n",
      "vsby    43017\n",
      "sknt      196\n",
      "mslp       26\n",
      "p01i        0\n",
      "alti        4\n",
      "dwpf      219\n",
      "drct     7106\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(43019, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\MTP_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code N03: ./csvs/N03.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel      1020\n",
      "relh      1020\n",
      "tmpf      1020\n",
      "vsby        16\n",
      "sknt        13\n",
      "mslp    129134\n",
      "p01i         0\n",
      "alti        12\n",
      "dwpf      1020\n",
      "drct        13\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel         0\n",
      "relh         0\n",
      "tmpf         0\n",
      "vsby         0\n",
      "sknt         0\n",
      "mslp    129134\n",
      "p01i         0\n",
      "alti         0\n",
      "dwpf         0\n",
      "drct         0\n",
      "dtype: int64\n",
      "(129134, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\N03_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code NY0: ./csvs/NY0.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel      567\n",
      "relh      562\n",
      "tmpf      556\n",
      "vsby     2062\n",
      "sknt       16\n",
      "mslp    93295\n",
      "p01i        0\n",
      "alti       66\n",
      "dwpf      562\n",
      "drct       16\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel        0\n",
      "relh        0\n",
      "tmpf        0\n",
      "vsby        0\n",
      "sknt        0\n",
      "mslp    93295\n",
      "p01i        0\n",
      "alti        0\n",
      "dwpf        0\n",
      "drct        0\n",
      "dtype: int64\n",
      "(93295, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\NY0_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code NYC: ./csvs/NYC.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel     1190\n",
      "relh      136\n",
      "tmpf       98\n",
      "vsby      158\n",
      "sknt     4715\n",
      "mslp    11122\n",
      "p01i     3768\n",
      "alti      164\n",
      "dwpf      136\n",
      "drct    21168\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(54528, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\NYC_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code OGS: ./csvs/OGS.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel        47\n",
      "relh        22\n",
      "tmpf        19\n",
      "vsby        40\n",
      "sknt       214\n",
      "mslp    130731\n",
      "p01i         0\n",
      "alti        13\n",
      "dwpf        22\n",
      "drct     15931\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel         0\n",
      "relh         0\n",
      "tmpf         0\n",
      "vsby         0\n",
      "sknt         0\n",
      "mslp    130731\n",
      "p01i         0\n",
      "alti         0\n",
      "dwpf         0\n",
      "drct         0\n",
      "dtype: int64\n",
      "(130731, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\OGS_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code OIC: ./csvs/OIC.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel     3423\n",
      "relh      624\n",
      "tmpf      624\n",
      "vsby      645\n",
      "sknt     3978\n",
      "mslp    77938\n",
      "p01i        0\n",
      "alti      607\n",
      "dwpf      624\n",
      "drct     4523\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel        0\n",
      "relh        0\n",
      "tmpf        0\n",
      "vsby        0\n",
      "sknt        0\n",
      "mslp    77938\n",
      "p01i        0\n",
      "alti        0\n",
      "dwpf        0\n",
      "drct        0\n",
      "dtype: int64\n",
      "(77938, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\OIC_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code OLE: ./csvs/OLE.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel      5038\n",
      "relh      5036\n",
      "tmpf      5036\n",
      "vsby       452\n",
      "sknt       439\n",
      "mslp    119266\n",
      "p01i         0\n",
      "alti       439\n",
      "dwpf      5036\n",
      "drct       439\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel         0\n",
      "relh         0\n",
      "tmpf         0\n",
      "vsby         0\n",
      "sknt         0\n",
      "mslp    119266\n",
      "p01i         0\n",
      "alti         0\n",
      "dwpf         0\n",
      "drct         0\n",
      "dtype: int64\n",
      "(119266, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\OLE_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code PBG: ./csvs/PBG.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      199\n",
      "relh       61\n",
      "tmpf       51\n",
      "vsby       73\n",
      "sknt      486\n",
      "mslp    10043\n",
      "p01i     6150\n",
      "alti        0\n",
      "dwpf       61\n",
      "drct     3862\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(52468, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\PBG_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code PEO: ./csvs/PEO.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      554\n",
      "relh      455\n",
      "tmpf        9\n",
      "vsby       25\n",
      "sknt      329\n",
      "mslp    16831\n",
      "p01i    10945\n",
      "alti        1\n",
      "dwpf      455\n",
      "drct     5011\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(60406, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\PEO_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist for airport code PLB: ./csvs/PLB.csv\n",
      "File exists for airport code POU: ./csvs/POU.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel       68\n",
      "relh       33\n",
      "tmpf       31\n",
      "vsby       96\n",
      "sknt      226\n",
      "mslp    11082\n",
      "p01i     2511\n",
      "alti       20\n",
      "dwpf       33\n",
      "drct     2807\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(54716, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\POU_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code PTD: ./csvs/PTD.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel       119\n",
      "relh        83\n",
      "tmpf        83\n",
      "vsby       110\n",
      "sknt       571\n",
      "mslp    127185\n",
      "p01i         0\n",
      "alti        63\n",
      "dwpf        83\n",
      "drct      3789\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel         0\n",
      "relh         0\n",
      "tmpf         0\n",
      "vsby         0\n",
      "sknt         0\n",
      "mslp    127185\n",
      "p01i         0\n",
      "alti         0\n",
      "dwpf         0\n",
      "drct         0\n",
      "dtype: int64\n",
      "(127185, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\PTD_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code RME: ./csvs/RME.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      149\n",
      "relh      139\n",
      "tmpf      115\n",
      "vsby       13\n",
      "sknt       58\n",
      "mslp    16776\n",
      "p01i     9886\n",
      "alti        1\n",
      "dwpf      139\n",
      "drct     1332\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(60375, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\RME_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code ROC: ./csvs/ROC.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel       15\n",
      "relh        3\n",
      "tmpf        2\n",
      "vsby        0\n",
      "sknt       30\n",
      "mslp    10381\n",
      "p01i    11006\n",
      "alti        1\n",
      "dwpf        3\n",
      "drct      639\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(54156, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\ROC_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code SCH: ./csvs/SCH.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n",
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feel      458\n",
      "relh      440\n",
      "tmpf      419\n",
      "vsby       41\n",
      "sknt       59\n",
      "mslp    20784\n",
      "p01i        0\n",
      "alti        2\n",
      "dwpf      417\n",
      "drct       58\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel        0\n",
      "relh        0\n",
      "tmpf        0\n",
      "vsby        0\n",
      "sknt        0\n",
      "mslp    20784\n",
      "p01i        0\n",
      "alti        0\n",
      "dwpf        0\n",
      "drct        0\n",
      "dtype: int64\n",
      "(20784, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\SCH_processed.csv\n",
      "File exists for airport code SDC: ./csvs/SDC.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel         7\n",
      "relh         6\n",
      "tmpf         6\n",
      "vsby        44\n",
      "sknt         9\n",
      "mslp    122672\n",
      "p01i         0\n",
      "alti        14\n",
      "dwpf         6\n",
      "drct         9\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel         0\n",
      "relh         0\n",
      "tmpf         0\n",
      "vsby         0\n",
      "sknt         0\n",
      "mslp    122672\n",
      "p01i         0\n",
      "alti         0\n",
      "dwpf         0\n",
      "drct         0\n",
      "dtype: int64\n",
      "(122672, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\SDC_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code SLK: ./csvs/SLK.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel      404\n",
      "relh       19\n",
      "tmpf       12\n",
      "vsby      259\n",
      "sknt      734\n",
      "mslp    29474\n",
      "p01i    12821\n",
      "alti        0\n",
      "dwpf       19\n",
      "drct     8998\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(72752, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\SLK_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code SWF: ./csvs/SWF.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel      159\n",
      "relh      124\n",
      "tmpf       74\n",
      "vsby       51\n",
      "sknt      115\n",
      "mslp    43884\n",
      "p01i        0\n",
      "alti        3\n",
      "dwpf       75\n",
      "drct     4818\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel        0\n",
      "relh        0\n",
      "tmpf        0\n",
      "vsby        0\n",
      "sknt        0\n",
      "mslp    43884\n",
      "p01i        0\n",
      "alti        0\n",
      "dwpf        0\n",
      "drct        0\n",
      "dtype: int64\n",
      "(43884, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\SWF_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists for airport code SYR: ./csvs/SYR.csv\n",
      "new function!\n",
      "Missing values in continuous columns before processing:\n",
      "feel       20\n",
      "relh        3\n",
      "tmpf        2\n",
      "vsby        7\n",
      "sknt       41\n",
      "mslp    11571\n",
      "p01i    11578\n",
      "alti       10\n",
      "dwpf        3\n",
      "drct      923\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel    0\n",
      "relh    0\n",
      "tmpf    0\n",
      "vsby    0\n",
      "sknt    0\n",
      "mslp    0\n",
      "p01i    0\n",
      "alti    0\n",
      "dwpf    0\n",
      "drct    0\n",
      "dtype: int64\n",
      "(54963, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\SYR_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist for airport code UCA: ./csvs/UCA.csv\n",
      "File exists for airport code VGC: ./csvs/VGC.csv\n",
      "new function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:57: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[continuous_cols] = df[continuous_cols].replace(placeholders, np.nan).astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in continuous columns before processing:\n",
      "feel     11819\n",
      "relh     11569\n",
      "tmpf        31\n",
      "vsby        61\n",
      "sknt      2984\n",
      "mslp    112884\n",
      "p01i         0\n",
      "alti        18\n",
      "dwpf     11569\n",
      "drct      2984\n",
      "dtype: int64\n",
      "Using fixed continuous columns: ['feel', 'relh', 'tmpf', 'vsby', 'sknt', 'mslp', 'p01i', 'alti', 'dwpf', 'drct']\n",
      "Missing values in continuous columns after processing:\n",
      "feel         0\n",
      "relh         0\n",
      "tmpf         0\n",
      "vsby         0\n",
      "sknt         0\n",
      "mslp    112884\n",
      "p01i         0\n",
      "alti         0\n",
      "dwpf         0\n",
      "drct         0\n",
      "dtype: int64\n",
      "(112884, 10)\n",
      "normalizing...\n",
      "saving csv to ./csvs\\VGC_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\segRNN\\utils.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\GitHub\\segRNN\\utils.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[continuous_cols] = df.groupby('station')[continuous_cols].transform(\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1137: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1142: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\sklearn\\utils\\extmath.py:1162: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist for airport code XNT: ./csvs/XNT.csv\n"
     ]
    }
   ],
   "source": [
    "input_csv_path = './csvs/_nylocations.csv'\n",
    "\n",
    "# Check if the file exists\n",
    "if not os.path.exists(input_csv_path):\n",
    "   raise FileNotFoundError(f\"Input CSV file not found: {input_csv_path}\")\n",
    "\n",
    "# Read the airport codes from the input CSV\n",
    "data = pd.read_csv(input_csv_path)\n",
    "airports = ['POU', 'PTD', 'RME', 'ROC', 'SCH', 'SDC', 'SLK', 'SWF', 'SYR', 'UCA', 'VGC', 'XNT']\n",
    "airports2 = ['VGC']\n",
    "# List to store airport codes that exist\n",
    "airports_exists = []\n",
    "\n",
    "# Iterate through each airport code in the CSV\n",
    "for airport_code in data['stid']:\n",
    "   csv_file_path = f'./csvs/{airport_code}.csv'\n",
    "   if os.path.exists(csv_file_path):\n",
    "      print(f\"File exists for airport code {airport_code}: {csv_file_path}\")\n",
    "      airports_exists.append(airport_code)\n",
    "      try:\n",
    "         preprocess_and_save_data(csv_file_path, normalize=True)\n",
    "      except:\n",
    "         pass\n",
    "   else:\n",
    "      print(f\"File does not exist for airport code {airport_code}: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stid</th>\n",
       "      <th>station_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elev</th>\n",
       "      <th>begints</th>\n",
       "      <th>endts</th>\n",
       "      <th>iem_network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6B9</td>\n",
       "      <td>Skaneateles</td>\n",
       "      <td>42.9140</td>\n",
       "      <td>-76.4408</td>\n",
       "      <td>304.324520</td>\n",
       "      <td>2016-07-22 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALB</td>\n",
       "      <td>ALBANY COUNTY ARPT</td>\n",
       "      <td>42.7576</td>\n",
       "      <td>-73.8036</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1945-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ART</td>\n",
       "      <td>WATERTOWN INTL ARPT</td>\n",
       "      <td>43.9888</td>\n",
       "      <td>-76.0262</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1949-04-30 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BGM</td>\n",
       "      <td>BINGHAMTON/BROOME</td>\n",
       "      <td>42.2086</td>\n",
       "      <td>-75.9797</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>1948-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BUF</td>\n",
       "      <td>BUFFALO INTL ARPT</td>\n",
       "      <td>42.9408</td>\n",
       "      <td>-78.7358</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>1942-01-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DKK</td>\n",
       "      <td>DUNKIRK AIRPORT</td>\n",
       "      <td>42.4933</td>\n",
       "      <td>-79.2720</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DSV</td>\n",
       "      <td>DANSVILLE MUNICIPAL</td>\n",
       "      <td>42.5709</td>\n",
       "      <td>-77.7130</td>\n",
       "      <td>209.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ELM</td>\n",
       "      <td>Elmira / Corning</td>\n",
       "      <td>42.1571</td>\n",
       "      <td>-76.8994</td>\n",
       "      <td>287.125370</td>\n",
       "      <td>1949-02-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ELZ</td>\n",
       "      <td>Wellsville Municipal</td>\n",
       "      <td>42.1078</td>\n",
       "      <td>-77.9842</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>1978-06-13 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FOK</td>\n",
       "      <td>WESTHAMPTON BEACH</td>\n",
       "      <td>40.8436</td>\n",
       "      <td>-72.6318</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1943-07-18 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRG</td>\n",
       "      <td>FARMINGDALE/REPUBLC</td>\n",
       "      <td>40.7288</td>\n",
       "      <td>-73.4134</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1943-04-12 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FZY</td>\n",
       "      <td>Oswego County</td>\n",
       "      <td>43.3504</td>\n",
       "      <td>-76.3831</td>\n",
       "      <td>141.826460</td>\n",
       "      <td>1997-05-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GFL</td>\n",
       "      <td>GLEN FALLS/WARREN</td>\n",
       "      <td>43.3412</td>\n",
       "      <td>-73.6103</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1949-01-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GTB</td>\n",
       "      <td>FORT DRUM/WHEELER</td>\n",
       "      <td>44.0556</td>\n",
       "      <td>-75.7195</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>1942-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GVQ</td>\n",
       "      <td>Batavia</td>\n",
       "      <td>43.0317</td>\n",
       "      <td>-78.1675</td>\n",
       "      <td>275.450840</td>\n",
       "      <td>2009-06-28 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HPN</td>\n",
       "      <td>WHITE PLAINS</td>\n",
       "      <td>41.0669</td>\n",
       "      <td>-73.7075</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HTO</td>\n",
       "      <td>EAST HAMPTON</td>\n",
       "      <td>40.9600</td>\n",
       "      <td>-72.2500</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2000-01-07 00:00</td>\n",
       "      <td>2022-03-02 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>HWV</td>\n",
       "      <td>BROOKHAVEN AIRPORT/SHIRLEY</td>\n",
       "      <td>40.8217</td>\n",
       "      <td>-72.8689</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1999-09-30 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IAG</td>\n",
       "      <td>NIAGARA FALLS INTL</td>\n",
       "      <td>43.1073</td>\n",
       "      <td>-78.9462</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>1951-06-12 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ISP</td>\n",
       "      <td>ISLIP/MACARTHUR</td>\n",
       "      <td>40.7939</td>\n",
       "      <td>-73.1017</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1972-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ITH</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>42.4910</td>\n",
       "      <td>-76.4584</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1972-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>IUA</td>\n",
       "      <td>Canandaigua</td>\n",
       "      <td>42.9089</td>\n",
       "      <td>-77.3252</td>\n",
       "      <td>244.597890</td>\n",
       "      <td>2021-10-14 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>JFK</td>\n",
       "      <td>NEW YORK/JF KENNEDY</td>\n",
       "      <td>40.6386</td>\n",
       "      <td>-73.7622</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1948-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JHW</td>\n",
       "      <td>JAMESTOWN (AWOS)</td>\n",
       "      <td>42.1534</td>\n",
       "      <td>-79.2580</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>1972-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JPX</td>\n",
       "      <td>East Hampton</td>\n",
       "      <td>40.9594</td>\n",
       "      <td>-72.2517</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1996-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JRB</td>\n",
       "      <td>Manhattan - Wall Street</td>\n",
       "      <td>40.7012</td>\n",
       "      <td>-74.0090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2016-07-21 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LGA</td>\n",
       "      <td>New York/LaGuardia</td>\n",
       "      <td>40.7794</td>\n",
       "      <td>-73.8803</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1948-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MGJ</td>\n",
       "      <td>ORANGE COUNTY AIRPORT</td>\n",
       "      <td>41.5092</td>\n",
       "      <td>-74.2650</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>1997-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MSS</td>\n",
       "      <td>MASSENA/RICHARDS</td>\n",
       "      <td>44.9358</td>\n",
       "      <td>-74.8456</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1949-02-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MSV</td>\n",
       "      <td>MONTICELLO(AWOS)</td>\n",
       "      <td>41.7016</td>\n",
       "      <td>-74.7950</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>1981-02-12 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MTP</td>\n",
       "      <td>MONTAUK AIRPORT</td>\n",
       "      <td>41.0731</td>\n",
       "      <td>-71.9233</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1975-10-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>N03</td>\n",
       "      <td>Cortland</td>\n",
       "      <td>42.5929</td>\n",
       "      <td>-76.2174</td>\n",
       "      <td>356.635200</td>\n",
       "      <td>2013-10-24 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NY0</td>\n",
       "      <td>Johnstown</td>\n",
       "      <td>42.9982</td>\n",
       "      <td>-74.3296</td>\n",
       "      <td>263.009900</td>\n",
       "      <td>2014-08-20 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NYC</td>\n",
       "      <td>NEW YORK CITY</td>\n",
       "      <td>40.7790</td>\n",
       "      <td>-73.9692</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1943-12-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>OGS</td>\n",
       "      <td>OGDENSBURG INTL</td>\n",
       "      <td>44.6819</td>\n",
       "      <td>-75.4655</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1977-05-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>OIC</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>42.5666</td>\n",
       "      <td>-75.5241</td>\n",
       "      <td>306.802000</td>\n",
       "      <td>2007-12-17 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OLE</td>\n",
       "      <td>Olean</td>\n",
       "      <td>42.2412</td>\n",
       "      <td>-78.3714</td>\n",
       "      <td>649.319760</td>\n",
       "      <td>1987-08-13 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>PBG</td>\n",
       "      <td>Plattsburgh AFB</td>\n",
       "      <td>44.6382</td>\n",
       "      <td>-73.4624</td>\n",
       "      <td>46.954082</td>\n",
       "      <td>1956-01-14 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>PEO</td>\n",
       "      <td>Penn Yan</td>\n",
       "      <td>42.6441</td>\n",
       "      <td>-77.0529</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>1997-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PLB</td>\n",
       "      <td>PLATTSBURGH/CLINTON</td>\n",
       "      <td>44.6875</td>\n",
       "      <td>-73.5245</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>1978-08-22 00:00</td>\n",
       "      <td>2007-05-22 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>POU</td>\n",
       "      <td>POUGHKEEPSIE</td>\n",
       "      <td>41.6266</td>\n",
       "      <td>-73.8842</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1948-12-31 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PTD</td>\n",
       "      <td>Potsdam</td>\n",
       "      <td>44.6757</td>\n",
       "      <td>-74.9469</td>\n",
       "      <td>140.470340</td>\n",
       "      <td>2018-02-03 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RME</td>\n",
       "      <td>Griffiss AFB / Rome</td>\n",
       "      <td>43.2239</td>\n",
       "      <td>-75.3953</td>\n",
       "      <td>143.616610</td>\n",
       "      <td>1942-07-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ROC</td>\n",
       "      <td>ROCHESTER/MONROE CO</td>\n",
       "      <td>43.1167</td>\n",
       "      <td>-77.6767</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>1948-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SCH</td>\n",
       "      <td>SCHENECTADY AIRPORT</td>\n",
       "      <td>42.8500</td>\n",
       "      <td>-73.9300</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1950-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SDC</td>\n",
       "      <td>Williamson</td>\n",
       "      <td>43.2346</td>\n",
       "      <td>-77.1195</td>\n",
       "      <td>127.863280</td>\n",
       "      <td>2017-12-08 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SLK</td>\n",
       "      <td>SARANAC LAKE/ADIRON</td>\n",
       "      <td>44.3853</td>\n",
       "      <td>-74.2062</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>1973-01-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SWF</td>\n",
       "      <td>NEWBURGH/STEWART</td>\n",
       "      <td>41.5041</td>\n",
       "      <td>-74.1048</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>1942-08-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SYR</td>\n",
       "      <td>SYRACUSE/HANCOCK</td>\n",
       "      <td>43.1112</td>\n",
       "      <td>-76.1063</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>1942-10-01 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UCA</td>\n",
       "      <td>UTICA/ONEIDA CO.</td>\n",
       "      <td>43.1451</td>\n",
       "      <td>-75.3839</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>1947-12-31 00:00</td>\n",
       "      <td>2010-12-31 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>VGC</td>\n",
       "      <td>Hamilton</td>\n",
       "      <td>42.8434</td>\n",
       "      <td>-75.5612</td>\n",
       "      <td>342.825680</td>\n",
       "      <td>2020-08-06 00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>XNT</td>\n",
       "      <td>Springville - Bertrand Chaffee</td>\n",
       "      <td>42.5084</td>\n",
       "      <td>-78.6581</td>\n",
       "      <td>423.819000</td>\n",
       "      <td>2016-08-24 00:00</td>\n",
       "      <td>2017-07-05 00:00</td>\n",
       "      <td>NY_ASOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stid                    station_name      lat      lon        elev  \\\n",
       "0   6B9                     Skaneateles  42.9140 -76.4408  304.324520   \n",
       "1   ALB              ALBANY COUNTY ARPT  42.7576 -73.8036   89.000000   \n",
       "2   ART             WATERTOWN INTL ARPT  43.9888 -76.0262   99.000000   \n",
       "3   BGM               BINGHAMTON/BROOME  42.2086 -75.9797  497.000000   \n",
       "4   BUF               BUFFALO INTL ARPT  42.9408 -78.7358  215.000000   \n",
       "5   DKK                 DUNKIRK AIRPORT  42.4933 -79.2720  203.000000   \n",
       "6   DSV             DANSVILLE MUNICIPAL  42.5709 -77.7130  209.000000   \n",
       "7   ELM                Elmira / Corning  42.1571 -76.8994  287.125370   \n",
       "8   ELZ            Wellsville Municipal  42.1078 -77.9842  639.000000   \n",
       "9   FOK               WESTHAMPTON BEACH  40.8436 -72.6318   20.000000   \n",
       "10  FRG             FARMINGDALE/REPUBLC  40.7288 -73.4134   25.000000   \n",
       "11  FZY                   Oswego County  43.3504 -76.3831  141.826460   \n",
       "12  GFL               GLEN FALLS/WARREN  43.3412 -73.6103  100.000000   \n",
       "13  GTB               FORT DRUM/WHEELER  44.0556 -75.7195  207.000000   \n",
       "14  GVQ                         Batavia  43.0317 -78.1675  275.450840   \n",
       "15  HPN                    WHITE PLAINS  41.0669 -73.7075  134.000000   \n",
       "16  HTO                    EAST HAMPTON  40.9600 -72.2500   17.000000   \n",
       "17  HWV      BROOKHAVEN AIRPORT/SHIRLEY  40.8217 -72.8689   25.000000   \n",
       "18  IAG              NIAGARA FALLS INTL  43.1073 -78.9462  180.000000   \n",
       "19  ISP                 ISLIP/MACARTHUR  40.7939 -73.1017   30.000000   \n",
       "20  ITH                          Ithaca  42.4910 -76.4584  335.000000   \n",
       "21  IUA                     Canandaigua  42.9089 -77.3252  244.597890   \n",
       "22  JFK             NEW YORK/JF KENNEDY  40.6386 -73.7622    7.000000   \n",
       "23  JHW                JAMESTOWN (AWOS)  42.1534 -79.2580  525.000000   \n",
       "24  JPX                    East Hampton  40.9594 -72.2517   11.000000   \n",
       "25  JRB         Manhattan - Wall Street  40.7012 -74.0090    0.000000   \n",
       "26  LGA              New York/LaGuardia  40.7794 -73.8803    9.000000   \n",
       "27  MGJ           ORANGE COUNTY AIRPORT  41.5092 -74.2650  111.000000   \n",
       "28  MSS                MASSENA/RICHARDS  44.9358 -74.8456   65.000000   \n",
       "29  MSV                MONTICELLO(AWOS)  41.7016 -74.7950  428.000000   \n",
       "30  MTP                 MONTAUK AIRPORT  41.0731 -71.9233    6.000000   \n",
       "31  N03                        Cortland  42.5929 -76.2174  356.635200   \n",
       "32  NY0                       Johnstown  42.9982 -74.3296  263.009900   \n",
       "33  NYC                   NEW YORK CITY  40.7790 -73.9692   27.000000   \n",
       "34  OGS                 OGDENSBURG INTL  44.6819 -75.4655   91.000000   \n",
       "35  OIC                         Norwich  42.5666 -75.5241  306.802000   \n",
       "36  OLE                           Olean  42.2412 -78.3714  649.319760   \n",
       "37  PBG                 Plattsburgh AFB  44.6382 -73.4624   46.954082   \n",
       "38  PEO                        Penn Yan  42.6441 -77.0529  267.000000   \n",
       "39  PLB             PLATTSBURGH/CLINTON  44.6875 -73.5245  113.000000   \n",
       "40  POU                    POUGHKEEPSIE  41.6266 -73.8842   51.000000   \n",
       "41  PTD                         Potsdam  44.6757 -74.9469  140.470340   \n",
       "42  RME             Griffiss AFB / Rome  43.2239 -75.3953  143.616610   \n",
       "43  ROC             ROCHESTER/MONROE CO  43.1167 -77.6767  169.000000   \n",
       "44  SCH             SCHENECTADY AIRPORT  42.8500 -73.9300  115.000000   \n",
       "45  SDC                      Williamson  43.2346 -77.1195  127.863280   \n",
       "46  SLK             SARANAC LAKE/ADIRON  44.3853 -74.2062  507.000000   \n",
       "47  SWF                NEWBURGH/STEWART  41.5041 -74.1048  150.000000   \n",
       "48  SYR                SYRACUSE/HANCOCK  43.1112 -76.1063  124.000000   \n",
       "49  UCA                UTICA/ONEIDA CO.  43.1451 -75.3839  226.000000   \n",
       "50  VGC                        Hamilton  42.8434 -75.5612  342.825680   \n",
       "51  XNT  Springville - Bertrand Chaffee  42.5084 -78.6581  423.819000   \n",
       "\n",
       "             begints             endts iem_network  \n",
       "0   2016-07-22 00:00               NaN     NY_ASOS  \n",
       "1   1945-01-01 00:00               NaN     NY_ASOS  \n",
       "2   1949-04-30 00:00               NaN     NY_ASOS  \n",
       "3   1948-01-01 00:00               NaN     NY_ASOS  \n",
       "4   1942-01-31 00:00               NaN     NY_ASOS  \n",
       "5   1948-12-31 00:00               NaN     NY_ASOS  \n",
       "6   1948-12-31 00:00               NaN     NY_ASOS  \n",
       "7   1949-02-01 00:00               NaN     NY_ASOS  \n",
       "8   1978-06-13 00:00               NaN     NY_ASOS  \n",
       "9   1943-07-18 00:00               NaN     NY_ASOS  \n",
       "10  1943-04-12 00:00               NaN     NY_ASOS  \n",
       "11  1997-05-31 00:00               NaN     NY_ASOS  \n",
       "12  1949-01-31 00:00               NaN     NY_ASOS  \n",
       "13  1942-01-01 00:00               NaN     NY_ASOS  \n",
       "14  2009-06-28 00:00               NaN     NY_ASOS  \n",
       "15  1948-12-31 00:00               NaN     NY_ASOS  \n",
       "16  2000-01-07 00:00  2022-03-02 00:00     NY_ASOS  \n",
       "17  1999-09-30 00:00               NaN     NY_ASOS  \n",
       "18  1951-06-12 00:00               NaN     NY_ASOS  \n",
       "19  1972-12-31 00:00               NaN     NY_ASOS  \n",
       "20  1972-12-31 00:00               NaN     NY_ASOS  \n",
       "21  2021-10-14 00:00               NaN     NY_ASOS  \n",
       "22  1948-07-01 00:00               NaN     NY_ASOS  \n",
       "23  1972-12-31 00:00               NaN     NY_ASOS  \n",
       "24  1996-07-01 00:00               NaN     NY_ASOS  \n",
       "25  2016-07-21 00:00               NaN     NY_ASOS  \n",
       "26  1948-07-01 00:00               NaN     NY_ASOS  \n",
       "27  1997-12-31 00:00               NaN     NY_ASOS  \n",
       "28  1949-02-01 00:00               NaN     NY_ASOS  \n",
       "29  1981-02-12 00:00               NaN     NY_ASOS  \n",
       "30  1975-10-01 00:00               NaN     NY_ASOS  \n",
       "31  2013-10-24 00:00               NaN     NY_ASOS  \n",
       "32  2014-08-20 00:00               NaN     NY_ASOS  \n",
       "33  1943-12-01 00:00               NaN     NY_ASOS  \n",
       "34  1977-05-01 00:00               NaN     NY_ASOS  \n",
       "35  2007-12-17 00:00               NaN     NY_ASOS  \n",
       "36  1987-08-13 00:00               NaN     NY_ASOS  \n",
       "37  1956-01-14 00:00               NaN     NY_ASOS  \n",
       "38  1997-12-31 00:00               NaN     NY_ASOS  \n",
       "39  1978-08-22 00:00  2007-05-22 00:00     NY_ASOS  \n",
       "40  1948-12-31 00:00               NaN     NY_ASOS  \n",
       "41  2018-02-03 00:00               NaN     NY_ASOS  \n",
       "42  1942-07-01 00:00               NaN     NY_ASOS  \n",
       "43  1948-01-01 00:00               NaN     NY_ASOS  \n",
       "44  1950-01-01 00:00               NaN     NY_ASOS  \n",
       "45  2017-12-08 00:00               NaN     NY_ASOS  \n",
       "46  1973-01-01 00:00               NaN     NY_ASOS  \n",
       "47  1942-08-01 00:00               NaN     NY_ASOS  \n",
       "48  1942-10-01 00:00               NaN     NY_ASOS  \n",
       "49  1947-12-31 00:00  2010-12-31 00:00     NY_ASOS  \n",
       "50  2020-08-06 00:00               NaN     NY_ASOS  \n",
       "51  2016-08-24 00:00  2017-07-05 00:00     NY_ASOS  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nylocations = './csvs/_nylocations.csv'\n",
    "latlongs = pd.read_csv(nylocations)\n",
    "latlongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feel</th>\n",
       "      <th>relh</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>vsby</th>\n",
       "      <th>sknt</th>\n",
       "      <th>mslp</th>\n",
       "      <th>p01i</th>\n",
       "      <th>alti</th>\n",
       "      <th>dwpf</th>\n",
       "      <th>drct</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.174910</td>\n",
       "      <td>0.697551</td>\n",
       "      <td>-1.137798</td>\n",
       "      <td>-0.933129</td>\n",
       "      <td>0.053963</td>\n",
       "      <td>0.608525</td>\n",
       "      <td>0.048107</td>\n",
       "      <td>0.519840</td>\n",
       "      <td>-0.905510</td>\n",
       "      <td>1.145016</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.203914</td>\n",
       "      <td>0.697551</td>\n",
       "      <td>-1.137798</td>\n",
       "      <td>-0.576635</td>\n",
       "      <td>0.264491</td>\n",
       "      <td>0.608525</td>\n",
       "      <td>0.048107</td>\n",
       "      <td>0.519840</td>\n",
       "      <td>-0.905510</td>\n",
       "      <td>1.240019</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.310557</td>\n",
       "      <td>0.451501</td>\n",
       "      <td>-1.191739</td>\n",
       "      <td>-2.359108</td>\n",
       "      <td>0.685546</td>\n",
       "      <td>0.608525</td>\n",
       "      <td>0.048107</td>\n",
       "      <td>0.562862</td>\n",
       "      <td>-1.031491</td>\n",
       "      <td>1.240019</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.336437</td>\n",
       "      <td>0.446870</td>\n",
       "      <td>-1.240287</td>\n",
       "      <td>-1.289624</td>\n",
       "      <td>0.475018</td>\n",
       "      <td>0.771120</td>\n",
       "      <td>0.033860</td>\n",
       "      <td>0.734950</td>\n",
       "      <td>-1.083029</td>\n",
       "      <td>1.145016</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.370348</td>\n",
       "      <td>0.076928</td>\n",
       "      <td>-1.299622</td>\n",
       "      <td>-0.576635</td>\n",
       "      <td>0.264491</td>\n",
       "      <td>0.908700</td>\n",
       "      <td>0.019614</td>\n",
       "      <td>0.864016</td>\n",
       "      <td>-1.254822</td>\n",
       "      <td>1.240019</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54151</th>\n",
       "      <td>0.289088</td>\n",
       "      <td>0.060139</td>\n",
       "      <td>0.156795</td>\n",
       "      <td>0.492850</td>\n",
       "      <td>-0.788146</td>\n",
       "      <td>-0.729753</td>\n",
       "      <td>-0.208330</td>\n",
       "      <td>-0.727798</td>\n",
       "      <td>0.234050</td>\n",
       "      <td>-0.755035</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54152</th>\n",
       "      <td>0.289088</td>\n",
       "      <td>0.060139</td>\n",
       "      <td>0.156795</td>\n",
       "      <td>0.492850</td>\n",
       "      <td>-0.788146</td>\n",
       "      <td>-0.729753</td>\n",
       "      <td>-0.208330</td>\n",
       "      <td>-0.727798</td>\n",
       "      <td>0.234050</td>\n",
       "      <td>-0.565030</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54153</th>\n",
       "      <td>0.333709</td>\n",
       "      <td>0.065349</td>\n",
       "      <td>0.210736</td>\n",
       "      <td>0.492850</td>\n",
       "      <td>-0.156564</td>\n",
       "      <td>-0.829811</td>\n",
       "      <td>-0.208330</td>\n",
       "      <td>-0.856864</td>\n",
       "      <td>0.291314</td>\n",
       "      <td>-0.565030</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54154</th>\n",
       "      <td>0.244468</td>\n",
       "      <td>0.394186</td>\n",
       "      <td>0.102854</td>\n",
       "      <td>0.492850</td>\n",
       "      <td>-1.630256</td>\n",
       "      <td>-0.892347</td>\n",
       "      <td>-0.208330</td>\n",
       "      <td>-0.899886</td>\n",
       "      <td>0.291314</td>\n",
       "      <td>-1.895066</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54155</th>\n",
       "      <td>0.199847</td>\n",
       "      <td>0.569026</td>\n",
       "      <td>0.048912</td>\n",
       "      <td>0.492850</td>\n",
       "      <td>-0.577619</td>\n",
       "      <td>-1.029927</td>\n",
       "      <td>-0.208330</td>\n",
       "      <td>-1.028952</td>\n",
       "      <td>0.291314</td>\n",
       "      <td>-0.565030</td>\n",
       "      <td>ROC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54156 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           feel      relh      tmpf      vsby      sknt      mslp      p01i  \\\n",
       "0     -1.174910  0.697551 -1.137798 -0.933129  0.053963  0.608525  0.048107   \n",
       "1     -1.203914  0.697551 -1.137798 -0.576635  0.264491  0.608525  0.048107   \n",
       "2     -1.310557  0.451501 -1.191739 -2.359108  0.685546  0.608525  0.048107   \n",
       "3     -1.336437  0.446870 -1.240287 -1.289624  0.475018  0.771120  0.033860   \n",
       "4     -1.370348  0.076928 -1.299622 -0.576635  0.264491  0.908700  0.019614   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "54151  0.289088  0.060139  0.156795  0.492850 -0.788146 -0.729753 -0.208330   \n",
       "54152  0.289088  0.060139  0.156795  0.492850 -0.788146 -0.729753 -0.208330   \n",
       "54153  0.333709  0.065349  0.210736  0.492850 -0.156564 -0.829811 -0.208330   \n",
       "54154  0.244468  0.394186  0.102854  0.492850 -1.630256 -0.892347 -0.208330   \n",
       "54155  0.199847  0.569026  0.048912  0.492850 -0.577619 -1.029927 -0.208330   \n",
       "\n",
       "           alti      dwpf      drct station  \n",
       "0      0.519840 -0.905510  1.145016     ROC  \n",
       "1      0.519840 -0.905510  1.240019     ROC  \n",
       "2      0.562862 -1.031491  1.240019     ROC  \n",
       "3      0.734950 -1.083029  1.145016     ROC  \n",
       "4      0.864016 -1.254822  1.240019     ROC  \n",
       "...         ...       ...       ...     ...  \n",
       "54151 -0.727798  0.234050 -0.755035     ROC  \n",
       "54152 -0.727798  0.234050 -0.565030     ROC  \n",
       "54153 -0.856864  0.291314 -0.565030     ROC  \n",
       "54154 -0.899886  0.291314 -1.895066     ROC  \n",
       "54155 -1.028952  0.291314 -0.565030     ROC  \n",
       "\n",
       "[54156 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc = './csvs/ROC_processed.csv'\n",
    "roc_p = pd.read_csv(roc)\n",
    "roc_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(airports_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'6B9': {'lat': 42.914, 'lon': -76.4408}, 'ALB': {'lat': 42.7576, 'lon': -73.8036}, 'ART': {'lat': 43.9888, 'lon': -76.0262}, 'BGM': {'lat': 42.2086, 'lon': -75.9797}, 'BUF': {'lat': 42.9408, 'lon': -78.7358}, 'DKK': {'lat': 42.4933, 'lon': -79.272}, 'DSV': {'lat': 42.5709, 'lon': -77.713}, 'ELM': {'lat': 42.1571, 'lon': -76.8994}, 'ELZ': {'lat': 42.1078, 'lon': -77.9842}, 'FOK': {'lat': 40.8436, 'lon': -72.6318}, 'FRG': {'lat': 40.7288, 'lon': -73.4134}, 'FZY': {'lat': 43.3504, 'lon': -76.3831}, 'GFL': {'lat': 43.3412, 'lon': -73.6103}, 'GTB': {'lat': 44.0556, 'lon': -75.7195}, 'GVQ': {'lat': 43.0317, 'lon': -78.1675}, 'HPN': {'lat': 41.0669, 'lon': -73.7075}, 'HTO': {'lat': 40.96, 'lon': -72.25}, 'HWV': {'lat': 40.8217, 'lon': -72.8689}, 'IAG': {'lat': 43.1073, 'lon': -78.9462}, 'ISP': {'lat': 40.7939, 'lon': -73.1017}, 'ITH': {'lat': 42.491, 'lon': -76.4584}, 'IUA': {'lat': 42.9089, 'lon': -77.3252}, 'JFK': {'lat': 40.6386, 'lon': -73.7622}, 'JHW': {'lat': 42.1534, 'lon': -79.258}, 'JPX': {'lat': 40.9594, 'lon': -72.2517}, 'JRB': {'lat': 40.7012, 'lon': -74.009}, 'LGA': {'lat': 40.7794, 'lon': -73.8803}, 'MGJ': {'lat': 41.5092, 'lon': -74.265}, 'MSS': {'lat': 44.9358, 'lon': -74.8456}, 'MSV': {'lat': 41.7016, 'lon': -74.795}, 'MTP': {'lat': 41.0731, 'lon': -71.9233}, 'N03': {'lat': 42.5929, 'lon': -76.2174}, 'NY0': {'lat': 42.9982, 'lon': -74.3296}, 'NYC': {'lat': 40.779, 'lon': -73.9692}, 'OGS': {'lat': 44.6819, 'lon': -75.4655}, 'OIC': {'lat': 42.5666, 'lon': -75.5241}, 'OLE': {'lat': 42.2412, 'lon': -78.3714}, 'PBG': {'lat': 44.6382, 'lon': -73.4624}, 'PEO': {'lat': 42.6441, 'lon': -77.0529}, 'POU': {'lat': 41.6266, 'lon': -73.8842}, 'PTD': {'lat': 44.6757, 'lon': -74.9469}, 'RME': {'lat': 43.2239, 'lon': -75.3953}, 'ROC': {'lat': 43.1167, 'lon': -77.6767}, 'SCH': {'lat': 42.85, 'lon': -73.93}, 'SDC': {'lat': 43.2346, 'lon': -77.1195}, 'SLK': {'lat': 44.3853, 'lon': -74.2062}, 'SWF': {'lat': 41.5041, 'lon': -74.1048}, 'SYR': {'lat': 43.1112, 'lon': -76.1063}, 'VGC': {'lat': 42.8434, 'lon': -75.5612}}\n",
      "{'6B9': './csvs/6B9_processed.csv', 'ALB': './csvs/ALB_processed.csv', 'ART': './csvs/ART_processed.csv', 'BGM': './csvs/BGM_processed.csv', 'BUF': './csvs/BUF_processed.csv', 'DKK': './csvs/DKK_processed.csv', 'DSV': './csvs/DSV_processed.csv', 'ELM': './csvs/ELM_processed.csv', 'ELZ': './csvs/ELZ_processed.csv', 'FOK': './csvs/FOK_processed.csv', 'FRG': './csvs/FRG_processed.csv', 'FZY': './csvs/FZY_processed.csv', 'GFL': './csvs/GFL_processed.csv', 'GTB': './csvs/GTB_processed.csv', 'GVQ': './csvs/GVQ_processed.csv', 'HPN': './csvs/HPN_processed.csv', 'HTO': './csvs/HTO_processed.csv', 'HWV': './csvs/HWV_processed.csv', 'IAG': './csvs/IAG_processed.csv', 'ISP': './csvs/ISP_processed.csv', 'ITH': './csvs/ITH_processed.csv', 'IUA': './csvs/IUA_processed.csv', 'JFK': './csvs/JFK_processed.csv', 'JHW': './csvs/JHW_processed.csv', 'JPX': './csvs/JPX_processed.csv', 'JRB': './csvs/JRB_processed.csv', 'LGA': './csvs/LGA_processed.csv', 'MGJ': './csvs/MGJ_processed.csv', 'MSS': './csvs/MSS_processed.csv', 'MSV': './csvs/MSV_processed.csv', 'MTP': './csvs/MTP_processed.csv', 'N03': './csvs/N03_processed.csv', 'NY0': './csvs/NY0_processed.csv', 'NYC': './csvs/NYC_processed.csv', 'OGS': './csvs/OGS_processed.csv', 'OIC': './csvs/OIC_processed.csv', 'OLE': './csvs/OLE_processed.csv', 'PBG': './csvs/PBG_processed.csv', 'PEO': './csvs/PEO_processed.csv', 'POU': './csvs/POU_processed.csv', 'PTD': './csvs/PTD_processed.csv', 'RME': './csvs/RME_processed.csv', 'ROC': './csvs/ROC_processed.csv', 'SCH': './csvs/SCH_processed.csv', 'SDC': './csvs/SDC_processed.csv', 'SLK': './csvs/SLK_processed.csv', 'SWF': './csvs/SWF_processed.csv', 'SYR': './csvs/SYR_processed.csv', 'VGC': './csvs/VGC_processed.csv'}\n",
      "latlong is tensor([0.7384, 0.2877])\n",
      "latlong is tensor([0.7375, 0.2950])\n",
      "latlong is tensor([0.7444, 0.2888])\n",
      "latlong is tensor([0.7345, 0.2889])\n",
      "latlong is tensor([0.7386, 0.2813])\n",
      "latlong is tensor([0.7361, 0.2798])\n",
      "latlong is tensor([0.7365, 0.2841])\n",
      "latlong is tensor([0.7342, 0.2864])\n",
      "latlong is tensor([0.7339, 0.2834])\n",
      "latlong is tensor([0.7269, 0.2982])\n",
      "latlong is tensor([0.7263, 0.2961])\n",
      "latlong is tensor([0.7408, 0.2878])\n",
      "latlong is tensor([0.7408, 0.2955])\n",
      "latlong is tensor([0.7448, 0.2897])\n",
      "latlong is tensor([0.7391, 0.2829])\n",
      "latlong is tensor([0.7281, 0.2953])\n",
      "latlong is tensor([0.7276, 0.2993])\n",
      "latlong is tensor([0.7268, 0.2976])\n",
      "latlong is tensor([0.7395, 0.2807])\n",
      "latlong is tensor([0.7266, 0.2969])\n",
      "latlong is tensor([0.7361, 0.2876])\n",
      "latlong is tensor([0.7384, 0.2852])\n",
      "latlong is tensor([0.7258, 0.2951])\n",
      "latlong is tensor([0.7342, 0.2798])\n",
      "latlong is tensor([0.7276, 0.2993])\n",
      "latlong is tensor([0.7261, 0.2944])\n",
      "latlong is tensor([0.7266, 0.2948])\n",
      "latlong is tensor([0.7306, 0.2937])\n",
      "latlong is tensor([0.7496, 0.2921])\n",
      "latlong is tensor([0.7317, 0.2922])\n",
      "latlong is tensor([0.7282, 0.3002])\n",
      "latlong is tensor([0.7366, 0.2883])\n",
      "latlong is tensor([0.7389, 0.2935])\n",
      "latlong is tensor([0.7265, 0.2945])\n",
      "latlong is tensor([0.7482, 0.2904])\n",
      "latlong is tensor([0.7365, 0.2902])\n",
      "latlong is tensor([0.7347, 0.2823])\n",
      "latlong is tensor([0.7480, 0.2959])\n",
      "latlong is tensor([0.7369, 0.2860])\n",
      "latlong is tensor([0.7313, 0.2948])\n",
      "latlong is tensor([0.7482, 0.2918])\n",
      "latlong is tensor([0.7401, 0.2906])\n",
      "latlong is tensor([0.7395, 0.2842])\n",
      "latlong is tensor([0.7381, 0.2946])\n",
      "latlong is tensor([0.7402, 0.2858])\n",
      "latlong is tensor([0.7466, 0.2939])\n",
      "latlong is tensor([0.7306, 0.2942])\n",
      "latlong is tensor([0.7395, 0.2886])\n",
      "latlong is tensor([0.7380, 0.2901])\n",
      "n latlongs: [[0.738411111111111, 0.28766444444444444], [0.7375422222222222, 0.29499], [0.7443822222222222, 0.2888161111111111], [0.7344922222222222, 0.2889452777777778], [0.73856, 0.2812894444444444], [0.7360738888888889, 0.2798], [0.736505, 0.28413055555555555], [0.7342061111111112, 0.28639055555555554], [0.7339322222222222, 0.2833772222222222], [0.7269088888888889, 0.298245], [0.7262711111111112, 0.2960738888888889], [0.7408355555555556, 0.2878247222222222], [0.7407844444444446, 0.29552694444444444], [0.7447533333333334, 0.2896680555555556], [0.739065, 0.28286805555555555], [0.7281494444444445, 0.29525694444444445], [0.7275555555555556, 0.29930555555555555], [0.7267872222222221, 0.2975863888888889], [0.7394850000000001, 0.280705], [0.7266327777777778, 0.29693972222222226], [0.736061111111111, 0.28761555555555557], [0.7383827777777778, 0.2852077777777778], [0.72577, 0.295105], [0.7341855555555555, 0.2798388888888889], [0.7275522222222223, 0.29930083333333335], [0.7261177777777778, 0.29441944444444446], [0.7265522222222223, 0.2947769444444444], [0.7306066666666666, 0.29370833333333335], [0.7496433333333333, 0.29209555555555555], [0.7316755555555555, 0.2922361111111111], [0.728183888888889, 0.30021305555555555], [0.7366272222222221, 0.288285], [0.7388788888888889, 0.2935288888888889], [0.72655, 0.29453], [0.7482327777777777, 0.2903736111111111], [0.736481111111111, 0.2902108333333333], [0.7346733333333333, 0.2823016666666667], [0.7479899999999999, 0.29593777777777774], [0.7369116666666667, 0.2859641666666667], [0.7312588888888889, 0.2947661111111111], [0.7481983333333334, 0.29181416666666665], [0.7401327777777779, 0.2905686111111111], [0.7395372222222223, 0.2842313888888889], [0.7380555555555556, 0.2946388888888889], [0.7401922222222223, 0.28577916666666664], [0.746585, 0.2938716666666667], [0.7305783333333333, 0.2941533333333333], [0.7395066666666666, 0.2885936111111111], [0.7380188888888889, 0.2901077777777778]]\n",
      "torch.Size([49, 12])\n",
      "node features before is:\n",
      "tensor([[ 1.2171e-02,  1.5269e-02, -6.2166e-03,  1.0089e-02,  2.2844e-02,\n",
      "                 nan,  1.0337e-02,  7.1035e-03,  9.9793e-03,  1.6842e-02,\n",
      "          7.4196e-01,  2.9205e-01],\n",
      "        [-2.5096e-03, -3.5381e-03, -3.4048e-03,  8.8977e-03, -1.3887e-02,\n",
      "         -8.2461e-03, -1.2837e-02, -2.8030e-03, -1.1055e-02, -9.4431e-03,\n",
      "          7.4074e-01,  3.0174e-01],\n",
      "        [-7.8208e-03, -2.6047e-03, -3.2194e-03,  1.2828e-02,  4.4612e-03,\n",
      "         -3.1503e-03,  4.2263e-03,  1.5539e-02,  1.1382e-02,  6.5313e-04,\n",
      "          7.4073e-01,  2.6539e-01],\n",
      "        [-6.1210e-04,  1.2859e-03,  1.2647e-03,  1.4171e-02, -3.0260e-03,\n",
      "          1.1638e-02,  6.1556e-03,  8.4128e-03, -1.2088e-02, -1.8693e-02,\n",
      "          7.3362e-01,  2.9464e-01],\n",
      "        [-6.2156e-03, -4.6122e-03,  1.1162e-02,  3.5427e-03,  1.1040e-03,\n",
      "         -2.6655e-02,  5.5445e-03,  5.6716e-03,  6.5956e-04,  4.7071e-03,\n",
      "          7.4641e-01,  2.8504e-01],\n",
      "        [ 2.6136e-02,  4.3709e-03,  4.7666e-03,  4.6915e-03, -1.0764e-02,\n",
      "          1.2271e-02,  1.0791e-02,  3.2878e-04, -9.7808e-03, -4.4114e-04,\n",
      "          7.3373e-01,  2.7168e-01],\n",
      "        [ 5.5534e-03, -2.0287e-02, -1.9273e-02, -8.1734e-03,  4.1366e-03,\n",
      "          8.5021e-03,  6.6137e-03,  1.1351e-02,  1.2174e-02, -1.4715e-02,\n",
      "          7.3952e-01,  2.7992e-01],\n",
      "        [ 4.5207e-03, -9.5818e-03, -9.0035e-03, -3.4317e-03, -1.7524e-02,\n",
      "         -1.5670e-02, -1.3918e-03,  1.7447e-03, -3.2770e-03,  2.4046e-03,\n",
      "          7.3344e-01,  2.8389e-01],\n",
      "        [-6.0047e-03, -3.4926e-03, -3.2278e-03, -1.1985e-02,  8.9921e-03,\n",
      "         -1.6305e-02,  5.1242e-03, -1.7986e-02, -1.4190e-02,  1.8259e-02,\n",
      "          7.3692e-01,  2.8660e-01],\n",
      "        [-9.7094e-03, -1.2541e-02,  1.4518e-03,  7.8559e-03, -9.1971e-03,\n",
      "         -3.0959e-03, -8.5705e-03,  1.1634e-03,  1.6516e-03, -4.1056e-03,\n",
      "          7.2154e-01,  2.9658e-01],\n",
      "        [ 5.5299e-03,  4.3376e-03,  2.3522e-02,  4.6219e-03, -1.6018e-02,\n",
      "          1.7624e-02, -6.1799e-03,  1.7243e-02,  9.3998e-03,  6.7354e-03,\n",
      "          7.1936e-01,  2.9550e-01],\n",
      "        [ 2.0665e-04,  1.0332e-02,  7.3888e-03, -1.2438e-03, -2.5383e-03,\n",
      "         -5.7243e-03, -8.7132e-03, -5.8063e-03,  4.8654e-03, -7.5082e-03,\n",
      "          7.2814e-01,  2.7875e-01],\n",
      "        [ 1.0130e-02,  2.1659e-03, -4.3037e-03,  9.8520e-04,  9.4047e-03,\n",
      "         -3.1540e-03,  9.2515e-03, -1.2592e-03,  8.9317e-03,  1.0783e-02,\n",
      "          7.5232e-01,  3.2464e-01],\n",
      "        [-6.0516e-03,  9.0574e-03, -2.1470e-02,  5.4607e-03,  1.4401e-02,\n",
      "         -8.9900e-03,  4.0069e-03,  2.3320e-03,  2.5292e-04,  3.2572e-03,\n",
      "          7.6233e-01,  2.8074e-01],\n",
      "        [-2.3321e-02,  1.6143e-03, -1.7963e-04, -1.5655e-02,  2.3248e-02,\n",
      "         -1.4463e-02,  6.1653e-04, -1.0495e-02, -7.6582e-04,  6.3140e-03,\n",
      "          7.5568e-01,  2.6778e-01],\n",
      "        [-2.8576e-03,  1.2096e-02, -3.9867e-03, -7.5008e-03, -6.9220e-03,\n",
      "          6.9040e-04, -1.3417e-02,  1.7211e-02,  2.3239e-02, -4.0759e-03,\n",
      "          7.1626e-01,  3.0387e-01],\n",
      "        [ 1.1175e-02, -2.7699e-03, -1.4713e-02, -5.6487e-03, -5.9063e-03,\n",
      "                 nan, -1.1019e-02,  5.3110e-03, -8.1859e-03, -7.5331e-03,\n",
      "          7.1300e-01,  2.7804e-01],\n",
      "        [-5.6900e-03,  1.0372e-04,  1.2890e-02, -2.1401e-02, -1.2173e-02,\n",
      "          4.2663e-04,  4.6755e-03, -4.9433e-03,  3.0683e-03,  9.9464e-03,\n",
      "          7.5234e-01,  2.8727e-01],\n",
      "        [-1.9841e-03,  7.0862e-03, -6.8731e-04, -2.0510e-03, -1.3405e-02,\n",
      "         -1.8463e-02,  5.4639e-04,  1.7514e-03,  3.5909e-03,  7.2348e-03,\n",
      "          7.3399e-01,  2.7801e-01],\n",
      "        [ 1.0923e-02, -1.6336e-02,  5.8942e-03,  5.7168e-04, -9.0578e-03,\n",
      "         -6.9596e-03,  1.7476e-03,  6.1322e-03, -1.7205e-03,  5.4902e-03,\n",
      "          7.2011e-01,  2.9968e-01],\n",
      "        [-2.4366e-02, -6.3761e-03, -4.4081e-03,  2.1519e-03, -1.4072e-02,\n",
      "         -5.4415e-03,  1.6858e-02,  7.6160e-03,  1.5218e-02, -1.0157e-02,\n",
      "          7.2348e-01,  2.9418e-01],\n",
      "        [-5.9760e-03, -9.3907e-04, -8.3637e-03,  7.2676e-03,  7.6391e-03,\n",
      "                 nan, -9.3829e-04, -1.2164e-02, -1.3141e-02, -9.0073e-03,\n",
      "          7.4332e-01,  2.9056e-01],\n",
      "        [-1.3927e-02,  2.5374e-03, -1.7196e-02, -6.2592e-03,  8.1683e-03,\n",
      "         -4.0887e-03,  9.6138e-03, -3.8342e-03, -1.2452e-02, -1.5066e-02,\n",
      "          7.2144e-01,  2.9990e-01],\n",
      "        [ 2.7478e-03,  5.6427e-03, -2.3638e-03,  2.1452e-02,  8.6999e-03,\n",
      "         -1.2549e-02, -1.0454e-02, -8.5801e-04,  3.5177e-03,  5.6957e-04,\n",
      "          7.3552e-01,  2.6218e-01],\n",
      "        [-2.2541e-03,  4.6993e-03,  6.2904e-04, -4.2663e-03,  1.3647e-02,\n",
      "                 nan, -7.0145e-03, -2.7366e-03,  7.5251e-03, -5.4856e-03,\n",
      "          7.2711e-01,  2.8681e-01],\n",
      "        [ 1.1901e-03, -2.2576e-03, -4.2917e-03, -7.7175e-03, -4.0281e-03,\n",
      "         -8.5773e-03,  6.2461e-03, -1.2540e-02,  2.0729e-03, -2.8724e-02,\n",
      "          7.2743e-01,  2.8527e-01],\n",
      "        [ 2.0528e-02,  5.9969e-03, -5.3090e-03,  1.6143e-02,  1.9130e-03,\n",
      "          1.8259e-02, -1.9352e-02,  7.7118e-03,  4.6747e-03,  5.1192e-03,\n",
      "          7.3929e-01,  2.9367e-01],\n",
      "        [ 6.0811e-03,  1.9894e-02, -2.2919e-03, -1.0835e-03, -1.1803e-02,\n",
      "          5.4001e-03,  8.2466e-03, -3.0928e-03, -1.1076e-02,  5.5755e-03,\n",
      "          7.1667e-01,  2.9106e-01],\n",
      "        [-6.0629e-03, -1.5609e-02, -8.6702e-04, -1.5417e-02, -9.9382e-03,\n",
      "         -1.4232e-02,  2.0661e-02, -2.4410e-03,  1.1269e-02, -1.4058e-02,\n",
      "          7.4120e-01,  2.9378e-01],\n",
      "        [-3.0188e-03,  4.4326e-03,  8.2043e-03,  7.7046e-03, -4.4316e-03,\n",
      "         -1.3377e-02,  6.8208e-03, -3.9041e-04,  9.2208e-03,  1.1486e-02,\n",
      "          7.4178e-01,  2.9514e-01],\n",
      "        [-2.1707e-02, -2.2369e-02,  3.6374e-03,  1.6840e-03,  3.1107e-03,\n",
      "         -1.8928e-02,  1.2287e-02,  2.6062e-03,  2.1117e-02, -5.5739e-03,\n",
      "          7.2518e-01,  2.9939e-01],\n",
      "        [ 3.7289e-03,  1.3662e-02,  4.6108e-03,  1.3856e-02, -4.8066e-03,\n",
      "                 nan,  1.1567e-02, -6.3124e-03,  1.8491e-02,  1.7021e-02,\n",
      "          7.6358e-01,  2.8246e-01],\n",
      "        [ 2.3976e-02,  5.0857e-04, -1.4242e-02,  5.4251e-03,  2.4531e-03,\n",
      "                 nan, -1.9956e-02,  1.2500e-03,  1.4692e-02, -7.5933e-03,\n",
      "          7.5305e-01,  2.9257e-01],\n",
      "        [-2.0005e-02,  4.7404e-03, -1.3461e-02,  2.1001e-05, -3.3580e-03,\n",
      "         -8.2720e-03, -8.6927e-03,  8.6019e-03,  3.2097e-03,  1.0578e-02,\n",
      "          7.2068e-01,  3.0331e-01],\n",
      "        [-1.5420e-02,  2.6696e-03, -2.0433e-03,  5.6527e-03, -1.8199e-02,\n",
      "                 nan, -1.1607e-02,  1.1056e-02, -4.2397e-03,  1.3280e-02,\n",
      "          7.4151e-01,  2.7109e-01],\n",
      "        [ 3.5108e-03,  1.4867e-03, -8.1003e-03,  1.0602e-03,  2.0284e-04,\n",
      "                 nan,  1.1317e-02,  2.4938e-03, -9.5986e-03, -7.1404e-03,\n",
      "          7.3734e-01,  3.0875e-01],\n",
      "        [-7.5632e-03, -2.5740e-03,  3.9065e-03,  5.8527e-03,  4.1617e-03,\n",
      "                 nan,  7.9323e-03, -3.3286e-03,  4.7026e-03, -2.1791e-03,\n",
      "          7.4217e-01,  2.7127e-01],\n",
      "        [-1.3394e-03,  1.0358e-02, -1.7018e-02,  1.2489e-02,  8.5137e-04,\n",
      "         -4.4742e-03, -1.4399e-02,  1.8518e-03,  1.6710e-03,  2.9716e-03,\n",
      "          7.4599e-01,  2.9501e-01],\n",
      "        [ 9.9977e-03,  5.9548e-03,  7.0311e-03, -3.7420e-03, -6.9640e-04,\n",
      "          1.2530e-02, -4.6140e-03, -1.8742e-03,  5.7159e-03,  8.1090e-03,\n",
      "          7.3720e-01,  2.8229e-01],\n",
      "        [-1.2722e-02,  1.0324e-02,  6.7640e-03, -3.9738e-03, -1.0685e-03,\n",
      "         -2.7016e-03,  1.0264e-03, -1.2112e-02,  3.1288e-03,  3.1588e-03,\n",
      "          7.4447e-01,  2.9486e-01],\n",
      "        [ 1.3322e-02, -1.7351e-02,  6.0449e-03, -1.3029e-02, -1.6487e-02,\n",
      "                 nan, -2.6239e-03,  1.1408e-03,  7.4688e-03,  4.8256e-03,\n",
      "          7.5058e-01,  2.9657e-01],\n",
      "        [-8.9454e-03, -1.2466e-02, -1.2546e-03,  4.6677e-03,  6.0697e-03,\n",
      "          1.4255e-02, -1.7330e-03,  5.4636e-04, -3.2609e-03, -4.0092e-03,\n",
      "          7.2058e-01,  2.8248e-01],\n",
      "        [-1.3672e-03, -9.2414e-03,  3.4581e-03,  3.8780e-04,  1.0554e-02,\n",
      "         -6.4124e-03, -1.8393e-03, -7.2935e-03,  1.1679e-02, -2.4111e-02,\n",
      "          7.4326e-01,  2.6880e-01],\n",
      "        [ 4.6015e-03,  6.9050e-03, -2.0043e-03, -3.0638e-03,  1.5034e-02,\n",
      "                 nan, -5.3577e-03,  1.0097e-02,  1.1312e-02, -1.0243e-02,\n",
      "          7.3533e-01,  2.8167e-01],\n",
      "        [-1.3511e-02, -8.6917e-03, -2.1241e-02, -1.7681e-02,  1.8688e-03,\n",
      "                 nan,  8.3368e-03, -1.1987e-02,  4.2447e-04, -6.9634e-03,\n",
      "          7.3409e-01,  2.9088e-01],\n",
      "        [-1.3261e-02,  1.3626e-02, -6.4971e-04,  2.1666e-04,  6.7442e-03,\n",
      "          5.4190e-03,  1.9932e-02, -1.2994e-02, -2.4582e-03,  7.8504e-03,\n",
      "          7.3625e-01,  3.1198e-01],\n",
      "        [-4.4738e-03,  1.1539e-02,  4.6894e-03, -6.7376e-03,  6.9642e-03,\n",
      "                 nan,  1.0074e-02, -1.2567e-02,  1.4478e-02,  5.3884e-03,\n",
      "          7.3795e-01,  2.8492e-01],\n",
      "        [ 7.3684e-03,  7.0611e-03,  1.4515e-02, -8.3439e-03, -4.7031e-03,\n",
      "          2.2524e-03, -2.0003e-02, -5.4716e-03, -9.0828e-03,  1.1989e-02,\n",
      "          7.1117e-01,  2.9499e-01],\n",
      "        [-1.9923e-03,  5.3186e-03, -2.8071e-02,  1.6215e-03, -8.6260e-03,\n",
      "                 nan,  5.7113e-03, -1.1526e-02,  2.8831e-02, -2.1785e-02,\n",
      "          7.4832e-01,  2.8955e-01]])\n",
      "Node features after replacing NaNs with small random noise:\n",
      "tensor([[ 1.2171e-02,  1.5269e-02, -6.2166e-03,  1.0089e-02,  2.2844e-02,\n",
      "         -1.0270e-05,  1.0337e-02,  7.1035e-03,  9.9793e-03,  1.6842e-02,\n",
      "          7.4196e-01,  2.9205e-01],\n",
      "        [-2.5096e-03, -3.5381e-03, -3.4048e-03,  8.8977e-03, -1.3887e-02,\n",
      "         -8.2461e-03, -1.2837e-02, -2.8030e-03, -1.1055e-02, -9.4431e-03,\n",
      "          7.4074e-01,  3.0174e-01],\n",
      "        [-7.8208e-03, -2.6047e-03, -3.2194e-03,  1.2828e-02,  4.4612e-03,\n",
      "         -3.1503e-03,  4.2263e-03,  1.5539e-02,  1.1382e-02,  6.5313e-04,\n",
      "          7.4073e-01,  2.6539e-01],\n",
      "        [-6.1210e-04,  1.2859e-03,  1.2647e-03,  1.4171e-02, -3.0260e-03,\n",
      "          1.1638e-02,  6.1556e-03,  8.4128e-03, -1.2088e-02, -1.8693e-02,\n",
      "          7.3362e-01,  2.9464e-01],\n",
      "        [-6.2156e-03, -4.6122e-03,  1.1162e-02,  3.5427e-03,  1.1040e-03,\n",
      "         -2.6655e-02,  5.5445e-03,  5.6716e-03,  6.5956e-04,  4.7071e-03,\n",
      "          7.4641e-01,  2.8504e-01],\n",
      "        [ 2.6136e-02,  4.3709e-03,  4.7666e-03,  4.6915e-03, -1.0764e-02,\n",
      "          1.2271e-02,  1.0791e-02,  3.2878e-04, -9.7808e-03, -4.4114e-04,\n",
      "          7.3373e-01,  2.7168e-01],\n",
      "        [ 5.5534e-03, -2.0287e-02, -1.9273e-02, -8.1734e-03,  4.1366e-03,\n",
      "          8.5021e-03,  6.6137e-03,  1.1351e-02,  1.2174e-02, -1.4715e-02,\n",
      "          7.3952e-01,  2.7992e-01],\n",
      "        [ 4.5207e-03, -9.5818e-03, -9.0035e-03, -3.4317e-03, -1.7524e-02,\n",
      "         -1.5670e-02, -1.3918e-03,  1.7447e-03, -3.2770e-03,  2.4046e-03,\n",
      "          7.3344e-01,  2.8389e-01],\n",
      "        [-6.0047e-03, -3.4926e-03, -3.2278e-03, -1.1985e-02,  8.9921e-03,\n",
      "         -1.6305e-02,  5.1242e-03, -1.7986e-02, -1.4190e-02,  1.8259e-02,\n",
      "          7.3692e-01,  2.8660e-01],\n",
      "        [-9.7094e-03, -1.2541e-02,  1.4518e-03,  7.8559e-03, -9.1971e-03,\n",
      "         -3.0959e-03, -8.5705e-03,  1.1634e-03,  1.6516e-03, -4.1056e-03,\n",
      "          7.2154e-01,  2.9658e-01],\n",
      "        [ 5.5299e-03,  4.3376e-03,  2.3522e-02,  4.6219e-03, -1.6018e-02,\n",
      "          1.7624e-02, -6.1799e-03,  1.7243e-02,  9.3998e-03,  6.7354e-03,\n",
      "          7.1936e-01,  2.9550e-01],\n",
      "        [ 2.0665e-04,  1.0332e-02,  7.3888e-03, -1.2438e-03, -2.5383e-03,\n",
      "         -5.7243e-03, -8.7132e-03, -5.8063e-03,  4.8654e-03, -7.5082e-03,\n",
      "          7.2814e-01,  2.7875e-01],\n",
      "        [ 1.0130e-02,  2.1659e-03, -4.3037e-03,  9.8520e-04,  9.4047e-03,\n",
      "         -3.1540e-03,  9.2515e-03, -1.2592e-03,  8.9317e-03,  1.0783e-02,\n",
      "          7.5232e-01,  3.2464e-01],\n",
      "        [-6.0516e-03,  9.0574e-03, -2.1470e-02,  5.4607e-03,  1.4401e-02,\n",
      "         -8.9900e-03,  4.0069e-03,  2.3320e-03,  2.5292e-04,  3.2572e-03,\n",
      "          7.6233e-01,  2.8074e-01],\n",
      "        [-2.3321e-02,  1.6143e-03, -1.7963e-04, -1.5655e-02,  2.3248e-02,\n",
      "         -1.4463e-02,  6.1653e-04, -1.0495e-02, -7.6582e-04,  6.3140e-03,\n",
      "          7.5568e-01,  2.6778e-01],\n",
      "        [-2.8576e-03,  1.2096e-02, -3.9867e-03, -7.5008e-03, -6.9220e-03,\n",
      "          6.9040e-04, -1.3417e-02,  1.7211e-02,  2.3239e-02, -4.0759e-03,\n",
      "          7.1626e-01,  3.0387e-01],\n",
      "        [ 1.1175e-02, -2.7699e-03, -1.4713e-02, -5.6487e-03, -5.9063e-03,\n",
      "         -6.9843e-05, -1.1019e-02,  5.3110e-03, -8.1859e-03, -7.5331e-03,\n",
      "          7.1300e-01,  2.7804e-01],\n",
      "        [-5.6900e-03,  1.0372e-04,  1.2890e-02, -2.1401e-02, -1.2173e-02,\n",
      "          4.2663e-04,  4.6755e-03, -4.9433e-03,  3.0683e-03,  9.9464e-03,\n",
      "          7.5234e-01,  2.8727e-01],\n",
      "        [-1.9841e-03,  7.0862e-03, -6.8731e-04, -2.0510e-03, -1.3405e-02,\n",
      "         -1.8463e-02,  5.4639e-04,  1.7514e-03,  3.5909e-03,  7.2348e-03,\n",
      "          7.3399e-01,  2.7801e-01],\n",
      "        [ 1.0923e-02, -1.6336e-02,  5.8942e-03,  5.7168e-04, -9.0578e-03,\n",
      "         -6.9596e-03,  1.7476e-03,  6.1322e-03, -1.7205e-03,  5.4902e-03,\n",
      "          7.2011e-01,  2.9968e-01],\n",
      "        [-2.4366e-02, -6.3761e-03, -4.4081e-03,  2.1519e-03, -1.4072e-02,\n",
      "         -5.4415e-03,  1.6858e-02,  7.6160e-03,  1.5218e-02, -1.0157e-02,\n",
      "          7.2348e-01,  2.9418e-01],\n",
      "        [-5.9760e-03, -9.3907e-04, -8.3637e-03,  7.2676e-03,  7.6391e-03,\n",
      "          4.6306e-05, -9.3829e-04, -1.2164e-02, -1.3141e-02, -9.0073e-03,\n",
      "          7.4332e-01,  2.9056e-01],\n",
      "        [-1.3927e-02,  2.5374e-03, -1.7196e-02, -6.2592e-03,  8.1683e-03,\n",
      "         -4.0887e-03,  9.6138e-03, -3.8342e-03, -1.2452e-02, -1.5066e-02,\n",
      "          7.2144e-01,  2.9990e-01],\n",
      "        [ 2.7478e-03,  5.6427e-03, -2.3638e-03,  2.1452e-02,  8.6999e-03,\n",
      "         -1.2549e-02, -1.0454e-02, -8.5801e-04,  3.5177e-03,  5.6957e-04,\n",
      "          7.3552e-01,  2.6218e-01],\n",
      "        [-2.2541e-03,  4.6993e-03,  6.2904e-04, -4.2663e-03,  1.3647e-02,\n",
      "          2.5542e-05, -7.0145e-03, -2.7366e-03,  7.5251e-03, -5.4856e-03,\n",
      "          7.2711e-01,  2.8681e-01],\n",
      "        [ 1.1901e-03, -2.2576e-03, -4.2917e-03, -7.7175e-03, -4.0281e-03,\n",
      "         -8.5773e-03,  6.2461e-03, -1.2540e-02,  2.0729e-03, -2.8724e-02,\n",
      "          7.2743e-01,  2.8527e-01],\n",
      "        [ 2.0528e-02,  5.9969e-03, -5.3090e-03,  1.6143e-02,  1.9130e-03,\n",
      "          1.8259e-02, -1.9352e-02,  7.7118e-03,  4.6747e-03,  5.1192e-03,\n",
      "          7.3929e-01,  2.9367e-01],\n",
      "        [ 6.0811e-03,  1.9894e-02, -2.2919e-03, -1.0835e-03, -1.1803e-02,\n",
      "          5.4001e-03,  8.2466e-03, -3.0928e-03, -1.1076e-02,  5.5755e-03,\n",
      "          7.1667e-01,  2.9106e-01],\n",
      "        [-6.0629e-03, -1.5609e-02, -8.6702e-04, -1.5417e-02, -9.9382e-03,\n",
      "         -1.4232e-02,  2.0661e-02, -2.4410e-03,  1.1269e-02, -1.4058e-02,\n",
      "          7.4120e-01,  2.9378e-01],\n",
      "        [-3.0188e-03,  4.4326e-03,  8.2043e-03,  7.7046e-03, -4.4316e-03,\n",
      "         -1.3377e-02,  6.8208e-03, -3.9041e-04,  9.2208e-03,  1.1486e-02,\n",
      "          7.4178e-01,  2.9514e-01],\n",
      "        [-2.1707e-02, -2.2369e-02,  3.6374e-03,  1.6840e-03,  3.1107e-03,\n",
      "         -1.8928e-02,  1.2287e-02,  2.6062e-03,  2.1117e-02, -5.5739e-03,\n",
      "          7.2518e-01,  2.9939e-01],\n",
      "        [ 3.7289e-03,  1.3662e-02,  4.6108e-03,  1.3856e-02, -4.8066e-03,\n",
      "         -1.5373e-04,  1.1567e-02, -6.3124e-03,  1.8491e-02,  1.7021e-02,\n",
      "          7.6358e-01,  2.8246e-01],\n",
      "        [ 2.3976e-02,  5.0857e-04, -1.4242e-02,  5.4251e-03,  2.4531e-03,\n",
      "         -5.7388e-05, -1.9956e-02,  1.2500e-03,  1.4692e-02, -7.5933e-03,\n",
      "          7.5305e-01,  2.9257e-01],\n",
      "        [-2.0005e-02,  4.7404e-03, -1.3461e-02,  2.1001e-05, -3.3580e-03,\n",
      "         -8.2720e-03, -8.6927e-03,  8.6019e-03,  3.2097e-03,  1.0578e-02,\n",
      "          7.2068e-01,  3.0331e-01],\n",
      "        [-1.5420e-02,  2.6696e-03, -2.0433e-03,  5.6527e-03, -1.8199e-02,\n",
      "         -1.1518e-04, -1.1607e-02,  1.1056e-02, -4.2397e-03,  1.3280e-02,\n",
      "          7.4151e-01,  2.7109e-01],\n",
      "        [ 3.5108e-03,  1.4867e-03, -8.1003e-03,  1.0602e-03,  2.0284e-04,\n",
      "          1.2736e-04,  1.1317e-02,  2.4938e-03, -9.5986e-03, -7.1404e-03,\n",
      "          7.3734e-01,  3.0875e-01],\n",
      "        [-7.5632e-03, -2.5740e-03,  3.9065e-03,  5.8527e-03,  4.1617e-03,\n",
      "         -1.5560e-04,  7.9323e-03, -3.3286e-03,  4.7026e-03, -2.1791e-03,\n",
      "          7.4217e-01,  2.7127e-01],\n",
      "        [-1.3394e-03,  1.0358e-02, -1.7018e-02,  1.2489e-02,  8.5137e-04,\n",
      "         -4.4742e-03, -1.4399e-02,  1.8518e-03,  1.6710e-03,  2.9716e-03,\n",
      "          7.4599e-01,  2.9501e-01],\n",
      "        [ 9.9977e-03,  5.9548e-03,  7.0311e-03, -3.7420e-03, -6.9640e-04,\n",
      "          1.2530e-02, -4.6140e-03, -1.8742e-03,  5.7159e-03,  8.1090e-03,\n",
      "          7.3720e-01,  2.8229e-01],\n",
      "        [-1.2722e-02,  1.0324e-02,  6.7640e-03, -3.9738e-03, -1.0685e-03,\n",
      "         -2.7016e-03,  1.0264e-03, -1.2112e-02,  3.1288e-03,  3.1588e-03,\n",
      "          7.4447e-01,  2.9486e-01],\n",
      "        [ 1.3322e-02, -1.7351e-02,  6.0449e-03, -1.3029e-02, -1.6487e-02,\n",
      "         -5.9893e-05, -2.6239e-03,  1.1408e-03,  7.4688e-03,  4.8256e-03,\n",
      "          7.5058e-01,  2.9657e-01],\n",
      "        [-8.9454e-03, -1.2466e-02, -1.2546e-03,  4.6677e-03,  6.0697e-03,\n",
      "          1.4255e-02, -1.7330e-03,  5.4636e-04, -3.2609e-03, -4.0092e-03,\n",
      "          7.2058e-01,  2.8248e-01],\n",
      "        [-1.3672e-03, -9.2414e-03,  3.4581e-03,  3.8780e-04,  1.0554e-02,\n",
      "         -6.4124e-03, -1.8393e-03, -7.2935e-03,  1.1679e-02, -2.4111e-02,\n",
      "          7.4326e-01,  2.6880e-01],\n",
      "        [ 4.6015e-03,  6.9050e-03, -2.0043e-03, -3.0638e-03,  1.5034e-02,\n",
      "         -2.2205e-04, -5.3577e-03,  1.0097e-02,  1.1312e-02, -1.0243e-02,\n",
      "          7.3533e-01,  2.8167e-01],\n",
      "        [-1.3511e-02, -8.6917e-03, -2.1241e-02, -1.7681e-02,  1.8688e-03,\n",
      "         -2.0410e-05,  8.3368e-03, -1.1987e-02,  4.2447e-04, -6.9634e-03,\n",
      "          7.3409e-01,  2.9088e-01],\n",
      "        [-1.3261e-02,  1.3626e-02, -6.4971e-04,  2.1666e-04,  6.7442e-03,\n",
      "          5.4190e-03,  1.9932e-02, -1.2994e-02, -2.4582e-03,  7.8504e-03,\n",
      "          7.3625e-01,  3.1198e-01],\n",
      "        [-4.4738e-03,  1.1539e-02,  4.6894e-03, -6.7376e-03,  6.9642e-03,\n",
      "         -4.4851e-05,  1.0074e-02, -1.2567e-02,  1.4478e-02,  5.3884e-03,\n",
      "          7.3795e-01,  2.8492e-01],\n",
      "        [ 7.3684e-03,  7.0611e-03,  1.4515e-02, -8.3439e-03, -4.7031e-03,\n",
      "          2.2524e-03, -2.0003e-02, -5.4716e-03, -9.0828e-03,  1.1989e-02,\n",
      "          7.1117e-01,  2.9499e-01],\n",
      "        [-1.9923e-03,  5.3186e-03, -2.8071e-02,  1.6215e-03, -8.6260e-03,\n",
      "         -9.8056e-05,  5.7113e-03, -1.1526e-02,  2.8831e-02, -2.1785e-02,\n",
      "          7.4832e-01,  2.8955e-01]])\n",
      "tensor([1.2748e-04, 9.3173e-05, 1.0145e-04, 8.3604e-05, 1.0458e-04, 8.9816e-05,\n",
      "        1.0385e-04, 7.0035e-05, 1.0164e-04, 1.1990e-04, 1.5629e-04, 1.5388e-04])\n",
      "Distance Matrix:\n",
      "[[0.         0.00737691 0.00608116 ... 0.01017143 0.00143652 0.00247461]\n",
      " [0.00737691 0.         0.00921426 ... 0.00701397 0.00669125 0.00490544]\n",
      " [0.00608116 0.00921426 0.         ... 0.01479977 0.00488063 0.00649311]\n",
      " ...\n",
      " [0.01017143 0.00701397 0.01479977 ... 0.         0.01051787 0.00846926]\n",
      " [0.00143652 0.00669125 0.00488063 ... 0.01051787 0.         0.00212278]\n",
      " [0.00247461 0.00490544 0.00649311 ... 0.00846926 0.00212278 0.        ]]\n",
      "Edge Index:\n",
      "tensor([[ 0,  0,  0,  ..., 48, 48, 48],\n",
      "        [ 1,  2,  3,  ..., 44, 46, 47]])\n",
      "Data(x=[49, 12], edge_index=[2, 968])\n"
     ]
    }
   ],
   "source": [
    "required_stations = airports_exists\n",
    "\n",
    "### first get the locations of stations\n",
    "# Filter the DataFrame for the required stations\n",
    "stations_df = latlongs[latlongs['stid'].isin(required_stations)]\n",
    "# Create a dictionary from the filtered DataFrame\n",
    "stations_latlong = stations_df.set_index('stid')[['lat', 'lon']].T.to_dict()\n",
    "\n",
    "print(stations_latlong)\n",
    "\n",
    "### now get station data itself\n",
    "processed_data_paths = {station:f'./csvs/{station}_processed.csv' for station in required_stations}\n",
    "print(processed_data_paths)\n",
    "\n",
    "station_features = []\n",
    "normalized_latlongs = []\n",
    "for stid in required_stations:\n",
    "   station_data = pd.read_csv(processed_data_paths[stid])\n",
    "   features = torch.tensor(station_data.drop(columns=['station']).values, dtype=torch.float)\n",
    "   mean_features = features.mean(dim=0)  # Mean of all the features to get \"average weather\"\n",
    "\n",
    "   # Append latitude and longitude to the feature vector\n",
    "   lat, long = stations_latlong[stid]['lat'], stations_latlong[stid]['lon']\n",
    "   nlat = (lat+90)/ (180)\n",
    "   nlong = (long+180)/ (360) \n",
    "   lat_long = torch.tensor([nlat,nlong], dtype=torch.float)\n",
    "   print(f\"latlong is {lat_long}\")\n",
    "   combined_features = torch.cat((mean_features, lat_long))  # Concatenate features with lat/lon\n",
    "\n",
    "   station_features.append(combined_features)\n",
    "   normalized_latlongs.append([nlat, nlong])\n",
    "\n",
    "print(f'n latlongs: {normalized_latlongs}')\n",
    "\n",
    "node_features = torch.stack(station_features)\n",
    "node_features += torch.randn_like(node_features) * 0.01  # noise\n",
    "print(node_features.shape)\n",
    "print('node features before is:')\n",
    "print(node_features)\n",
    "\n",
    "small_noise = (torch.randn_like(node_features) * 1e-4)\n",
    "node_features = torch.where(torch.isnan(node_features), small_noise, node_features)\n",
    "\n",
    "print(\"Node features after replacing NaNs with small random noise:\")\n",
    "print(node_features)\n",
    "\n",
    "print(torch.var(node_features, dim=0))\n",
    "\n",
    "def calculate_distances(latlongs):\n",
    "   num_stations = len(latlongs)\n",
    "   distances = np.zeros((num_stations, num_stations))\n",
    "   for i, coord1 in enumerate(latlongs):\n",
    "      for j, coord2 in enumerate(latlongs):\n",
    "         # Calculate Euclidean distance for normalized coordinates\n",
    "         distances[i, j] = np.linalg.norm(np.array(coord1) - np.array(coord2))\n",
    "   return distances\n",
    "\n",
    "distances = calculate_distances(normalized_latlongs)\n",
    "print(\"Distance Matrix:\")\n",
    "print(distances)\n",
    "\n",
    "distance_threshold = 0.009  # Adjust this threshold based on your scale and data\n",
    "edges = []\n",
    "\n",
    "for i in range(len(distances)):\n",
    "   for j in range(len(distances)):\n",
    "      if i != j and distances[i, j] <= distance_threshold:\n",
    "         edges.append((i, j))\n",
    "\n",
    "# Define edges \n",
    "edge_index = torch.tensor(edges, dtype=torch.long).T  # Transpose to match edge_index format\n",
    "print(\"Edge Index:\")\n",
    "print(edge_index)\n",
    "\n",
    "# Create the graph data\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNN(torch.nn.Module):\n",
    "   def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "      super(SimpleGNN, self).__init__()\n",
    "      self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "      self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "   def forward(self, data):\n",
    "      x, edge_index = data.x, data.edge_index\n",
    "      x = self.conv1(x, edge_index)\n",
    "      x = F.relu(x)\n",
    "      x = self.conv2(x, edge_index)\n",
    "      return x  # Embeddings for each node\n",
    "\n",
    "# Initialize the GNN\n",
    "input_dim = node_features.shape[1]  # Latitude and longitude plus features\n",
    "hidden_dim = 14\n",
    "output_dim = 12  # Embedding size\n",
    "gnn = SimpleGNN(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial embeddings for each station:\n",
      "tensor([[-0.0800, -0.1233, -0.0198, -0.1689,  0.0997,  0.0334, -0.0165,  0.2111,\n",
      "         -0.0281,  0.1307,  0.0946,  0.1317],\n",
      "        [-0.0634, -0.0972, -0.0175, -0.1337,  0.0786,  0.0257, -0.0146,  0.1677,\n",
      "         -0.0217,  0.1037,  0.0756,  0.1048],\n",
      "        [-0.0767, -0.1172, -0.0200, -0.1612,  0.0951,  0.0319, -0.0165,  0.2017,\n",
      "         -0.0266,  0.1251,  0.0909,  0.1260],\n",
      "        [-0.0769, -0.1182, -0.0203, -0.1624,  0.0955,  0.0314, -0.0167,  0.2030,\n",
      "         -0.0267,  0.1255,  0.0914,  0.1267],\n",
      "        [-0.0661, -0.1020, -0.0156, -0.1396,  0.0824,  0.0279, -0.0128,  0.1739,\n",
      "         -0.0235,  0.1076,  0.0779,  0.1083],\n",
      "        [-0.0591, -0.0915, -0.0135, -0.1250,  0.0738,  0.0251, -0.0111,  0.1555,\n",
      "         -0.0212,  0.0962,  0.0696,  0.0968],\n",
      "        [-0.0693, -0.1069, -0.0165, -0.1464,  0.0864,  0.0291, -0.0136,  0.1824,\n",
      "         -0.0246,  0.1129,  0.0818,  0.1137],\n",
      "        [-0.0772, -0.1187, -0.0196, -0.1629,  0.0959,  0.0319, -0.0161,  0.2032,\n",
      "         -0.0271,  0.1256,  0.0915,  0.1267],\n",
      "        [-0.0677, -0.1044, -0.0160, -0.1429,  0.0843,  0.0285, -0.0132,  0.1780,\n",
      "         -0.0241,  0.1102,  0.0798,  0.1109],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0820, -0.1260, -0.0208, -0.1729,  0.1020,  0.0341, -0.0172,  0.2162,\n",
      "         -0.0287,  0.1340,  0.0970,  0.1350],\n",
      "        [-0.0634, -0.0967, -0.0170, -0.1330,  0.0786,  0.0263, -0.0142,  0.1670,\n",
      "         -0.0217,  0.1037,  0.0753,  0.1043],\n",
      "        [-0.0779, -0.1192, -0.0203, -0.1638,  0.0967,  0.0324, -0.0168,  0.2051,\n",
      "         -0.0270,  0.1272,  0.0924,  0.1281],\n",
      "        [-0.0730, -0.1125, -0.0176, -0.1541,  0.0909,  0.0306, -0.0145,  0.1921,\n",
      "         -0.0259,  0.1189,  0.0862,  0.1197],\n",
      "        [-0.0665, -0.0992, -0.0231, -0.1385,  0.0807,  0.0255, -0.0184,  0.1742,\n",
      "         -0.0212,  0.1077,  0.0807,  0.1089],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0629, -0.0972, -0.0146, -0.1329,  0.0785,  0.0266, -0.0120,  0.1654,\n",
      "         -0.0225,  0.1024,  0.0741,  0.1030],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0829, -0.1275, -0.0212, -0.1750,  0.1030,  0.0343, -0.0175,  0.2185,\n",
      "         -0.0290,  0.1352,  0.0983,  0.1363],\n",
      "        [-0.0744, -0.1145, -0.0181, -0.1570,  0.0926,  0.0311, -0.0149,  0.1957,\n",
      "         -0.0263,  0.1212,  0.0878,  0.1221],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0591, -0.0915, -0.0135, -0.1250,  0.0738,  0.0251, -0.0111,  0.1555,\n",
      "         -0.0212,  0.0962,  0.0696,  0.0968],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0779, -0.1173, -0.0249, -0.1629,  0.0953,  0.0306, -0.0202,  0.2046,\n",
      "         -0.0255,  0.1266,  0.0938,  0.1280],\n",
      "        [-0.0499, -0.0749, -0.0144, -0.1038,  0.0611,  0.0207, -0.0114,  0.1296,\n",
      "         -0.0169,  0.0807,  0.0593,  0.0810],\n",
      "        [-0.0834, -0.1259, -0.0258, -0.1746,  0.1023,  0.0330, -0.0210,  0.2192,\n",
      "         -0.0276,  0.1357,  0.1002,  0.1370],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0844, -0.1299, -0.0216, -0.1782,  0.1049,  0.0349, -0.0178,  0.2226,\n",
      "         -0.0295,  0.1377,  0.1001,  0.1389],\n",
      "        [-0.0738, -0.1134, -0.0198, -0.1558,  0.0917,  0.0301, -0.0165,  0.1952,\n",
      "         -0.0254,  0.1207,  0.0879,  0.1219],\n",
      "        [-0.0650, -0.0968, -0.0228, -0.1353,  0.0788,  0.0249, -0.0181,  0.1701,\n",
      "         -0.0206,  0.1051,  0.0789,  0.1063],\n",
      "        [-0.0562, -0.0846, -0.0159, -0.1171,  0.0689,  0.0232, -0.0127,  0.1463,\n",
      "         -0.0192,  0.0910,  0.0667,  0.0915],\n",
      "        [-0.0788, -0.1212, -0.0206, -0.1664,  0.0979,  0.0323, -0.0171,  0.2081,\n",
      "         -0.0274,  0.1286,  0.0936,  0.1299],\n",
      "        [-0.0677, -0.1044, -0.0160, -0.1429,  0.0843,  0.0285, -0.0132,  0.1780,\n",
      "         -0.0241,  0.1102,  0.0798,  0.1109],\n",
      "        [-0.0523, -0.0787, -0.0149, -0.1089,  0.0641,  0.0217, -0.0119,  0.1362,\n",
      "         -0.0177,  0.0847,  0.0621,  0.0851],\n",
      "        [-0.0772, -0.1189, -0.0190, -0.1630,  0.0961,  0.0322, -0.0158,  0.2034,\n",
      "         -0.0272,  0.1260,  0.0913,  0.1269],\n",
      "        [-0.0779, -0.1173, -0.0249, -0.1629,  0.0953,  0.0306, -0.0202,  0.2046,\n",
      "         -0.0255,  0.1266,  0.0938,  0.1280],\n",
      "        [-0.0564, -0.0851, -0.0159, -0.1176,  0.0693,  0.0233, -0.0128,  0.1472,\n",
      "         -0.0192,  0.0915,  0.0670,  0.0920],\n",
      "        [-0.0779, -0.1197, -0.0202, -0.1643,  0.0969,  0.0322, -0.0168,  0.2058,\n",
      "         -0.0271,  0.1275,  0.0924,  0.1286],\n",
      "        [-0.0730, -0.1125, -0.0176, -0.1541,  0.0909,  0.0306, -0.0145,  0.1921,\n",
      "         -0.0259,  0.1189,  0.0862,  0.1197],\n",
      "        [-0.0693, -0.1064, -0.0190, -0.1463,  0.0861,  0.0282, -0.0158,  0.1835,\n",
      "         -0.0237,  0.1135,  0.0827,  0.1146],\n",
      "        [-0.0744, -0.1145, -0.0181, -0.1570,  0.0926,  0.0311, -0.0149,  0.1957,\n",
      "         -0.0263,  0.1212,  0.0878,  0.1221],\n",
      "        [-0.0615, -0.0932, -0.0172, -0.1286,  0.0758,  0.0255, -0.0140,  0.1611,\n",
      "         -0.0210,  0.1002,  0.0731,  0.1008],\n",
      "        [-0.0779, -0.1173, -0.0249, -0.1629,  0.0953,  0.0306, -0.0202,  0.2046,\n",
      "         -0.0255,  0.1266,  0.0938,  0.1280],\n",
      "        [-0.0812, -0.1249, -0.0207, -0.1713,  0.1010,  0.0337, -0.0171,  0.2143,\n",
      "         -0.0284,  0.1327,  0.0961,  0.1338],\n",
      "        [-0.0801, -0.1234, -0.0209, -0.1693,  0.0996,  0.0329, -0.0173,  0.2117,\n",
      "         -0.0279,  0.1309,  0.0952,  0.1321]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embeddings = gnn(data)\n",
    "\n",
    "# Print embeddings\n",
    "print(\"initial embeddings for each station:\")\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train the gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity matrix is tensor([[0.6374, 0.6370, 0.6275,  ..., 0.6312, 0.6136, 0.6397],\n",
      "        [0.6370, 0.6405, 0.6287,  ..., 0.6321, 0.6159, 0.6417],\n",
      "        [0.6275, 0.6287, 0.6198,  ..., 0.6222, 0.6045, 0.6314],\n",
      "        ...,\n",
      "        [0.6312, 0.6321, 0.6222,  ..., 0.6265, 0.6088, 0.6351],\n",
      "        [0.6136, 0.6159, 0.6045,  ..., 0.6088, 0.5939, 0.6167],\n",
      "        [0.6397, 0.6417, 0.6314,  ..., 0.6351, 0.6167, 0.6462]])\n",
      "Epoch 1, Loss: 0.2622\n",
      "Epoch 2, Loss: 0.2547\n",
      "Epoch 3, Loss: 0.2470\n",
      "Epoch 4, Loss: 0.2391\n",
      "Epoch 5, Loss: 0.2311\n",
      "Epoch 6, Loss: 0.2229\n",
      "Epoch 7, Loss: 0.2146\n",
      "Epoch 8, Loss: 0.2062\n",
      "Epoch 9, Loss: 0.1976\n",
      "Epoch 10, Loss: 0.1890\n",
      "Epoch 11, Loss: 0.1803\n",
      "Epoch 12, Loss: 0.1715\n",
      "Epoch 13, Loss: 0.1626\n",
      "Epoch 14, Loss: 0.1538\n",
      "Epoch 15, Loss: 0.1449\n",
      "Epoch 16, Loss: 0.1361\n",
      "Epoch 17, Loss: 0.1273\n",
      "Epoch 18, Loss: 0.1187\n",
      "Epoch 19, Loss: 0.1103\n",
      "Epoch 20, Loss: 0.1021\n",
      "Epoch 21, Loss: 0.0941\n",
      "Epoch 22, Loss: 0.0863\n",
      "Epoch 23, Loss: 0.0788\n",
      "Epoch 24, Loss: 0.0715\n",
      "Epoch 25, Loss: 0.0645\n",
      "Epoch 26, Loss: 0.0578\n",
      "Epoch 27, Loss: 0.0514\n",
      "Epoch 28, Loss: 0.0454\n",
      "Epoch 29, Loss: 0.0398\n",
      "Epoch 30, Loss: 0.0346\n",
      "Epoch 31, Loss: 0.0300\n",
      "Epoch 32, Loss: 0.0258\n",
      "Epoch 33, Loss: 0.0221\n",
      "Epoch 34, Loss: 0.0189\n",
      "Epoch 35, Loss: 0.0162\n",
      "Epoch 36, Loss: 0.0140\n",
      "Epoch 37, Loss: 0.0123\n",
      "Epoch 38, Loss: 0.0110\n",
      "Epoch 39, Loss: 0.0100\n",
      "Epoch 40, Loss: 0.0095\n",
      "Epoch 41, Loss: 0.0092\n",
      "Epoch 42, Loss: 0.0092\n",
      "Epoch 43, Loss: 0.0094\n",
      "Epoch 44, Loss: 0.0097\n",
      "Epoch 45, Loss: 0.0101\n",
      "Epoch 46, Loss: 0.0105\n",
      "Epoch 47, Loss: 0.0110\n",
      "Epoch 48, Loss: 0.0114\n",
      "Epoch 49, Loss: 0.0117\n",
      "Epoch 50, Loss: 0.0119\n",
      "Epoch 51, Loss: 0.0121\n",
      "Epoch 52, Loss: 0.0121\n",
      "Epoch 53, Loss: 0.0120\n",
      "Epoch 54, Loss: 0.0119\n",
      "Epoch 55, Loss: 0.0116\n",
      "Epoch 56, Loss: 0.0114\n",
      "Epoch 57, Loss: 0.0111\n",
      "Epoch 58, Loss: 0.0108\n",
      "Epoch 59, Loss: 0.0105\n",
      "Epoch 60, Loss: 0.0102\n",
      "Epoch 61, Loss: 0.0099\n",
      "Epoch 62, Loss: 0.0097\n",
      "Epoch 63, Loss: 0.0095\n",
      "Epoch 64, Loss: 0.0093\n",
      "Epoch 65, Loss: 0.0092\n",
      "Epoch 66, Loss: 0.0091\n",
      "Epoch 67, Loss: 0.0090\n",
      "Epoch 68, Loss: 0.0090\n",
      "Epoch 69, Loss: 0.0090\n",
      "Epoch 70, Loss: 0.0090\n",
      "Epoch 71, Loss: 0.0090\n",
      "Epoch 72, Loss: 0.0091\n",
      "Epoch 73, Loss: 0.0091\n",
      "Epoch 74, Loss: 0.0091\n",
      "Epoch 75, Loss: 0.0091\n",
      "Epoch 76, Loss: 0.0092\n",
      "Epoch 77, Loss: 0.0092\n",
      "Epoch 78, Loss: 0.0092\n",
      "Epoch 79, Loss: 0.0092\n",
      "Epoch 80, Loss: 0.0092\n",
      "Epoch 81, Loss: 0.0091\n",
      "Epoch 82, Loss: 0.0091\n",
      "Epoch 83, Loss: 0.0091\n",
      "Epoch 84, Loss: 0.0091\n",
      "Epoch 85, Loss: 0.0090\n",
      "Epoch 86, Loss: 0.0090\n",
      "Epoch 87, Loss: 0.0090\n",
      "Epoch 88, Loss: 0.0090\n",
      "Epoch 89, Loss: 0.0089\n",
      "Epoch 90, Loss: 0.0089\n",
      "Epoch 91, Loss: 0.0089\n",
      "Epoch 92, Loss: 0.0089\n",
      "Epoch 93, Loss: 0.0089\n",
      "Epoch 94, Loss: 0.0089\n",
      "Epoch 95, Loss: 0.0089\n",
      "Epoch 96, Loss: 0.0089\n",
      "Epoch 97, Loss: 0.0089\n",
      "Epoch 98, Loss: 0.0089\n",
      "Epoch 99, Loss: 0.0089\n",
      "Epoch 100, Loss: 0.0089\n",
      "Epoch 101, Loss: 0.0089\n",
      "Epoch 102, Loss: 0.0089\n",
      "Epoch 103, Loss: 0.0089\n",
      "Epoch 104, Loss: 0.0088\n",
      "Epoch 105, Loss: 0.0088\n",
      "Epoch 106, Loss: 0.0088\n",
      "Epoch 107, Loss: 0.0088\n",
      "Epoch 108, Loss: 0.0088\n",
      "Epoch 109, Loss: 0.0088\n",
      "Epoch 110, Loss: 0.0088\n",
      "Epoch 111, Loss: 0.0088\n",
      "Epoch 112, Loss: 0.0088\n",
      "Epoch 113, Loss: 0.0088\n",
      "Epoch 114, Loss: 0.0088\n",
      "Epoch 115, Loss: 0.0088\n",
      "Epoch 116, Loss: 0.0088\n",
      "Epoch 117, Loss: 0.0088\n",
      "Epoch 118, Loss: 0.0087\n",
      "Epoch 119, Loss: 0.0087\n",
      "Epoch 120, Loss: 0.0087\n",
      "Epoch 121, Loss: 0.0087\n",
      "Epoch 122, Loss: 0.0087\n",
      "Epoch 123, Loss: 0.0087\n",
      "Epoch 124, Loss: 0.0087\n",
      "Epoch 125, Loss: 0.0087\n",
      "Epoch 126, Loss: 0.0087\n",
      "Epoch 127, Loss: 0.0087\n",
      "Epoch 128, Loss: 0.0087\n",
      "Epoch 129, Loss: 0.0087\n",
      "Epoch 130, Loss: 0.0087\n",
      "Epoch 131, Loss: 0.0087\n",
      "Epoch 132, Loss: 0.0087\n",
      "Epoch 133, Loss: 0.0087\n",
      "Epoch 134, Loss: 0.0086\n",
      "Epoch 135, Loss: 0.0086\n",
      "Epoch 136, Loss: 0.0086\n",
      "Epoch 137, Loss: 0.0086\n",
      "Epoch 138, Loss: 0.0086\n",
      "Epoch 139, Loss: 0.0086\n",
      "Epoch 140, Loss: 0.0086\n",
      "Epoch 141, Loss: 0.0086\n",
      "Epoch 142, Loss: 0.0086\n",
      "Epoch 143, Loss: 0.0086\n",
      "Epoch 144, Loss: 0.0086\n",
      "Epoch 145, Loss: 0.0086\n",
      "Epoch 146, Loss: 0.0086\n",
      "Epoch 147, Loss: 0.0086\n",
      "Epoch 148, Loss: 0.0086\n",
      "Epoch 149, Loss: 0.0085\n",
      "Epoch 150, Loss: 0.0085\n",
      "Epoch 151, Loss: 0.0085\n",
      "Epoch 152, Loss: 0.0085\n",
      "Epoch 153, Loss: 0.0085\n",
      "Epoch 154, Loss: 0.0085\n",
      "Epoch 155, Loss: 0.0085\n",
      "Epoch 156, Loss: 0.0085\n",
      "Epoch 157, Loss: 0.0085\n",
      "Epoch 158, Loss: 0.0085\n",
      "Epoch 159, Loss: 0.0085\n",
      "Epoch 160, Loss: 0.0085\n",
      "Epoch 161, Loss: 0.0085\n",
      "Epoch 162, Loss: 0.0085\n",
      "Epoch 163, Loss: 0.0084\n",
      "Epoch 164, Loss: 0.0084\n",
      "Epoch 165, Loss: 0.0084\n",
      "Epoch 166, Loss: 0.0084\n",
      "Epoch 167, Loss: 0.0084\n",
      "Epoch 168, Loss: 0.0084\n",
      "Epoch 169, Loss: 0.0084\n",
      "Epoch 170, Loss: 0.0084\n",
      "Epoch 171, Loss: 0.0084\n",
      "Epoch 172, Loss: 0.0084\n",
      "Epoch 173, Loss: 0.0084\n",
      "Epoch 174, Loss: 0.0084\n",
      "Epoch 175, Loss: 0.0084\n",
      "Epoch 176, Loss: 0.0084\n",
      "Epoch 177, Loss: 0.0083\n",
      "Epoch 178, Loss: 0.0083\n",
      "Epoch 179, Loss: 0.0083\n",
      "Epoch 180, Loss: 0.0083\n",
      "Epoch 181, Loss: 0.0083\n",
      "Epoch 182, Loss: 0.0083\n",
      "Epoch 183, Loss: 0.0083\n",
      "Epoch 184, Loss: 0.0083\n",
      "Epoch 185, Loss: 0.0083\n",
      "Epoch 186, Loss: 0.0083\n",
      "Epoch 187, Loss: 0.0083\n",
      "Epoch 188, Loss: 0.0083\n",
      "Epoch 189, Loss: 0.0083\n",
      "Epoch 190, Loss: 0.0082\n",
      "Epoch 191, Loss: 0.0082\n",
      "Epoch 192, Loss: 0.0082\n",
      "Epoch 193, Loss: 0.0082\n",
      "Epoch 194, Loss: 0.0082\n",
      "Epoch 195, Loss: 0.0082\n",
      "Epoch 196, Loss: 0.0082\n",
      "Epoch 197, Loss: 0.0082\n",
      "Epoch 198, Loss: 0.0082\n",
      "Epoch 199, Loss: 0.0082\n",
      "Epoch 200, Loss: 0.0082\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import cosine_similarity\n",
    "\n",
    "# Compute similarity matrix from node features\n",
    "similarity_matrix = torch.mm(node_features, node_features.T)\n",
    "print(f'similarity matrix is {similarity_matrix}')\n",
    "\n",
    "# Define unsupervised loss function with regularization\n",
    "def contrastive_loss(embeddings, similarity_matrix, distance_matrix, lambda_diversity=0.1, lambda_distance=0.1):\n",
    "   pred_similarity = torch.mm(embeddings, embeddings.T)\n",
    "   mse_loss = torch.nn.functional.mse_loss(pred_similarity, similarity_matrix)\n",
    "\n",
    "   diversity_loss = -torch.var(embeddings, dim=0).mean()  # Penalize low variance\n",
    "\n",
    "   pred_distance_matrix = torch.cdist(embeddings, embeddings, p=2)\n",
    "   distance_loss = torch.nn.functional.mse_loss(pred_distance_matrix, distance_matrix)\n",
    "\n",
    "   total_loss = mse_loss + lambda_diversity * diversity_loss + lambda_distance * distance_loss\n",
    "   return total_loss\n",
    "\n",
    "# Training loop\n",
    "epochs = 200\n",
    "optimizer = torch.optim.Adam(gnn.parameters(), lr=0.001)\n",
    "\n",
    "gnn.train()\n",
    "for epoch in range(epochs):\n",
    "   optimizer.zero_grad()  # Reset gradients\n",
    "   embeddings = gnn(data)  # Forward pass\n",
    "\n",
    "   # Compute contrastive loss\n",
    "   loss = contrastive_loss(embeddings, similarity_matrix, torch.Tensor(distances))\n",
    "   \n",
    "   # Backward pass and optimization\n",
    "   loss.backward()\n",
    "   optimizer.step()\n",
    "\n",
    "   # Print loss and gradient information\n",
    "   print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "   # for name, param in gnn.named_parameters():\n",
    "   #    if param.grad is not None:\n",
    "   #       print(f\"Gradient for {name}: {param.grad.abs().mean().item():.6f}\")\n",
    "   #    else:\n",
    "   #       print(f\"No gradient for {name}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned embeddings:\n",
      "tensor([[-0.2138, -0.3179, -0.0547, -0.3643,  0.2609,  0.1814, -0.0781,  0.3894,\n",
      "         -0.1806,  0.2691,  0.2090,  0.2664],\n",
      "        [-0.1787, -0.2615, -0.0545, -0.2978,  0.2158,  0.1539, -0.0754,  0.3177,\n",
      "         -0.1546,  0.2228,  0.1742,  0.2216],\n",
      "        [-0.2075, -0.3072, -0.0546, -0.3518,  0.2526,  0.1766, -0.0773,  0.3758,\n",
      "         -0.1757,  0.2604,  0.2027,  0.2577],\n",
      "        [-0.2069, -0.3074, -0.0549, -0.3520,  0.2521,  0.1756, -0.0778,  0.3759,\n",
      "         -0.1759,  0.2603,  0.2020,  0.2584],\n",
      "        [-0.1848, -0.2701, -0.0540, -0.3081,  0.2233,  0.1592, -0.0748,  0.3283,\n",
      "         -0.1584,  0.2295,  0.1806,  0.2269],\n",
      "        [-0.1708, -0.2470, -0.0534, -0.2809,  0.2053,  0.1484, -0.0731,  0.2988,\n",
      "         -0.1475,  0.2102,  0.1670,  0.2077],\n",
      "        [-0.1913, -0.2808, -0.0542, -0.3208,  0.2317,  0.1641, -0.0755,  0.3420,\n",
      "         -0.1634,  0.2384,  0.1869,  0.2358],\n",
      "        [-0.2074, -0.3077, -0.0548, -0.3524,  0.2525,  0.1762, -0.0775,  0.3762,\n",
      "         -0.1761,  0.2605,  0.2026,  0.2582],\n",
      "        [-0.1880, -0.2752, -0.0541, -0.3142,  0.2274,  0.1616, -0.0751,  0.3349,\n",
      "         -0.1608,  0.2338,  0.1837,  0.2312],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.2183, -0.3252, -0.0549, -0.3729,  0.2666,  0.1848, -0.0785,  0.3987,\n",
      "         -0.1840,  0.2752,  0.2134,  0.2724],\n",
      "        [-0.1798, -0.2622, -0.0541, -0.2987,  0.2171,  0.1554, -0.0749,  0.3186,\n",
      "         -0.1547,  0.2235,  0.1756,  0.2213],\n",
      "        [-0.2103, -0.3118, -0.0546, -0.3572,  0.2562,  0.1788, -0.0776,  0.3817,\n",
      "         -0.1778,  0.2642,  0.2055,  0.2613],\n",
      "        [-0.1988, -0.2930, -0.0544, -0.3352,  0.2413,  0.1698, -0.0764,  0.3576,\n",
      "         -0.1692,  0.2486,  0.1942,  0.2460],\n",
      "        [-0.1869, -0.2754, -0.0548, -0.3144,  0.2262,  0.1598, -0.0758,  0.3345,\n",
      "         -0.1613,  0.2334,  0.1822,  0.2325],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.1783, -0.2594, -0.0537, -0.2955,  0.2150,  0.1542, -0.0740,  0.3146,\n",
      "         -0.1533,  0.2206,  0.1743,  0.2180],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.2195, -0.3276, -0.0550, -0.3757,  0.2682,  0.1855, -0.0788,  0.4016,\n",
      "         -0.1852,  0.2769,  0.2145,  0.2745],\n",
      "        [-0.2017, -0.2978, -0.0545, -0.3408,  0.2450,  0.1720, -0.0768,  0.3637,\n",
      "         -0.1714,  0.2526,  0.1970,  0.2500],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.1708, -0.2470, -0.0534, -0.2809,  0.2053,  0.1484, -0.0731,  0.2988,\n",
      "         -0.1475,  0.2102,  0.1670,  0.2077],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.2102, -0.3134, -0.0553, -0.3590,  0.2563,  0.1779, -0.0783,  0.3832,\n",
      "         -0.1789,  0.2651,  0.2051,  0.2637],\n",
      "        [-0.1534, -0.2181, -0.0531, -0.2471,  0.1826,  0.1352, -0.0711,  0.2617,\n",
      "         -0.1342,  0.1863,  0.1498,  0.1839],\n",
      "        [-0.2212, -0.3313, -0.0556, -0.3801,  0.2705,  0.1864, -0.0795,  0.4062,\n",
      "         -0.1873,  0.2800,  0.2158,  0.2784],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.2227, -0.3329, -0.0551, -0.3819,  0.2724,  0.1880, -0.0791,  0.4084,\n",
      "         -0.1876,  0.2813,  0.2177,  0.2788],\n",
      "        [-0.2003, -0.2968, -0.0549, -0.3393,  0.2437,  0.1706, -0.0775,  0.3626,\n",
      "         -0.1709,  0.2519,  0.1955,  0.2502],\n",
      "        [-0.1838, -0.2704, -0.0548, -0.3084,  0.2222,  0.1575, -0.0755,  0.3280,\n",
      "         -0.1590,  0.2292,  0.1791,  0.2283],\n",
      "        [-0.1655, -0.2382, -0.0536, -0.2708,  0.1982,  0.1444, -0.0727,  0.2874,\n",
      "         -0.1437,  0.2032,  0.1615,  0.2009],\n",
      "        [-0.2106, -0.3135, -0.0550, -0.3591,  0.2569,  0.1785, -0.0783,  0.3838,\n",
      "         -0.1787,  0.2655,  0.2057,  0.2636],\n",
      "        [-0.1880, -0.2752, -0.0541, -0.3142,  0.2274,  0.1616, -0.0751,  0.3349,\n",
      "         -0.1608,  0.2338,  0.1837,  0.2312],\n",
      "        [-0.1584, -0.2266, -0.0532, -0.2569,  0.1892,  0.1391, -0.0716,  0.2725,\n",
      "         -0.1380,  0.1932,  0.1548,  0.1908],\n",
      "        [-0.2076, -0.3076, -0.0547, -0.3524,  0.2528,  0.1766, -0.0775,  0.3763,\n",
      "         -0.1760,  0.2607,  0.2028,  0.2582],\n",
      "        [-0.2102, -0.3134, -0.0553, -0.3590,  0.2563,  0.1779, -0.0783,  0.3832,\n",
      "         -0.1789,  0.2651,  0.2051,  0.2637],\n",
      "        [-0.1664, -0.2398, -0.0535, -0.2725,  0.1995,  0.1452, -0.0727,  0.2895,\n",
      "         -0.1443,  0.2043,  0.1625,  0.2020],\n",
      "        [-0.2096, -0.3112, -0.0549, -0.3564,  0.2554,  0.1780, -0.0780,  0.3810,\n",
      "         -0.1776,  0.2638,  0.2047,  0.2614],\n",
      "        [-0.1988, -0.2930, -0.0544, -0.3352,  0.2413,  0.1698, -0.0764,  0.3576,\n",
      "         -0.1692,  0.2486,  0.1942,  0.2460],\n",
      "        [-0.1911, -0.2819, -0.0548, -0.3217,  0.2319,  0.1636, -0.0766,  0.3436,\n",
      "         -0.1640,  0.2396,  0.1865,  0.2381],\n",
      "        [-0.2017, -0.2978, -0.0545, -0.3408,  0.2450,  0.1720, -0.0768,  0.3637,\n",
      "         -0.1714,  0.2526,  0.1970,  0.2500],\n",
      "        [-0.1770, -0.2571, -0.0538, -0.2929,  0.2132,  0.1533, -0.0740,  0.3118,\n",
      "         -0.1524,  0.2189,  0.1729,  0.2165],\n",
      "        [-0.2102, -0.3134, -0.0553, -0.3590,  0.2563,  0.1779, -0.0783,  0.3832,\n",
      "         -0.1789,  0.2651,  0.2051,  0.2637],\n",
      "        [-0.2164, -0.3222, -0.0549, -0.3694,  0.2641,  0.1832, -0.0785,  0.3949,\n",
      "         -0.1827,  0.2727,  0.2114,  0.2702],\n",
      "        [-0.2136, -0.3183, -0.0551, -0.3647,  0.2606,  0.1808, -0.0785,  0.3898,\n",
      "         -0.1809,  0.2694,  0.2086,  0.2673]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "learned_embeddings = gnn(data)  # Get final embeddings\n",
    "print(\"Learned embeddings:\")\n",
    "print(learned_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6B9\n",
      "(126039, 11)\n",
      "ALB\n",
      "(53649, 11)\n",
      "ART\n",
      "(59240, 11)\n",
      "BGM\n",
      "(64987, 11)\n",
      "BUF\n",
      "(56629, 11)\n",
      "DKK\n",
      "(57779, 11)\n",
      "DSV\n",
      "(55154, 11)\n",
      "ELM\n",
      "(61800, 11)\n",
      "ELZ\n",
      "(71175, 11)\n",
      "FOK\n",
      "(59241, 11)\n",
      "FRG\n",
      "(54766, 11)\n",
      "FZY\n",
      "(61412, 11)\n",
      "GFL\n",
      "(60691, 11)\n",
      "GTB\n",
      "(81886, 11)\n",
      "GVQ\n",
      "(58242, 11)\n",
      "HPN\n",
      "(47561, 11)\n",
      "HTO\n",
      "(110, 11)\n",
      "HWV\n",
      "(57076, 11)\n",
      "IAG\n",
      "(58294, 11)\n",
      "ISP\n",
      "(50376, 11)\n",
      "ITH\n",
      "(53994, 11)\n",
      "IUA\n",
      "(81772, 11)\n",
      "JFK\n",
      "(48688, 11)\n",
      "JHW\n",
      "(70760, 11)\n",
      "JPX\n",
      "(127665, 11)\n",
      "JRB\n",
      "(48555, 11)\n",
      "LGA\n",
      "(50944, 11)\n",
      "MGJ\n",
      "(56171, 11)\n",
      "MSS\n",
      "(59579, 11)\n",
      "MSV\n",
      "(44144, 11)\n",
      "MTP\n",
      "(43019, 11)\n",
      "N03\n",
      "(129134, 11)\n",
      "NY0\n",
      "(93295, 11)\n",
      "NYC\n",
      "(54528, 11)\n",
      "OGS\n",
      "(130731, 11)\n",
      "OIC\n",
      "(77938, 11)\n",
      "OLE\n",
      "(119266, 11)\n",
      "PBG\n",
      "(52468, 11)\n",
      "PEO\n",
      "(60406, 11)\n",
      "POU\n",
      "(54716, 11)\n",
      "PTD\n",
      "(127185, 11)\n",
      "RME\n",
      "(60375, 11)\n",
      "ROC\n",
      "(54156, 11)\n",
      "SCH\n",
      "(20784, 11)\n",
      "SDC\n",
      "(122672, 11)\n",
      "SLK\n",
      "(72752, 11)\n",
      "SWF\n",
      "(43884, 11)\n",
      "SYR\n",
      "(54963, 11)\n",
      "VGC\n",
      "(112884, 11)\n"
     ]
    }
   ],
   "source": [
    "for r in required_stations:\n",
    "   df = pd.read_csv(f'./csvs/{r}_processed.csv')\n",
    "   print(r)\n",
    "   print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each station, add on the static embedding that we just learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126039, 11)\n",
      "(126039, 23)\n",
      "(53649, 11)\n",
      "(53649, 23)\n",
      "(59240, 11)\n",
      "(59240, 23)\n",
      "(64987, 11)\n",
      "(64987, 23)\n",
      "(56629, 11)\n",
      "(56629, 23)\n",
      "(57779, 11)\n",
      "(57779, 23)\n",
      "(55154, 11)\n",
      "(55154, 23)\n",
      "(61800, 11)\n",
      "(61800, 23)\n",
      "(71175, 11)\n",
      "(71175, 23)\n",
      "(59241, 11)\n",
      "(59241, 23)\n",
      "(54766, 11)\n",
      "(54766, 23)\n",
      "(61412, 11)\n",
      "(61412, 23)\n",
      "(60691, 11)\n",
      "(60691, 23)\n",
      "(81886, 11)\n",
      "(81886, 23)\n",
      "(58242, 11)\n",
      "(58242, 23)\n",
      "(47561, 11)\n",
      "(47561, 23)\n",
      "(110, 11)\n",
      "(110, 23)\n",
      "(57076, 11)\n",
      "(57076, 23)\n",
      "(58294, 11)\n",
      "(58294, 23)\n",
      "(50376, 11)\n",
      "(50376, 23)\n",
      "(53994, 11)\n",
      "(53994, 23)\n",
      "(81772, 11)\n",
      "(81772, 23)\n",
      "(48688, 11)\n",
      "(48688, 23)\n",
      "(70760, 11)\n",
      "(70760, 23)\n",
      "(127665, 11)\n",
      "(127665, 23)\n",
      "(48555, 11)\n",
      "(48555, 23)\n",
      "(50944, 11)\n",
      "(50944, 23)\n",
      "(56171, 11)\n",
      "(56171, 23)\n",
      "(59579, 11)\n",
      "(59579, 23)\n",
      "(44144, 11)\n",
      "(44144, 23)\n",
      "(43019, 11)\n",
      "(43019, 23)\n",
      "(129134, 11)\n",
      "(129134, 23)\n",
      "(93295, 11)\n",
      "(93295, 23)\n",
      "(54528, 11)\n",
      "(54528, 23)\n",
      "(130731, 11)\n",
      "(130731, 23)\n",
      "(77938, 11)\n",
      "(77938, 23)\n",
      "(119266, 11)\n",
      "(119266, 23)\n",
      "(52468, 11)\n",
      "(52468, 23)\n",
      "(60406, 11)\n",
      "(60406, 23)\n",
      "(54716, 11)\n",
      "(54716, 23)\n",
      "(127185, 11)\n",
      "(127185, 23)\n",
      "(60375, 11)\n",
      "(60375, 23)\n",
      "(54156, 11)\n",
      "(54156, 23)\n",
      "(20784, 11)\n",
      "(20784, 23)\n",
      "(122672, 11)\n",
      "(122672, 23)\n",
      "(72752, 11)\n",
      "(72752, 23)\n",
      "(43884, 11)\n",
      "(43884, 23)\n",
      "(54963, 11)\n",
      "(54963, 23)\n",
      "(112884, 11)\n",
      "(112884, 23)\n",
      "(3323535, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feel</th>\n",
       "      <th>relh</th>\n",
       "      <th>tmpf</th>\n",
       "      <th>vsby</th>\n",
       "      <th>sknt</th>\n",
       "      <th>mslp</th>\n",
       "      <th>p01i</th>\n",
       "      <th>alti</th>\n",
       "      <th>dwpf</th>\n",
       "      <th>drct</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>embedding_4</th>\n",
       "      <th>embedding_5</th>\n",
       "      <th>embedding_6</th>\n",
       "      <th>embedding_7</th>\n",
       "      <th>embedding_8</th>\n",
       "      <th>embedding_9</th>\n",
       "      <th>embedding_10</th>\n",
       "      <th>embedding_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.130598</td>\n",
       "      <td>0.718336</td>\n",
       "      <td>-1.089139</td>\n",
       "      <td>0.409480</td>\n",
       "      <td>0.132476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.084206</td>\n",
       "      <td>0.162251</td>\n",
       "      <td>-0.801488</td>\n",
       "      <td>1.256682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054736</td>\n",
       "      <td>-0.364275</td>\n",
       "      <td>0.260879</td>\n",
       "      <td>0.181377</td>\n",
       "      <td>-0.078069</td>\n",
       "      <td>0.389423</td>\n",
       "      <td>-0.180591</td>\n",
       "      <td>0.269141</td>\n",
       "      <td>0.209007</td>\n",
       "      <td>0.266407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.244045</td>\n",
       "      <td>0.383944</td>\n",
       "      <td>-1.089139</td>\n",
       "      <td>0.409480</td>\n",
       "      <td>0.915473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.084206</td>\n",
       "      <td>0.207533</td>\n",
       "      <td>-0.903217</td>\n",
       "      <td>1.256682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054736</td>\n",
       "      <td>-0.364275</td>\n",
       "      <td>0.260879</td>\n",
       "      <td>0.181377</td>\n",
       "      <td>-0.078069</td>\n",
       "      <td>0.389423</td>\n",
       "      <td>-0.180591</td>\n",
       "      <td>0.269141</td>\n",
       "      <td>0.209007</td>\n",
       "      <td>0.266407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.273849</td>\n",
       "      <td>0.383944</td>\n",
       "      <td>-1.089139</td>\n",
       "      <td>-0.006972</td>\n",
       "      <td>1.176472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.084206</td>\n",
       "      <td>0.207533</td>\n",
       "      <td>-0.903217</td>\n",
       "      <td>1.340816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054736</td>\n",
       "      <td>-0.364275</td>\n",
       "      <td>0.260879</td>\n",
       "      <td>0.181377</td>\n",
       "      <td>-0.078069</td>\n",
       "      <td>0.389423</td>\n",
       "      <td>-0.180591</td>\n",
       "      <td>0.269141</td>\n",
       "      <td>0.209007</td>\n",
       "      <td>0.266407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.079643</td>\n",
       "      <td>0.718336</td>\n",
       "      <td>-1.089139</td>\n",
       "      <td>-2.922136</td>\n",
       "      <td>-0.128523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.084206</td>\n",
       "      <td>0.298097</td>\n",
       "      <td>-0.801488</td>\n",
       "      <td>1.424950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054736</td>\n",
       "      <td>-0.364275</td>\n",
       "      <td>0.260879</td>\n",
       "      <td>0.181377</td>\n",
       "      <td>-0.078069</td>\n",
       "      <td>0.389423</td>\n",
       "      <td>-0.180591</td>\n",
       "      <td>0.269141</td>\n",
       "      <td>0.209007</td>\n",
       "      <td>0.266407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.316632</td>\n",
       "      <td>0.715314</td>\n",
       "      <td>-1.188289</td>\n",
       "      <td>-2.922136</td>\n",
       "      <td>0.654474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.084206</td>\n",
       "      <td>0.388661</td>\n",
       "      <td>-0.903217</td>\n",
       "      <td>1.509085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054736</td>\n",
       "      <td>-0.364275</td>\n",
       "      <td>0.260879</td>\n",
       "      <td>0.181377</td>\n",
       "      <td>-0.078069</td>\n",
       "      <td>0.389423</td>\n",
       "      <td>-0.180591</td>\n",
       "      <td>0.269141</td>\n",
       "      <td>0.209007</td>\n",
       "      <td>0.266407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feel      relh      tmpf      vsby      sknt  mslp      p01i      alti  \\\n",
       "0 -1.130598  0.718336 -1.089139  0.409480  0.132476   NaN -0.084206  0.162251   \n",
       "1 -1.244045  0.383944 -1.089139  0.409480  0.915473   NaN -0.084206  0.207533   \n",
       "2 -1.273849  0.383944 -1.089139 -0.006972  1.176472   NaN -0.084206  0.207533   \n",
       "3 -1.079643  0.718336 -1.089139 -2.922136 -0.128523   NaN -0.084206  0.298097   \n",
       "4 -1.316632  0.715314 -1.188289 -2.922136  0.654474   NaN -0.084206  0.388661   \n",
       "\n",
       "       dwpf      drct  ... embedding_2  embedding_3  embedding_4  embedding_5  \\\n",
       "0 -0.801488  1.256682  ...   -0.054736    -0.364275     0.260879     0.181377   \n",
       "1 -0.903217  1.256682  ...   -0.054736    -0.364275     0.260879     0.181377   \n",
       "2 -0.903217  1.340816  ...   -0.054736    -0.364275     0.260879     0.181377   \n",
       "3 -0.801488  1.424950  ...   -0.054736    -0.364275     0.260879     0.181377   \n",
       "4 -0.903217  1.509085  ...   -0.054736    -0.364275     0.260879     0.181377   \n",
       "\n",
       "   embedding_6  embedding_7  embedding_8  embedding_9  embedding_10  \\\n",
       "0    -0.078069     0.389423    -0.180591     0.269141      0.209007   \n",
       "1    -0.078069     0.389423    -0.180591     0.269141      0.209007   \n",
       "2    -0.078069     0.389423    -0.180591     0.269141      0.209007   \n",
       "3    -0.078069     0.389423    -0.180591     0.269141      0.209007   \n",
       "4    -0.078069     0.389423    -0.180591     0.269141      0.209007   \n",
       "\n",
       "   embedding_11  \n",
       "0      0.266407  \n",
       "1      0.266407  \n",
       "2      0.266407  \n",
       "3      0.266407  \n",
       "4      0.266407  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = []\n",
    "\n",
    "for idx, (station, path) in enumerate(processed_data_paths.items()):\n",
    "   # Load the CSV into a DataFrame\n",
    "   df = pd.read_csv(path)\n",
    "   print(df.shape)\n",
    "   \n",
    "   # Get the corresponding embedding for this station\n",
    "   embedding = learned_embeddings[idx].detach().numpy()\n",
    "   \n",
    "   # Add the embedding as new columns to the DataFrame\n",
    "   for i, value in enumerate(embedding):\n",
    "      df[f'embedding_{i}'] = value\n",
    "\n",
    "   print(df.shape)\n",
    "   \n",
    "   # Append to the list of all data\n",
    "   all_data.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Display the result\n",
    "print(combined_df.shape)\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3322359, 24, 22)\n",
      "(3322359, 22)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Prepare sequences for LSTM input\n",
    "# Assuming we are predicting 'tmpf' (temperature) as the target variable\n",
    "# and using previous 24 time steps/8 hours (n_steps_in) to predict the next time step/20 minutes from now (n_steps_out)\n",
    "# create sliding window sequences X: (114640, 24, 10), y: (114640, 10)\n",
    "feature_cols = list(set(combined_df.columns) - set(['station']))\n",
    "\n",
    "n_steps_in = 24  # Number of past time steps\n",
    "n_steps_out = 1  # Number of future time steps to predict\n",
    "\n",
    "# We'll create sequences for each station separately\n",
    "def create_sequences(data, n_steps_in, n_steps_out):\n",
    "   X, y = [], []\n",
    "   for i in range(len(data) - n_steps_in - n_steps_out + 1):\n",
    "      X.append(data[i:(i + n_steps_in), :])\n",
    "      y.append(data[(i + n_steps_in):(i + n_steps_in + n_steps_out), :])\n",
    "   return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare data for each station\n",
    "X_list = []\n",
    "y_list = []\n",
    "stations = combined_df['station'].unique()\n",
    "\n",
    "for station in stations:\n",
    "   station_data = combined_df[combined_df['station'] == station]\n",
    "   station_data = station_data.reset_index(drop=True)\n",
    "   data_values = station_data[feature_cols].values\n",
    "   # target_col_index = feature_cols.index('tmpf')  # Index of target variable in features\n",
    "\n",
    "   X_station, y_station = create_sequences(data_values, n_steps_in, n_steps_out)\n",
    "   X_list.append(X_station)\n",
    "   y_list.append(y_station)\n",
    "\n",
    "\n",
    "# Concatenate data from all stations\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "\n",
    "\n",
    "if n_steps_out == 1:\n",
    "   y = y.squeeze(1)  # Shape becomes (num_samples, num_features) = (114640, 10) for JRB\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2325651, Validation size: 332235, Test size: 664473\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Split the data into training, validation, and testing sets\n",
    "# Since it's time-series data, we'll use the first 70% for training, next 10% for validation, and the rest for testing\n",
    "train_size = int(len(X) * 0.7)\n",
    "val_size = int(len(X) * 0.1)\n",
    "test_size = len(X) - train_size - val_size\n",
    "\n",
    "X_train, X_val, X_test = X[:train_size], X[train_size:train_size + val_size], X[train_size + val_size:]\n",
    "y_train, y_val, y_test = y[:train_size], y[train_size:train_size + val_size], y[train_size + val_size:]\n",
    "\n",
    "# Now the data is ready for training the LSTM model\n",
    "\n",
    "# Define a PyTorch Dataset\n",
    "class WeatherDataset(Dataset):\n",
    "   def __init__(self, X, y):\n",
    "      self.X = X\n",
    "      self.y = y\n",
    "   def __len__(self):\n",
    "      return len(self.X)\n",
    "   def __getitem__(self, idx):\n",
    "      return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create Dataset objects for training, validation, and testing\n",
    "train_dataset = WeatherDataset(X_train, y_train)\n",
    "val_dataset = WeatherDataset(X_val, y_val)\n",
    "test_dataset = WeatherDataset(X_test, y_test)\n",
    "\n",
    "# Example to check shapes\n",
    "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\neela\\anaconda3\\envs\\torch_projects\\lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:654: Checkpoint directory C:\\GitHub\\segRNN\\checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | model     | SegRNN  | 2.4 M  | train\n",
      "1 | criterion | MSELoss | 0      | train\n",
      "----------------------------------------------\n",
      "2.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 M     Total params\n",
      "9.642     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a131a270a964639b31d5631599cc6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3708728551864624\n",
      "Validation Loss: 0.39429929852485657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8848ddcf334a9b990704a902ed59d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5174390077590942\n",
      "Train Loss: 0.49530550837516785\n",
      "Train Loss: 0.35015568137168884\n",
      "Train Loss: 0.2769709527492523\n",
      "Train Loss: 0.6333376169204712\n",
      "Train Loss: 0.3887970745563507\n",
      "Train Loss: 0.5709745287895203\n",
      "Train Loss: 0.19832004606723785\n",
      "Train Loss: 0.35511112213134766\n",
      "Train Loss: 0.195025235414505\n",
      "Train Loss: 0.2082718163728714\n",
      "Train Loss: 0.14314603805541992\n",
      "Train Loss: 0.187015101313591\n",
      "Train Loss: 0.17265017330646515\n",
      "Train Loss: 0.15465059876441956\n",
      "Train Loss: 0.15799519419670105\n",
      "Train Loss: 0.14487352967262268\n",
      "Train Loss: 0.12841752171516418\n",
      "Train Loss: 0.12539099156856537\n",
      "Train Loss: 0.26416727900505066\n",
      "Train Loss: 0.13023927807807922\n",
      "Train Loss: 0.1563475877046585\n",
      "Train Loss: 0.10822641104459763\n",
      "Train Loss: 0.2430567443370819\n",
      "Train Loss: 0.0696759968996048\n",
      "Train Loss: 0.09517743438482285\n",
      "Train Loss: 0.14653626084327698\n",
      "Train Loss: 0.09842877089977264\n",
      "Train Loss: 0.17933933436870575\n",
      "Train Loss: 0.0893821120262146\n",
      "Train Loss: 0.08303742110729218\n",
      "Train Loss: 0.10038560628890991\n",
      "Train Loss: 0.07938200235366821\n",
      "Train Loss: 0.09167017042636871\n",
      "Train Loss: 0.10136649757623672\n",
      "Train Loss: 0.1776241809129715\n",
      "Train Loss: 0.08856693655252457\n",
      "Train Loss: 0.1367778778076172\n",
      "Train Loss: 0.10878539085388184\n",
      "Train Loss: 0.08502060174942017\n",
      "Train Loss: 0.11967913061380386\n",
      "Train Loss: 0.07913204282522202\n",
      "Train Loss: 0.10586964339017868\n",
      "Train Loss: 0.08220964670181274\n",
      "Train Loss: 0.08394729346036911\n",
      "Train Loss: 0.07921377569437027\n",
      "Train Loss: 0.06792265921831131\n",
      "Train Loss: 0.23015788197517395\n",
      "Train Loss: 0.10310029983520508\n",
      "Train Loss: 0.07860559225082397\n",
      "Train Loss: 0.06934419274330139\n",
      "Train Loss: 0.07630523294210434\n",
      "Train Loss: 0.08184678852558136\n",
      "Train Loss: 0.06600452959537506\n",
      "Train Loss: 0.08140241354703903\n",
      "Train Loss: 0.06904345005750656\n",
      "Train Loss: 0.06047537922859192\n",
      "Train Loss: 0.07579278200864792\n",
      "Train Loss: 0.0742458701133728\n",
      "Train Loss: 0.07305321842432022\n",
      "Train Loss: 0.06267006695270538\n",
      "Train Loss: 0.06725546717643738\n",
      "Train Loss: 0.07842347025871277\n",
      "Train Loss: 0.08178979903459549\n",
      "Train Loss: 0.04054497182369232\n",
      "Train Loss: 0.057899508625268936\n",
      "Train Loss: 0.0717553049325943\n",
      "Train Loss: 0.10917529463768005\n",
      "Train Loss: 0.05353027209639549\n",
      "Train Loss: 0.037167783826589584\n",
      "Train Loss: 0.07731008529663086\n",
      "Train Loss: 0.06674998998641968\n",
      "Train Loss: 0.05604329705238342\n",
      "Train Loss: 0.0955149307847023\n",
      "Train Loss: 0.06337541341781616\n",
      "Train Loss: 0.11617168039083481\n",
      "Train Loss: 0.10764221101999283\n",
      "Train Loss: 0.09651064872741699\n",
      "Train Loss: 0.05448523536324501\n",
      "Train Loss: 0.06633490324020386\n",
      "Train Loss: 0.05885585397481918\n",
      "Train Loss: 0.053503744304180145\n",
      "Train Loss: 0.06326432526111603\n",
      "Train Loss: 0.03595690801739693\n",
      "Train Loss: 0.07755770534276962\n",
      "Train Loss: 0.08276979625225067\n",
      "Train Loss: 0.08200716972351074\n",
      "Train Loss: 0.0787060409784317\n",
      "Train Loss: 0.08875899016857147\n",
      "Train Loss: 0.05546535924077034\n",
      "Train Loss: 0.04056761786341667\n",
      "Train Loss: 0.13724318146705627\n",
      "Train Loss: 0.06097910925745964\n",
      "Train Loss: 0.06587271392345428\n",
      "Train Loss: 0.07995166629552841\n",
      "Train Loss: 0.05227553844451904\n",
      "Train Loss: 0.06575703620910645\n",
      "Train Loss: 0.06968747824430466\n",
      "Train Loss: 0.05144191533327103\n",
      "Train Loss: 0.05038435384631157\n",
      "Train Loss: 0.16179049015045166\n",
      "Train Loss: 0.04990224540233612\n",
      "Train Loss: 0.029799457639455795\n",
      "Train Loss: 0.06984522938728333\n",
      "Train Loss: 0.07801157236099243\n",
      "Train Loss: 0.07555204629898071\n",
      "Train Loss: 0.044016044586896896\n",
      "Train Loss: 0.04913949966430664\n",
      "Train Loss: 0.058765433728694916\n",
      "Train Loss: 0.0556686595082283\n",
      "Train Loss: 0.06833021342754364\n",
      "Train Loss: 0.06349770724773407\n",
      "Train Loss: 0.045305777341127396\n",
      "Train Loss: 0.05910450965166092\n",
      "Train Loss: 0.7841238975524902\n",
      "Train Loss: 0.05768448859453201\n",
      "Train Loss: 0.05720227584242821\n",
      "Train Loss: 0.08931256085634232\n",
      "Train Loss: 0.049407798796892166\n",
      "Train Loss: 0.05023558810353279\n",
      "Train Loss: 0.04979269206523895\n",
      "Train Loss: 2.3313379287719727\n",
      "Train Loss: 0.07537689059972763\n",
      "Train Loss: 0.06145147979259491\n",
      "Train Loss: 0.07193727046251297\n",
      "Train Loss: 0.064217209815979\n",
      "Train Loss: 0.19556593894958496\n",
      "Train Loss: 0.05912712588906288\n",
      "Train Loss: 0.10865101218223572\n",
      "Train Loss: 0.0872122272849083\n",
      "Train Loss: 0.12478958815336227\n",
      "Train Loss: 0.07661984115839005\n",
      "Train Loss: 0.06771460920572281\n",
      "Train Loss: 0.05603734031319618\n",
      "Train Loss: 0.11855243891477585\n",
      "Train Loss: 0.08238514512777328\n",
      "Train Loss: 0.14072518050670624\n",
      "Train Loss: 0.044610727578401566\n",
      "Train Loss: 0.07146232575178146\n",
      "Train Loss: 0.06422697007656097\n",
      "Train Loss: 0.04903549700975418\n",
      "Train Loss: 0.1555001139640808\n",
      "Train Loss: 0.0502418614923954\n",
      "Train Loss: 0.04131022468209267\n",
      "Train Loss: 0.05218051001429558\n",
      "Train Loss: 0.07469264417886734\n",
      "Train Loss: 0.07103697955608368\n",
      "Train Loss: 0.043840475380420685\n",
      "Train Loss: 0.13270480930805206\n",
      "Train Loss: 0.12525787949562073\n",
      "Train Loss: 0.07108091562986374\n",
      "Train Loss: 0.06359585374593735\n",
      "Train Loss: 0.07929517328739166\n",
      "Train Loss: 0.042196642607450485\n",
      "Train Loss: 0.052544329315423965\n",
      "Train Loss: 0.04332291707396507\n",
      "Train Loss: 0.09074420481920242\n",
      "Train Loss: 0.06429002434015274\n",
      "Train Loss: 0.04904459789395332\n",
      "Train Loss: 0.055518899112939835\n",
      "Train Loss: 0.04100123047828674\n",
      "Train Loss: 0.08967629820108414\n",
      "Train Loss: 0.05137103050947189\n",
      "Train Loss: 0.06236739084124565\n",
      "Train Loss: 0.08396434783935547\n",
      "Train Loss: 0.041534144431352615\n",
      "Train Loss: 0.054798468947410583\n",
      "Train Loss: 0.05416974425315857\n",
      "Train Loss: 0.16150975227355957\n",
      "Train Loss: 0.0503116212785244\n",
      "Train Loss: 0.06901833415031433\n",
      "Train Loss: 0.05391668900847435\n",
      "Train Loss: 0.07366559654474258\n",
      "Train Loss: 0.06336326152086258\n",
      "Train Loss: 0.0892021581530571\n",
      "Train Loss: 0.05526662617921829\n",
      "Train Loss: 0.06758037954568863\n",
      "Train Loss: 0.04162047430872917\n",
      "Train Loss: 0.06344836950302124\n",
      "Train Loss: 0.052580825984478\n",
      "Train Loss: 0.03864789009094238\n",
      "Train Loss: 0.04000465199351311\n",
      "Train Loss: 0.03553968667984009\n",
      "Train Loss: 0.03480948880314827\n",
      "Train Loss: 0.07867535948753357\n",
      "Train Loss: 0.06925007700920105\n",
      "Train Loss: 0.06587202101945877\n",
      "Train Loss: 0.07945603132247925\n",
      "Train Loss: 0.06736721098423004\n",
      "Train Loss: 0.0718718096613884\n",
      "Train Loss: 0.08498676866292953\n",
      "Train Loss: 0.06457740813493729\n",
      "Train Loss: 0.05486311390995979\n",
      "Train Loss: 0.09235583990812302\n",
      "Train Loss: 0.0818505510687828\n",
      "Train Loss: 0.04817337542772293\n",
      "Train Loss: 0.04552461951971054\n",
      "Train Loss: 0.0380660779774189\n",
      "Train Loss: 0.06285443156957626\n",
      "Train Loss: 0.059051863849163055\n",
      "Train Loss: 0.20662808418273926\n",
      "Train Loss: 0.04748572036623955\n",
      "Train Loss: 0.05605394393205643\n",
      "Train Loss: 0.062200888991355896\n",
      "Train Loss: 0.07723259180784225\n",
      "Train Loss: 0.06990868598222733\n",
      "Train Loss: 0.06461603194475174\n",
      "Train Loss: 0.06303320080041885\n",
      "Train Loss: 0.042323581874370575\n",
      "Train Loss: 0.04735806584358215\n",
      "Train Loss: 0.18921545147895813\n",
      "Train Loss: 0.03612613305449486\n",
      "Train Loss: 0.21892496943473816\n",
      "Train Loss: 0.0336453802883625\n",
      "Train Loss: 0.08478160947561264\n",
      "Train Loss: 0.1215968057513237\n",
      "Train Loss: 0.06239796429872513\n",
      "Train Loss: 0.04726367071270943\n",
      "Train Loss: 0.05804920196533203\n",
      "Train Loss: 0.1012628898024559\n",
      "Train Loss: 0.04101932793855667\n",
      "Train Loss: 0.047482024878263474\n",
      "Train Loss: 0.048455510288476944\n",
      "Train Loss: 0.054894767701625824\n",
      "Train Loss: 0.09268054366111755\n",
      "Train Loss: 0.08168735355138779\n",
      "Train Loss: 0.05281480401754379\n",
      "Train Loss: 0.04933637008070946\n",
      "Train Loss: 0.04455261304974556\n",
      "Train Loss: 0.12843430042266846\n",
      "Train Loss: 0.11626844108104706\n",
      "Train Loss: 0.04978558421134949\n",
      "Train Loss: 0.042006559669971466\n",
      "Train Loss: 0.07492577284574509\n",
      "Train Loss: 0.06885454803705215\n",
      "Train Loss: 0.059913020581007004\n",
      "Train Loss: 0.14712046086788177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f37b97be6cb4bbba8dfba265bfb66e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04171450063586235\n",
      "Validation Loss: 0.04459365829825401\n",
      "Validation Loss: 0.038555487990379333\n",
      "Validation Loss: 0.050148725509643555\n",
      "Validation Loss: 1.0546802282333374\n",
      "Validation Loss: 0.19171173870563507\n",
      "Validation Loss: 0.025009993463754654\n",
      "Validation Loss: 0.060854773968458176\n",
      "Validation Loss: 0.05123163014650345\n",
      "Validation Loss: 0.03746676445007324\n",
      "Validation Loss: 0.044184356927871704\n",
      "Validation Loss: 0.04265594109892845\n",
      "Validation Loss: 0.033347733318805695\n",
      "Validation Loss: 0.07800935208797455\n",
      "Validation Loss: 0.0556715652346611\n",
      "Validation Loss: 0.012804134748876095\n",
      "Validation Loss: 0.06204023212194443\n",
      "Validation Loss: 0.07200802862644196\n",
      "Validation Loss: 0.06474127620458603\n",
      "Validation Loss: 0.03493053466081619\n",
      "Validation Loss: 0.04172644019126892\n",
      "Validation Loss: 0.019233999773859978\n",
      "Validation Loss: 0.031695324927568436\n",
      "Validation Loss: 0.07639723271131516\n",
      "Validation Loss: 0.056595854461193085\n",
      "Validation Loss: 0.07923175394535065\n",
      "Validation Loss: 0.10201183706521988\n",
      "Validation Loss: 0.038431521505117416\n",
      "Validation Loss: 0.03556489199399948\n",
      "Validation Loss: 0.0627978965640068\n",
      "Validation Loss: 0.03655865043401718\n",
      "Validation Loss: 0.03618057444691658\n",
      "Validation Loss: 0.0329766720533371\n",
      "Validation Loss: 0.05448395386338234\n",
      "Train Loss: 0.060513727366924286\n",
      "Train Loss: 0.09716691076755524\n",
      "Train Loss: 0.061133597046136856\n",
      "Train Loss: 0.039091188460588455\n",
      "Train Loss: 0.04961390048265457\n",
      "Train Loss: 0.04138365760445595\n",
      "Train Loss: 0.1163531020283699\n",
      "Train Loss: 0.10846376419067383\n",
      "Train Loss: 0.07183966040611267\n",
      "Train Loss: 0.07354797422885895\n",
      "Train Loss: 0.07451614737510681\n",
      "Train Loss: 0.05034571513533592\n",
      "Train Loss: 0.04968726262450218\n",
      "Train Loss: 0.06670575588941574\n",
      "Train Loss: 0.047785110771656036\n",
      "Train Loss: 0.07314791530370712\n",
      "Train Loss: 0.0786462053656578\n",
      "Train Loss: 0.06389369815587997\n",
      "Train Loss: 0.062309786677360535\n",
      "Train Loss: 0.1129101887345314\n",
      "Train Loss: 0.08949527144432068\n",
      "Train Loss: 0.03874742612242699\n",
      "Train Loss: 0.04108637943863869\n",
      "Train Loss: 0.16717679798603058\n",
      "Train Loss: 0.06429735571146011\n",
      "Train Loss: 0.03796201944351196\n",
      "Train Loss: 0.058439213782548904\n",
      "Train Loss: 0.08459045737981796\n",
      "Train Loss: 0.1327466517686844\n",
      "Train Loss: 0.05090352147817612\n",
      "Train Loss: 0.04089105501770973\n",
      "Train Loss: 0.07827604562044144\n",
      "Train Loss: 0.07904630154371262\n",
      "Train Loss: 0.04607637971639633\n",
      "Train Loss: 0.062726229429245\n",
      "Train Loss: 0.056355662643909454\n",
      "Train Loss: 0.03807993605732918\n",
      "Train Loss: 0.04793882369995117\n",
      "Train Loss: 0.0490182526409626\n",
      "Train Loss: 0.05851710960268974\n",
      "Train Loss: 0.05793299153447151\n",
      "Train Loss: 0.025112120434641838\n",
      "Train Loss: 0.033669065684080124\n",
      "Train Loss: 0.03899926319718361\n",
      "Train Loss: 0.11469215154647827\n",
      "Train Loss: 0.03773847594857216\n",
      "Train Loss: 0.08379457145929337\n",
      "Train Loss: 0.05030984804034233\n",
      "Train Loss: 0.06779690831899643\n",
      "Train Loss: 0.06998151540756226\n",
      "Train Loss: 0.07354587316513062\n",
      "Train Loss: 0.040068041533231735\n",
      "Train Loss: 0.03417257219552994\n",
      "Train Loss: 0.09059120714664459\n",
      "Train Loss: 0.10296361148357391\n",
      "Train Loss: 0.05058165267109871\n",
      "Train Loss: 0.043704040348529816\n",
      "Train Loss: 0.04632316529750824\n",
      "Train Loss: 0.06231139227747917\n",
      "Train Loss: 0.04627694934606552\n",
      "Train Loss: 0.059910211712121964\n",
      "Train Loss: 0.0439959280192852\n",
      "Train Loss: 0.089931420981884\n",
      "Train Loss: 0.08564070612192154\n",
      "Train Loss: 0.056242164224386215\n",
      "Train Loss: 0.06197451055049896\n",
      "Train Loss: 0.07633090019226074\n",
      "Train Loss: 0.053641244769096375\n",
      "Train Loss: 0.14684399962425232\n",
      "Train Loss: 0.050472840666770935\n",
      "Train Loss: 0.05603095889091492\n",
      "Train Loss: 0.04771606624126434\n",
      "Train Loss: 0.07648491859436035\n",
      "Train Loss: 0.08050847053527832\n",
      "Train Loss: 0.03722772374749184\n",
      "Train Loss: 0.04615576192736626\n",
      "Train Loss: 0.0962972417473793\n",
      "Train Loss: 0.03969616815447807\n",
      "Train Loss: 0.06805858761072159\n",
      "Train Loss: 0.0571141242980957\n",
      "Train Loss: 0.08389715105295181\n",
      "Train Loss: 0.032324694097042084\n",
      "Train Loss: 0.11980301886796951\n",
      "Train Loss: 0.04962441325187683\n",
      "Train Loss: 0.05715988203883171\n",
      "Train Loss: 0.04984920099377632\n",
      "Train Loss: 0.0567547008395195\n",
      "Train Loss: 0.0515492781996727\n",
      "Train Loss: 0.04004755988717079\n",
      "Train Loss: 0.054535262286663055\n",
      "Train Loss: 0.04922691360116005\n",
      "Train Loss: 0.047565460205078125\n",
      "Train Loss: 0.058990478515625\n",
      "Train Loss: 0.04307461529970169\n",
      "Train Loss: 0.04902135208249092\n",
      "Train Loss: 0.06043540686368942\n",
      "Train Loss: 0.08218212425708771\n",
      "Train Loss: 0.059578537940979004\n",
      "Train Loss: 0.08324212580919266\n",
      "Train Loss: 0.03536875173449516\n",
      "Train Loss: 0.03696078807115555\n",
      "Train Loss: 0.07080242037773132\n",
      "Train Loss: 0.058182697743177414\n",
      "Train Loss: 0.05257540941238403\n",
      "Train Loss: 0.048270151019096375\n",
      "Train Loss: 0.056070778518915176\n",
      "Train Loss: 0.05275607109069824\n",
      "Train Loss: 0.035433825105428696\n",
      "Train Loss: 0.046707507222890854\n",
      "Train Loss: 0.04494993016123772\n",
      "Train Loss: 0.04586802050471306\n",
      "Train Loss: 0.05233076587319374\n",
      "Train Loss: 0.06086867302656174\n",
      "Train Loss: 0.03995639830827713\n",
      "Train Loss: 0.05525098741054535\n",
      "Train Loss: 0.19334644079208374\n",
      "Train Loss: 0.03797932341694832\n",
      "Train Loss: 0.04559524729847908\n",
      "Train Loss: 0.04031406715512276\n",
      "Train Loss: 0.0338929258286953\n",
      "Train Loss: 0.042278725653886795\n",
      "Train Loss: 0.08197056502103806\n",
      "Train Loss: 0.06882081180810928\n",
      "Train Loss: 0.07194789499044418\n",
      "Train Loss: 0.06827662140130997\n",
      "Train Loss: 0.05708223208785057\n",
      "Train Loss: 0.10266900062561035\n",
      "Train Loss: 0.04791651666164398\n",
      "Train Loss: 0.05039656162261963\n",
      "Train Loss: 0.04833667352795601\n",
      "Train Loss: 0.1306544542312622\n",
      "Train Loss: 0.09691766649484634\n",
      "Train Loss: 0.07454460859298706\n",
      "Train Loss: 0.0622391402721405\n",
      "Train Loss: 0.12997521460056305\n",
      "Train Loss: 0.07249727845191956\n",
      "Train Loss: 0.05870529264211655\n",
      "Train Loss: 0.04925697669386864\n",
      "Train Loss: 0.07185420393943787\n",
      "Train Loss: 0.061719171702861786\n",
      "Train Loss: 0.07386255264282227\n",
      "Train Loss: 0.08910653740167618\n",
      "Train Loss: 0.06571051478385925\n",
      "Train Loss: 0.061495207250118256\n",
      "Train Loss: 0.07986868917942047\n",
      "Train Loss: 0.09930887073278427\n",
      "Train Loss: 0.07059644907712936\n",
      "Train Loss: 0.15558089315891266\n",
      "Train Loss: 0.17018838226795197\n",
      "Train Loss: 0.10229217261075974\n",
      "Train Loss: 0.03637375310063362\n",
      "Train Loss: 0.04846442490816116\n",
      "Train Loss: 0.03891816362738609\n",
      "Train Loss: 0.06084992736577988\n",
      "Train Loss: 0.06942111253738403\n",
      "Train Loss: 0.0569443516433239\n",
      "Train Loss: 0.06712371855974197\n",
      "Train Loss: 0.07104162126779556\n",
      "Train Loss: 0.0667162612080574\n",
      "Train Loss: 0.0720970630645752\n",
      "Train Loss: 0.03754133731126785\n",
      "Train Loss: 0.04095366224646568\n",
      "Train Loss: 0.05801565200090408\n",
      "Train Loss: 0.053557805716991425\n",
      "Train Loss: 0.03945939615368843\n",
      "Train Loss: 0.09265881776809692\n",
      "Train Loss: 0.05000334605574608\n",
      "Train Loss: 0.0318591482937336\n",
      "Train Loss: 0.05553966015577316\n",
      "Train Loss: 0.07796119898557663\n",
      "Train Loss: 0.06005393713712692\n",
      "Train Loss: 0.046026188880205154\n",
      "Train Loss: 0.04875953868031502\n",
      "Train Loss: 0.07259181886911392\n",
      "Train Loss: 0.07806297391653061\n",
      "Train Loss: 0.04802970588207245\n",
      "Train Loss: 0.035495832562446594\n",
      "Train Loss: 0.20479267835617065\n",
      "Train Loss: 0.08892036229372025\n",
      "Train Loss: 0.06318730115890503\n",
      "Train Loss: 0.06958029419183731\n",
      "Train Loss: 0.06957285851240158\n",
      "Train Loss: 0.05775680020451546\n",
      "Train Loss: 0.06656209379434586\n",
      "Train Loss: 0.054849740117788315\n",
      "Train Loss: 0.07830047607421875\n",
      "Train Loss: 2.2741806507110596\n",
      "Train Loss: 0.03932533413171768\n",
      "Train Loss: 0.051409970968961716\n",
      "Train Loss: 0.8053043484687805\n",
      "Train Loss: 0.060567889362573624\n",
      "Train Loss: 0.10276054590940475\n",
      "Train Loss: 0.06388003379106522\n",
      "Train Loss: 0.06505075842142105\n",
      "Train Loss: 0.04685593768954277\n",
      "Train Loss: 0.0570264533162117\n",
      "Train Loss: 0.0663495659828186\n",
      "Train Loss: 0.08268982172012329\n",
      "Train Loss: 0.23249825835227966\n",
      "Train Loss: 0.04834447428584099\n",
      "Train Loss: 0.0683724656701088\n",
      "Train Loss: 0.049147140234708786\n",
      "Train Loss: 0.09738260507583618\n",
      "Train Loss: 0.07249309122562408\n",
      "Train Loss: 0.0625738799571991\n",
      "Train Loss: 0.08731099963188171\n",
      "Train Loss: 0.07196135073900223\n",
      "Train Loss: 0.061059292405843735\n",
      "Train Loss: 0.07076258957386017\n",
      "Train Loss: 0.09589946269989014\n",
      "Train Loss: 0.05481897294521332\n",
      "Train Loss: 0.09971313178539276\n",
      "Train Loss: 0.049946945160627365\n",
      "Train Loss: 0.07012771815061569\n",
      "Train Loss: 0.06511900573968887\n",
      "Train Loss: 0.04536041244864464\n",
      "Train Loss: 0.11070644855499268\n",
      "Train Loss: 0.0702076181769371\n",
      "Train Loss: 0.06111763045191765\n",
      "Train Loss: 0.06328578293323517\n",
      "Train Loss: 0.043489065021276474\n",
      "Train Loss: 0.07541851699352264\n",
      "Train Loss: 0.08949816226959229\n",
      "Train Loss: 0.055727504193782806\n",
      "Train Loss: 0.06392773985862732\n",
      "Train Loss: 0.055236659944057465\n",
      "Train Loss: 0.07537475228309631\n",
      "Train Loss: 0.05645737051963806\n",
      "Train Loss: 0.08201584219932556\n",
      "Train Loss: 0.060306452214717865\n",
      "Train Loss: 0.05033758282661438\n",
      "Train Loss: 0.05483046546578407\n",
      "Train Loss: 0.04732769355177879\n",
      "Train Loss: 0.1082773208618164\n",
      "Train Loss: 0.07075939327478409\n",
      "Train Loss: 0.058791909366846085\n",
      "Train Loss: 0.05984104797244072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dacb5c32cd34d1190cfa5ddefd2398a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.039420243352651596\n",
      "Validation Loss: 0.04055556654930115\n",
      "Validation Loss: 0.03839140385389328\n",
      "Validation Loss: 0.038063496351242065\n",
      "Validation Loss: 0.8387275338172913\n",
      "Validation Loss: 0.20626939833164215\n",
      "Validation Loss: 0.022811228409409523\n",
      "Validation Loss: 0.05831792205572128\n",
      "Validation Loss: 0.05091259256005287\n",
      "Validation Loss: 0.039285749197006226\n",
      "Validation Loss: 0.04066803678870201\n",
      "Validation Loss: 0.040193602442741394\n",
      "Validation Loss: 0.02781890518963337\n",
      "Validation Loss: 0.07817874103784561\n",
      "Validation Loss: 0.05385788157582283\n",
      "Validation Loss: 0.01322955172508955\n",
      "Validation Loss: 0.060529883950948715\n",
      "Validation Loss: 0.053642839193344116\n",
      "Validation Loss: 0.06234155222773552\n",
      "Validation Loss: 0.03648015856742859\n",
      "Validation Loss: 0.03832654654979706\n",
      "Validation Loss: 0.015561660751700401\n",
      "Validation Loss: 0.03195330128073692\n",
      "Validation Loss: 0.08040115982294083\n",
      "Validation Loss: 0.05725519359111786\n",
      "Validation Loss: 0.07734741270542145\n",
      "Validation Loss: 0.0919066071510315\n",
      "Validation Loss: 0.03489937633275986\n",
      "Validation Loss: 0.03205880895256996\n",
      "Validation Loss: 0.06694492697715759\n",
      "Validation Loss: 0.03198249638080597\n",
      "Validation Loss: 0.034598615020513535\n",
      "Validation Loss: 0.02926569990813732\n",
      "Validation Loss: 0.051755353808403015\n",
      "Train Loss: 0.043626148253679276\n",
      "Train Loss: 0.0659690871834755\n",
      "Train Loss: 0.05602577328681946\n",
      "Train Loss: 0.0442655086517334\n",
      "Train Loss: 0.13425259292125702\n",
      "Train Loss: 0.07021166384220123\n",
      "Train Loss: 0.06789067387580872\n",
      "Train Loss: 0.0718713030219078\n",
      "Train Loss: 0.04084981605410576\n",
      "Train Loss: 0.04839126765727997\n",
      "Train Loss: 0.04134826362133026\n",
      "Train Loss: 0.04441440477967262\n",
      "Train Loss: 0.10225791484117508\n",
      "Train Loss: 0.0784011259675026\n",
      "Train Loss: 0.05735199153423309\n",
      "Train Loss: 0.09160484373569489\n",
      "Train Loss: 0.050980959087610245\n",
      "Train Loss: 0.03630839288234711\n",
      "Train Loss: 0.052010517567396164\n",
      "Train Loss: 0.06537379324436188\n",
      "Train Loss: 0.06349168717861176\n",
      "Train Loss: 0.08588290214538574\n",
      "Train Loss: 0.06312300264835358\n",
      "Train Loss: 0.03751368448138237\n",
      "Train Loss: 0.04825363680720329\n",
      "Train Loss: 0.06223517283797264\n",
      "Train Loss: 0.04841332137584686\n",
      "Train Loss: 0.05563568323850632\n",
      "Train Loss: 0.11790034174919128\n",
      "Train Loss: 0.06724363565444946\n",
      "Train Loss: 0.105231873691082\n",
      "Train Loss: 0.06950397789478302\n",
      "Train Loss: 0.05826672911643982\n",
      "Train Loss: 0.039021797478199005\n",
      "Train Loss: 0.07118696719408035\n",
      "Train Loss: 0.04442785307765007\n",
      "Train Loss: 0.037608157843351364\n",
      "Train Loss: 0.04638772830367088\n",
      "Train Loss: 0.04017346724867821\n",
      "Train Loss: 0.051543913781642914\n",
      "Train Loss: 0.11964995414018631\n",
      "Train Loss: 0.07805764675140381\n",
      "Train Loss: 0.06740190088748932\n",
      "Train Loss: 0.0640617161989212\n",
      "Train Loss: 0.06952041387557983\n",
      "Train Loss: 0.0761973038315773\n",
      "Train Loss: 0.12417714297771454\n",
      "Train Loss: 0.07222254574298859\n",
      "Train Loss: 0.04634593799710274\n",
      "Train Loss: 0.05618797987699509\n",
      "Train Loss: 0.06738396733999252\n",
      "Train Loss: 0.04825669154524803\n",
      "Train Loss: 0.14179757237434387\n",
      "Train Loss: 0.04840653017163277\n",
      "Train Loss: 0.03726852685213089\n",
      "Train Loss: 0.06955236196517944\n",
      "Train Loss: 0.054328083992004395\n",
      "Train Loss: 0.0655398815870285\n",
      "Train Loss: 0.03526994585990906\n",
      "Train Loss: 0.06743482500314713\n",
      "Train Loss: 0.042693011462688446\n",
      "Train Loss: 0.05351501703262329\n",
      "Train Loss: 0.048036593943834305\n",
      "Train Loss: 0.05113068222999573\n",
      "Train Loss: 0.04138330742716789\n",
      "Train Loss: 0.07890647649765015\n",
      "Train Loss: 0.05509345233440399\n",
      "Train Loss: 0.04578542336821556\n",
      "Train Loss: 0.050781965255737305\n",
      "Train Loss: 0.05220967158675194\n",
      "Train Loss: 0.178302600979805\n",
      "Train Loss: 0.06388537585735321\n",
      "Train Loss: 0.07835035026073456\n",
      "Train Loss: 0.04780048131942749\n",
      "Train Loss: 0.07603132724761963\n",
      "Train Loss: 0.08970898389816284\n",
      "Train Loss: 0.04865080863237381\n",
      "Train Loss: 0.07442561537027359\n",
      "Train Loss: 0.16137047111988068\n",
      "Train Loss: 0.0989217460155487\n",
      "Train Loss: 0.7676973342895508\n",
      "Train Loss: 0.04217598959803581\n",
      "Train Loss: 0.030870335176587105\n",
      "Train Loss: 0.04442461580038071\n",
      "Train Loss: 0.02988644503057003\n",
      "Train Loss: 0.0477539524435997\n",
      "Train Loss: 0.0769679918885231\n",
      "Train Loss: 0.0699751079082489\n",
      "Train Loss: 0.04484529048204422\n",
      "Train Loss: 0.10079125314950943\n",
      "Train Loss: 0.036219168454408646\n",
      "Train Loss: 0.04479598253965378\n",
      "Train Loss: 0.05161000415682793\n",
      "Train Loss: 0.05991029739379883\n",
      "Train Loss: 0.12706387042999268\n",
      "Train Loss: 0.057076506316661835\n",
      "Train Loss: 0.08290544897317886\n",
      "Train Loss: 0.050664227455854416\n",
      "Train Loss: 0.035303208976984024\n",
      "Train Loss: 0.06101307272911072\n",
      "Train Loss: 0.04689045995473862\n",
      "Train Loss: 0.08229102939367294\n",
      "Train Loss: 0.05764704570174217\n",
      "Train Loss: 0.03710702061653137\n",
      "Train Loss: 0.03862856328487396\n",
      "Train Loss: 0.1048959493637085\n",
      "Train Loss: 0.056532666087150574\n",
      "Train Loss: 0.03395744785666466\n",
      "Train Loss: 0.08585715293884277\n",
      "Train Loss: 0.06862868368625641\n",
      "Train Loss: 0.13395161926746368\n",
      "Train Loss: 0.07280132919549942\n",
      "Train Loss: 0.05298807471990585\n",
      "Train Loss: 0.06452658027410507\n",
      "Train Loss: 0.059138260781764984\n",
      "Train Loss: 0.04012642800807953\n",
      "Train Loss: 0.054515108466148376\n",
      "Train Loss: 0.0719083771109581\n",
      "Train Loss: 0.03633744269609451\n",
      "Train Loss: 0.05599120631814003\n",
      "Train Loss: 0.04916615039110184\n",
      "Train Loss: 0.0575956329703331\n",
      "Train Loss: 0.10926162451505661\n",
      "Train Loss: 0.06718792766332626\n",
      "Train Loss: 0.09607227891683578\n",
      "Train Loss: 0.07294491678476334\n",
      "Train Loss: 0.08579177409410477\n",
      "Train Loss: 0.0620279423892498\n",
      "Train Loss: 0.043223828077316284\n",
      "Train Loss: 0.043407656252384186\n",
      "Train Loss: 0.03812003508210182\n",
      "Train Loss: 0.04712115600705147\n",
      "Train Loss: 0.07560254633426666\n",
      "Train Loss: 0.0703783705830574\n",
      "Train Loss: 0.04419318959116936\n",
      "Train Loss: 0.06471764296293259\n",
      "Train Loss: 0.08857069164514542\n",
      "Train Loss: 0.031201502308249474\n",
      "Train Loss: 0.05675823241472244\n",
      "Train Loss: 0.048778802156448364\n",
      "Train Loss: 0.07194700837135315\n",
      "Train Loss: 0.04952286556363106\n",
      "Train Loss: 0.05436405912041664\n",
      "Train Loss: 0.0626787394285202\n",
      "Train Loss: 0.0647110864520073\n",
      "Train Loss: 0.07786983996629715\n",
      "Train Loss: 0.06790484488010406\n",
      "Train Loss: 0.04659242182970047\n",
      "Train Loss: 0.0301177017390728\n",
      "Train Loss: 0.04331040382385254\n",
      "Train Loss: 0.0755501464009285\n",
      "Train Loss: 0.14706094563007355\n",
      "Train Loss: 0.07928325980901718\n",
      "Train Loss: 0.05442257970571518\n",
      "Train Loss: 0.040020525455474854\n",
      "Train Loss: 0.048546433448791504\n",
      "Train Loss: 0.039709169417619705\n",
      "Train Loss: 0.06623317301273346\n",
      "Train Loss: 0.06273246556520462\n",
      "Train Loss: 0.050456877797842026\n",
      "Train Loss: 0.06567450612783432\n",
      "Train Loss: 0.056609611958265305\n",
      "Train Loss: 0.04738130420446396\n",
      "Train Loss: 0.053410016000270844\n",
      "Train Loss: 0.04394468665122986\n",
      "Train Loss: 0.06905511766672134\n",
      "Train Loss: 0.1839868426322937\n",
      "Train Loss: 0.04931534081697464\n",
      "Train Loss: 0.05388607829809189\n",
      "Train Loss: 0.04791726917028427\n",
      "Train Loss: 0.12761083245277405\n",
      "Train Loss: 2.3365960121154785\n",
      "Train Loss: 0.06210474669933319\n",
      "Train Loss: 0.05485350638628006\n",
      "Train Loss: 0.095920130610466\n",
      "Train Loss: 0.055676668882369995\n",
      "Train Loss: 0.03459199517965317\n",
      "Train Loss: 0.07854782044887543\n",
      "Train Loss: 0.05658019706606865\n",
      "Train Loss: 0.05261072516441345\n",
      "Train Loss: 0.05509110167622566\n",
      "Train Loss: 0.06532992422580719\n",
      "Train Loss: 0.05483892932534218\n",
      "Train Loss: 0.0539911724627018\n",
      "Train Loss: 0.05836150050163269\n",
      "Train Loss: 0.08136140555143356\n",
      "Train Loss: 0.06785617023706436\n",
      "Train Loss: 0.04563456401228905\n",
      "Train Loss: 0.12522229552268982\n",
      "Train Loss: 0.04418666288256645\n",
      "Train Loss: 0.0752924233675003\n",
      "Train Loss: 0.056072551757097244\n",
      "Train Loss: 0.04424155503511429\n",
      "Train Loss: 0.10188963264226913\n",
      "Train Loss: 0.05458018183708191\n",
      "Train Loss: 0.06221316382288933\n",
      "Train Loss: 0.05081712082028389\n",
      "Train Loss: 0.04335365071892738\n",
      "Train Loss: 0.14567208290100098\n",
      "Train Loss: 0.12894457578659058\n",
      "Train Loss: 0.05761309340596199\n",
      "Train Loss: 0.2327454835176468\n",
      "Train Loss: 0.06363105028867722\n",
      "Train Loss: 0.053564321249723434\n",
      "Train Loss: 0.06636850535869598\n",
      "Train Loss: 0.042869146913290024\n",
      "Train Loss: 0.05750737711787224\n",
      "Train Loss: 0.08497897535562515\n",
      "Train Loss: 0.04658154770731926\n",
      "Train Loss: 0.07072720676660538\n",
      "Train Loss: 0.050214216113090515\n",
      "Train Loss: 0.06616543233394623\n",
      "Train Loss: 0.057358987629413605\n",
      "Train Loss: 0.05902818962931633\n",
      "Train Loss: 0.030903177335858345\n",
      "Train Loss: 0.07729639858007431\n",
      "Train Loss: 0.05169718712568283\n",
      "Train Loss: 0.06140436604619026\n",
      "Train Loss: 0.059868037700653076\n",
      "Train Loss: 0.049404606223106384\n",
      "Train Loss: 0.05707636848092079\n",
      "Train Loss: 0.04385797679424286\n",
      "Train Loss: 0.047537606209516525\n",
      "Train Loss: 0.04640325903892517\n",
      "Train Loss: 0.05528595298528671\n",
      "Train Loss: 0.2063247412443161\n",
      "Train Loss: 0.05283746495842934\n",
      "Train Loss: 0.04858895391225815\n",
      "Train Loss: 0.04495464265346527\n",
      "Train Loss: 0.04254120588302612\n",
      "Train Loss: 0.05705619603395462\n",
      "Train Loss: 0.07760948687791824\n",
      "Train Loss: 0.04468141868710518\n",
      "Train Loss: 0.06224808469414711\n",
      "Train Loss: 0.07055813819169998\n",
      "Train Loss: 0.02876031957566738\n",
      "Train Loss: 0.03260241076350212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443f066a31dc4fae887572bc0bd0b4e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03728026524186134\n",
      "Validation Loss: 0.037666432559490204\n",
      "Validation Loss: 0.031073054298758507\n",
      "Validation Loss: 0.04145066812634468\n",
      "Validation Loss: 1.1727843284606934\n",
      "Validation Loss: 0.1819131225347519\n",
      "Validation Loss: 0.022016866132616997\n",
      "Validation Loss: 0.058658014982938766\n",
      "Validation Loss: 0.04707425460219383\n",
      "Validation Loss: 0.03861195594072342\n",
      "Validation Loss: 0.04150436818599701\n",
      "Validation Loss: 0.040286336094141006\n",
      "Validation Loss: 0.02290487289428711\n",
      "Validation Loss: 0.07543732225894928\n",
      "Validation Loss: 0.05551857501268387\n",
      "Validation Loss: 0.01322747953236103\n",
      "Validation Loss: 0.059255342930555344\n",
      "Validation Loss: 0.04757804423570633\n",
      "Validation Loss: 0.05943341925740242\n",
      "Validation Loss: 0.03173452615737915\n",
      "Validation Loss: 0.03880659490823746\n",
      "Validation Loss: 0.016110286116600037\n",
      "Validation Loss: 0.029852112755179405\n",
      "Validation Loss: 0.07533645629882812\n",
      "Validation Loss: 0.055390890687704086\n",
      "Validation Loss: 0.07772032916545868\n",
      "Validation Loss: 0.0891357809305191\n",
      "Validation Loss: 0.03359876200556755\n",
      "Validation Loss: 0.03282708302140236\n",
      "Validation Loss: 0.06187296658754349\n",
      "Validation Loss: 0.034001730382442474\n",
      "Validation Loss: 0.033850740641355515\n",
      "Validation Loss: 0.030822107568383217\n",
      "Validation Loss: 0.04933013767004013\n",
      "Train Loss: 0.04677847400307655\n",
      "Train Loss: 0.07976212352514267\n",
      "Train Loss: 0.05311586707830429\n",
      "Train Loss: 0.0570928193628788\n",
      "Train Loss: 0.0513400174677372\n",
      "Train Loss: 0.04416145011782646\n",
      "Train Loss: 0.044805847108364105\n",
      "Train Loss: 0.08050346374511719\n",
      "Train Loss: 2.234872579574585\n",
      "Train Loss: 0.07239176332950592\n",
      "Train Loss: 0.046050213277339935\n",
      "Train Loss: 0.03714403882622719\n",
      "Train Loss: 0.046108268201351166\n",
      "Train Loss: 0.058805208653211594\n",
      "Train Loss: 0.06639598309993744\n",
      "Train Loss: 0.07068625837564468\n",
      "Train Loss: 0.09609777480363846\n",
      "Train Loss: 0.0620872788131237\n",
      "Train Loss: 0.05326396971940994\n",
      "Train Loss: 0.14601771533489227\n",
      "Train Loss: 0.06141481176018715\n",
      "Train Loss: 0.06773597002029419\n",
      "Train Loss: 0.06326237320899963\n",
      "Train Loss: 0.05966050177812576\n",
      "Train Loss: 0.04545845836400986\n",
      "Train Loss: 0.13459712266921997\n",
      "Train Loss: 0.07625224441289902\n",
      "Train Loss: 0.08028224110603333\n",
      "Train Loss: 0.04107992723584175\n",
      "Train Loss: 0.07086264342069626\n",
      "Train Loss: 0.09505349397659302\n",
      "Train Loss: 0.06279954314231873\n",
      "Train Loss: 0.050247810781002045\n",
      "Train Loss: 0.0915776714682579\n",
      "Train Loss: 0.09756778925657272\n",
      "Train Loss: 0.04737665504217148\n",
      "Train Loss: 0.05150315538048744\n",
      "Train Loss: 0.040870364755392075\n",
      "Train Loss: 0.05414673686027527\n",
      "Train Loss: 0.05710114166140556\n",
      "Train Loss: 0.07200141251087189\n",
      "Train Loss: 0.037158213555812836\n",
      "Train Loss: 0.04198278859257698\n",
      "Train Loss: 0.04385292902588844\n",
      "Train Loss: 0.053313788026571274\n",
      "Train Loss: 0.05564176291227341\n",
      "Train Loss: 0.054152242839336395\n",
      "Train Loss: 0.061241716146469116\n",
      "Train Loss: 0.07362256944179535\n",
      "Train Loss: 0.16480058431625366\n",
      "Train Loss: 0.051574524492025375\n",
      "Train Loss: 0.054894447326660156\n",
      "Train Loss: 0.051987528800964355\n",
      "Train Loss: 0.02709168754518032\n",
      "Train Loss: 0.04691038653254509\n",
      "Train Loss: 0.06848704814910889\n",
      "Train Loss: 0.04236774519085884\n",
      "Train Loss: 0.05531465634703636\n",
      "Train Loss: 0.05441441386938095\n",
      "Train Loss: 0.04446779564023018\n",
      "Train Loss: 0.7759187817573547\n",
      "Train Loss: 0.02604353055357933\n",
      "Train Loss: 0.040737271308898926\n",
      "Train Loss: 0.05472821742296219\n",
      "Train Loss: 0.06309723109006882\n",
      "Train Loss: 0.06703127920627594\n",
      "Train Loss: 0.056896328926086426\n",
      "Train Loss: 0.1321810483932495\n",
      "Train Loss: 0.05248809605836868\n",
      "Train Loss: 0.0406358428299427\n",
      "Train Loss: 0.05909458175301552\n",
      "Train Loss: 0.05250271037220955\n",
      "Train Loss: 0.05482754111289978\n",
      "Train Loss: 0.044162947684526443\n",
      "Train Loss: 0.045533809810876846\n",
      "Train Loss: 0.08496526628732681\n",
      "Train Loss: 0.06538344919681549\n",
      "Train Loss: 0.05298759788274765\n",
      "Train Loss: 0.0325751006603241\n",
      "Train Loss: 0.07472137361764908\n",
      "Train Loss: 0.09641605615615845\n",
      "Train Loss: 0.06897813081741333\n",
      "Train Loss: 0.06396825611591339\n",
      "Train Loss: 0.05274204909801483\n",
      "Train Loss: 0.0295519158244133\n",
      "Train Loss: 0.06944853812456131\n",
      "Train Loss: 0.061938103288412094\n",
      "Train Loss: 0.05020977184176445\n",
      "Train Loss: 0.055159520357847214\n",
      "Train Loss: 0.04907132312655449\n",
      "Train Loss: 0.04141697660088539\n",
      "Train Loss: 0.08416101336479187\n",
      "Train Loss: 0.07596272230148315\n",
      "Train Loss: 0.051041316241025925\n",
      "Train Loss: 0.03516631945967674\n",
      "Train Loss: 0.045744869858026505\n",
      "Train Loss: 0.06632114946842194\n",
      "Train Loss: 0.10022184997797012\n",
      "Train Loss: 0.12730002403259277\n",
      "Train Loss: 0.0507519468665123\n",
      "Train Loss: 0.06052970141172409\n",
      "Train Loss: 0.03956315666437149\n",
      "Train Loss: 0.06359533965587616\n",
      "Train Loss: 0.04281873628497124\n",
      "Train Loss: 0.059090811759233475\n",
      "Train Loss: 0.04619555547833443\n",
      "Train Loss: 0.06848014891147614\n",
      "Train Loss: 0.040184181183576584\n",
      "Train Loss: 0.056578271090984344\n",
      "Train Loss: 0.07322843372821808\n",
      "Train Loss: 0.06640776991844177\n",
      "Train Loss: 0.20934370160102844\n",
      "Train Loss: 0.05569784343242645\n",
      "Train Loss: 0.05425005778670311\n",
      "Train Loss: 0.040543992072343826\n",
      "Train Loss: 0.0688619390130043\n",
      "Train Loss: 0.05955164134502411\n",
      "Train Loss: 0.09814786911010742\n",
      "Train Loss: 0.03027222491800785\n",
      "Train Loss: 0.06263414770364761\n",
      "Train Loss: 0.045395392924547195\n",
      "Train Loss: 0.03581497073173523\n",
      "Train Loss: 0.04898109287023544\n",
      "Train Loss: 0.13104882836341858\n",
      "Train Loss: 0.12243448197841644\n",
      "Train Loss: 0.044720981270074844\n",
      "Train Loss: 0.047969698905944824\n",
      "Train Loss: 0.0566883310675621\n",
      "Train Loss: 0.0693085566163063\n",
      "Train Loss: 0.05674775317311287\n",
      "Train Loss: 0.05634983256459236\n",
      "Train Loss: 0.056810520589351654\n",
      "Train Loss: 0.06837314367294312\n",
      "Train Loss: 0.04922924563288689\n",
      "Train Loss: 0.08857515454292297\n",
      "Train Loss: 0.0514611080288887\n",
      "Train Loss: 0.053303103893995285\n",
      "Train Loss: 0.05261563882231712\n",
      "Train Loss: 0.04479386657476425\n",
      "Train Loss: 0.06598258018493652\n",
      "Train Loss: 0.048996616154909134\n",
      "Train Loss: 0.17899619042873383\n",
      "Train Loss: 0.05619675666093826\n",
      "Train Loss: 0.06328070163726807\n",
      "Train Loss: 0.035520222038030624\n",
      "Train Loss: 0.06265298277139664\n",
      "Train Loss: 0.04050351306796074\n",
      "Train Loss: 0.04215215891599655\n",
      "Train Loss: 0.07169671356678009\n",
      "Train Loss: 0.04065582528710365\n",
      "Train Loss: 0.07040250301361084\n",
      "Train Loss: 0.07505707442760468\n",
      "Train Loss: 0.06303972750902176\n",
      "Train Loss: 0.03878875821828842\n",
      "Train Loss: 0.05190243571996689\n",
      "Train Loss: 0.05213770270347595\n",
      "Train Loss: 0.06735104322433472\n",
      "Train Loss: 0.036100927740335464\n",
      "Train Loss: 0.05386688560247421\n",
      "Train Loss: 0.07478863000869751\n",
      "Train Loss: 0.04077838361263275\n",
      "Train Loss: 0.07119116932153702\n",
      "Train Loss: 0.034404683858156204\n",
      "Train Loss: 0.052053302526474\n",
      "Train Loss: 0.05391138419508934\n",
      "Train Loss: 0.05114791914820671\n",
      "Train Loss: 0.043603334575891495\n",
      "Train Loss: 0.08001872152090073\n",
      "Train Loss: 0.06927813589572906\n",
      "Train Loss: 0.04751932621002197\n",
      "Train Loss: 0.04927830398082733\n",
      "Train Loss: 0.05245117470622063\n",
      "Train Loss: 0.1768660992383957\n",
      "Train Loss: 0.047704193741083145\n",
      "Train Loss: 0.038330525159835815\n",
      "Train Loss: 0.04768809676170349\n",
      "Train Loss: 0.092378631234169\n",
      "Train Loss: 0.06477818638086319\n",
      "Train Loss: 0.05173049867153168\n",
      "Train Loss: 0.044076934456825256\n",
      "Train Loss: 0.11369573324918747\n",
      "Train Loss: 0.03951159119606018\n",
      "Train Loss: 0.04739735648036003\n",
      "Train Loss: 0.08152122795581818\n",
      "Train Loss: 0.05122840404510498\n",
      "Train Loss: 0.05751298367977142\n",
      "Train Loss: 0.05470583215355873\n",
      "Train Loss: 0.06823290884494781\n",
      "Train Loss: 0.055993564426898956\n",
      "Train Loss: 0.057939086109399796\n",
      "Train Loss: 0.0452137291431427\n",
      "Train Loss: 0.048675235360860825\n",
      "Train Loss: 0.05286367982625961\n",
      "Train Loss: 0.08752862364053726\n",
      "Train Loss: 0.18897409737110138\n",
      "Train Loss: 0.07009994238615036\n",
      "Train Loss: 0.052010342478752136\n",
      "Train Loss: 0.045397933572530746\n",
      "Train Loss: 0.04135867953300476\n",
      "Train Loss: 0.0412459596991539\n",
      "Train Loss: 0.048866163939237595\n",
      "Train Loss: 0.18337447941303253\n",
      "Train Loss: 0.07692208886146545\n",
      "Train Loss: 0.05864936113357544\n",
      "Train Loss: 0.054482072591781616\n",
      "Train Loss: 0.06634843349456787\n",
      "Train Loss: 0.05608696863055229\n",
      "Train Loss: 0.08451838791370392\n",
      "Train Loss: 0.049954067915678024\n",
      "Train Loss: 0.1286737471818924\n",
      "Train Loss: 0.06111270189285278\n",
      "Train Loss: 0.09141882508993149\n",
      "Train Loss: 0.0385114848613739\n",
      "Train Loss: 0.09526696056127548\n",
      "Train Loss: 0.03995932266116142\n",
      "Train Loss: 0.08696797490119934\n",
      "Train Loss: 0.07002568244934082\n",
      "Train Loss: 0.06168411672115326\n",
      "Train Loss: 0.06361649930477142\n",
      "Train Loss: 0.043525826185941696\n",
      "Train Loss: 0.04318016767501831\n",
      "Train Loss: 0.05508166179060936\n",
      "Train Loss: 0.028846779838204384\n",
      "Train Loss: 0.03226017579436302\n",
      "Train Loss: 0.07497378438711166\n",
      "Train Loss: 0.04154392331838608\n",
      "Train Loss: 0.06477624177932739\n",
      "Train Loss: 0.0331169068813324\n",
      "Train Loss: 0.09026328474283218\n",
      "Train Loss: 0.049628812819719315\n",
      "Train Loss: 0.095140241086483\n",
      "Train Loss: 0.04962260276079178\n",
      "Train Loss: 0.04940826818346977\n",
      "Train Loss: 0.08132421970367432\n",
      "Train Loss: 0.04062940180301666\n",
      "Train Loss: 0.06168545410037041\n",
      "Train Loss: 0.24119125306606293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6795c514cc074df8985517e386e3c575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04101312905550003\n",
      "Validation Loss: 0.041786227375268936\n",
      "Validation Loss: 0.038286931812763214\n",
      "Validation Loss: 0.04424932971596718\n",
      "Validation Loss: 0.8456733226776123\n",
      "Validation Loss: 0.22560341656208038\n",
      "Validation Loss: 0.024775240570306778\n",
      "Validation Loss: 0.05643892288208008\n",
      "Validation Loss: 0.04868679866194725\n",
      "Validation Loss: 0.03752142935991287\n",
      "Validation Loss: 0.04553055763244629\n",
      "Validation Loss: 0.042090725153684616\n",
      "Validation Loss: 0.031439147889614105\n",
      "Validation Loss: 0.07561010122299194\n",
      "Validation Loss: 0.054521795362234116\n",
      "Validation Loss: 0.010566428303718567\n",
      "Validation Loss: 0.059599731117486954\n",
      "Validation Loss: 0.06331320106983185\n",
      "Validation Loss: 0.060823410749435425\n",
      "Validation Loss: 0.03200029954314232\n",
      "Validation Loss: 0.0402664840221405\n",
      "Validation Loss: 0.014257187955081463\n",
      "Validation Loss: 0.031320031732320786\n",
      "Validation Loss: 0.08053711801767349\n",
      "Validation Loss: 0.05404365062713623\n",
      "Validation Loss: 0.08159378916025162\n",
      "Validation Loss: 0.09744467586278915\n",
      "Validation Loss: 0.03650713711977005\n",
      "Validation Loss: 0.03564128279685974\n",
      "Validation Loss: 0.061454784125089645\n",
      "Validation Loss: 0.037340372800827026\n",
      "Validation Loss: 0.035566601902246475\n",
      "Validation Loss: 0.034836601465940475\n",
      "Validation Loss: 0.057172875851392746\n",
      "Train Loss: 0.03568929806351662\n",
      "Train Loss: 0.04572330042719841\n",
      "Train Loss: 0.05072139576077461\n",
      "Train Loss: 0.060640476644039154\n",
      "Train Loss: 0.06131495162844658\n",
      "Train Loss: 0.058308493345975876\n",
      "Train Loss: 0.06531903892755508\n",
      "Train Loss: 0.07617561519145966\n",
      "Train Loss: 0.07532614469528198\n",
      "Train Loss: 0.0737130418419838\n",
      "Train Loss: 0.04765006899833679\n",
      "Train Loss: 0.036669861525297165\n",
      "Train Loss: 0.05846747010946274\n",
      "Train Loss: 0.09387289732694626\n",
      "Train Loss: 0.03692077472805977\n",
      "Train Loss: 0.031326066702604294\n",
      "Train Loss: 0.050024423748254776\n",
      "Train Loss: 2.25795578956604\n",
      "Train Loss: 0.042904507368803024\n",
      "Train Loss: 0.06314991414546967\n",
      "Train Loss: 0.07194782793521881\n",
      "Train Loss: 0.03716830909252167\n",
      "Train Loss: 0.05918213725090027\n",
      "Train Loss: 0.06941582262516022\n",
      "Train Loss: 0.11538253724575043\n",
      "Train Loss: 0.061987511813640594\n",
      "Train Loss: 0.05802825465798378\n",
      "Train Loss: 0.07619846612215042\n",
      "Train Loss: 0.06755727529525757\n",
      "Train Loss: 0.09886214882135391\n",
      "Train Loss: 0.03879950940608978\n",
      "Train Loss: 0.07042188942432404\n",
      "Train Loss: 0.07409486919641495\n",
      "Train Loss: 0.06964632123708725\n",
      "Train Loss: 0.0512811616063118\n",
      "Train Loss: 0.06160062551498413\n",
      "Train Loss: 0.0648365169763565\n",
      "Train Loss: 0.05921858549118042\n",
      "Train Loss: 0.065736785531044\n",
      "Train Loss: 0.07146561145782471\n",
      "Train Loss: 0.07480134814977646\n",
      "Train Loss: 0.09070751816034317\n",
      "Train Loss: 0.02872021682560444\n",
      "Train Loss: 0.051152393221855164\n",
      "Train Loss: 0.0447261668741703\n",
      "Train Loss: 0.04007239267230034\n",
      "Train Loss: 0.08724970370531082\n",
      "Train Loss: 0.06482972204685211\n",
      "Train Loss: 0.03534228727221489\n",
      "Train Loss: 0.05440489947795868\n",
      "Train Loss: 0.07857641577720642\n",
      "Train Loss: 0.06591615825891495\n",
      "Train Loss: 0.06335916370153427\n",
      "Train Loss: 0.06681928783655167\n",
      "Train Loss: 0.07319432497024536\n",
      "Train Loss: 0.06917469948530197\n",
      "Train Loss: 0.0677950382232666\n",
      "Train Loss: 0.024903105571866035\n",
      "Train Loss: 0.0488232858479023\n",
      "Train Loss: 0.04359548166394234\n",
      "Train Loss: 0.046725187450647354\n",
      "Train Loss: 0.05035941302776337\n",
      "Train Loss: 0.05393609404563904\n",
      "Train Loss: 0.035054292529821396\n",
      "Train Loss: 0.05337467044591904\n",
      "Train Loss: 0.04244578257203102\n",
      "Train Loss: 0.038880135864019394\n",
      "Train Loss: 0.07428479194641113\n",
      "Train Loss: 0.029476527124643326\n",
      "Train Loss: 0.04787595942616463\n",
      "Train Loss: 0.05234081298112869\n",
      "Train Loss: 0.06794539839029312\n",
      "Train Loss: 0.06501519680023193\n",
      "Train Loss: 0.043461550027132034\n",
      "Train Loss: 0.07353094965219498\n",
      "Train Loss: 0.04000791907310486\n",
      "Train Loss: 0.06870555877685547\n",
      "Train Loss: 0.033442769199609756\n",
      "Train Loss: 0.046871889382600784\n",
      "Train Loss: 0.07186286151409149\n",
      "Train Loss: 0.04421721398830414\n",
      "Train Loss: 0.04633944854140282\n",
      "Train Loss: 0.08205115050077438\n",
      "Train Loss: 0.035414449870586395\n",
      "Train Loss: 0.07225031405687332\n",
      "Train Loss: 0.04846448451280594\n",
      "Train Loss: 0.056065116077661514\n",
      "Train Loss: 0.03648628666996956\n",
      "Train Loss: 0.07276858389377594\n",
      "Train Loss: 0.06373383104801178\n",
      "Train Loss: 0.05283806845545769\n",
      "Train Loss: 0.09287574142217636\n",
      "Train Loss: 0.07317482680082321\n",
      "Train Loss: 0.07657530903816223\n",
      "Train Loss: 0.07019131630659103\n",
      "Train Loss: 0.03654595464468002\n",
      "Train Loss: 0.1532389223575592\n",
      "Train Loss: 0.05153462290763855\n",
      "Train Loss: 0.09443533420562744\n",
      "Train Loss: 0.055459436029195786\n",
      "Train Loss: 0.05758783221244812\n",
      "Train Loss: 0.03745752200484276\n",
      "Train Loss: 0.058455877006053925\n",
      "Train Loss: 0.10713577270507812\n",
      "Train Loss: 0.04458877444267273\n",
      "Train Loss: 0.7603633403778076\n",
      "Train Loss: 0.06861566752195358\n",
      "Train Loss: 0.12559670209884644\n",
      "Train Loss: 0.07237070798873901\n",
      "Train Loss: 0.04627075046300888\n",
      "Train Loss: 0.04202654957771301\n",
      "Train Loss: 0.04100071266293526\n",
      "Train Loss: 0.06461310386657715\n",
      "Train Loss: 0.0553421825170517\n",
      "Train Loss: 0.07385364919900894\n",
      "Train Loss: 0.043719202280044556\n",
      "Train Loss: 0.0539393350481987\n",
      "Train Loss: 0.035530220717191696\n",
      "Train Loss: 0.05919725447893143\n",
      "Train Loss: 0.04441554471850395\n",
      "Train Loss: 0.039339691400527954\n",
      "Train Loss: 0.029586706310510635\n",
      "Train Loss: 0.08378622680902481\n",
      "Train Loss: 0.054177165031433105\n",
      "Train Loss: 0.06924967467784882\n",
      "Train Loss: 0.08874404430389404\n",
      "Train Loss: 0.0886947512626648\n",
      "Train Loss: 0.09434273093938828\n",
      "Train Loss: 0.03630749136209488\n",
      "Train Loss: 0.05255585536360741\n",
      "Train Loss: 0.03921141475439072\n",
      "Train Loss: 0.048460494726896286\n",
      "Train Loss: 0.029240677133202553\n",
      "Train Loss: 0.06118595600128174\n",
      "Train Loss: 0.06873804330825806\n",
      "Train Loss: 0.06046063452959061\n",
      "Train Loss: 0.08077343553304672\n",
      "Train Loss: 0.03742159157991409\n",
      "Train Loss: 0.04757551848888397\n",
      "Train Loss: 0.19843052327632904\n",
      "Train Loss: 0.04174879565834999\n",
      "Train Loss: 0.03251536563038826\n",
      "Train Loss: 0.03997363522648811\n",
      "Train Loss: 0.05198109149932861\n",
      "Train Loss: 0.07309788465499878\n",
      "Train Loss: 0.06928294152021408\n",
      "Train Loss: 0.03195644170045853\n",
      "Train Loss: 0.04788423702120781\n",
      "Train Loss: 0.039633799344301224\n",
      "Train Loss: 0.06493082642555237\n",
      "Train Loss: 0.038698967546224594\n",
      "Train Loss: 0.11182095110416412\n",
      "Train Loss: 0.03358010947704315\n",
      "Train Loss: 0.04792429134249687\n",
      "Train Loss: 0.05005267634987831\n",
      "Train Loss: 0.08328139781951904\n",
      "Train Loss: 0.036766085773706436\n",
      "Train Loss: 0.04956329986453056\n",
      "Train Loss: 0.07879219949245453\n",
      "Train Loss: 0.06775966286659241\n",
      "Train Loss: 0.0346396267414093\n",
      "Train Loss: 0.05700746551156044\n",
      "Train Loss: 0.04951867833733559\n",
      "Train Loss: 0.04010719805955887\n",
      "Train Loss: 0.05825964733958244\n",
      "Train Loss: 0.05920001119375229\n",
      "Train Loss: 0.037888407707214355\n",
      "Train Loss: 0.0933464989066124\n",
      "Train Loss: 0.0580836720764637\n",
      "Train Loss: 0.05191982910037041\n",
      "Train Loss: 0.06542515009641647\n",
      "Train Loss: 0.08057061582803726\n",
      "Train Loss: 0.0333932563662529\n",
      "Train Loss: 0.055655915290117264\n",
      "Train Loss: 0.06819379329681396\n",
      "Train Loss: 0.20479726791381836\n",
      "Train Loss: 0.06438858807086945\n",
      "Train Loss: 0.05162467807531357\n",
      "Train Loss: 0.046116769313812256\n",
      "Train Loss: 0.057133328169584274\n",
      "Train Loss: 0.06618364155292511\n",
      "Train Loss: 0.1418892741203308\n",
      "Train Loss: 0.12159687280654907\n",
      "Train Loss: 0.07484120875597\n",
      "Train Loss: 0.040574442595243454\n",
      "Train Loss: 0.0743398442864418\n",
      "Train Loss: 0.06752991676330566\n",
      "Train Loss: 0.02873414382338524\n",
      "Train Loss: 0.03776907920837402\n",
      "Train Loss: 0.03868057206273079\n",
      "Train Loss: 0.04943591356277466\n",
      "Train Loss: 0.05470792576670647\n",
      "Train Loss: 0.039864372462034225\n",
      "Train Loss: 0.06329536437988281\n",
      "Train Loss: 0.04740948602557182\n",
      "Train Loss: 0.06299716979265213\n",
      "Train Loss: 0.06933623552322388\n",
      "Train Loss: 0.05697708949446678\n",
      "Train Loss: 0.05639830231666565\n",
      "Train Loss: 0.06083300709724426\n",
      "Train Loss: 0.03818931430578232\n",
      "Train Loss: 0.049620792269706726\n",
      "Train Loss: 0.033711113035678864\n",
      "Train Loss: 0.0479205921292305\n",
      "Train Loss: 0.05039919540286064\n",
      "Train Loss: 0.04963494464755058\n",
      "Train Loss: 0.051680803298950195\n",
      "Train Loss: 0.06790135055780411\n",
      "Train Loss: 0.06283117085695267\n",
      "Train Loss: 0.06376347690820694\n",
      "Train Loss: 0.05112781003117561\n",
      "Train Loss: 0.04440462216734886\n",
      "Train Loss: 0.051998887211084366\n",
      "Train Loss: 0.11608418077230453\n",
      "Train Loss: 0.050406794995069504\n",
      "Train Loss: 0.07113249599933624\n",
      "Train Loss: 0.05314405634999275\n",
      "Train Loss: 0.06957821547985077\n",
      "Train Loss: 0.04861324653029442\n",
      "Train Loss: 0.06060213968157768\n",
      "Train Loss: 0.06019037961959839\n",
      "Train Loss: 0.05075492709875107\n",
      "Train Loss: 0.08812955021858215\n",
      "Train Loss: 0.058610737323760986\n",
      "Train Loss: 0.032838866114616394\n",
      "Train Loss: 0.05425867810845375\n",
      "Train Loss: 0.06294891983270645\n",
      "Train Loss: 0.0485670268535614\n",
      "Train Loss: 0.06581158190965652\n",
      "Train Loss: 0.05928494781255722\n",
      "Train Loss: 0.0349397249519825\n",
      "Train Loss: 0.0652080625295639\n",
      "Train Loss: 0.03878409042954445\n",
      "Train Loss: 0.06427569687366486\n",
      "Train Loss: 0.03929360583424568\n",
      "Train Loss: 0.06432325392961502\n",
      "Train Loss: 0.28512752056121826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1278b656627340f99ef526eec21ac79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03821864724159241\n",
      "Validation Loss: 0.03574733808636665\n",
      "Validation Loss: 0.04070116952061653\n",
      "Validation Loss: 0.048635710030794144\n",
      "Validation Loss: 0.7867829203605652\n",
      "Validation Loss: 0.24781522154808044\n",
      "Validation Loss: 0.023702356964349747\n",
      "Validation Loss: 0.058613333851099014\n",
      "Validation Loss: 0.04465983435511589\n",
      "Validation Loss: 0.03776388615369797\n",
      "Validation Loss: 0.04406396672129631\n",
      "Validation Loss: 0.040617018938064575\n",
      "Validation Loss: 0.025209007784724236\n",
      "Validation Loss: 0.07464593648910522\n",
      "Validation Loss: 0.054255612194538116\n",
      "Validation Loss: 0.013999879360198975\n",
      "Validation Loss: 0.06430989503860474\n",
      "Validation Loss: 0.056209295988082886\n",
      "Validation Loss: 0.06062370166182518\n",
      "Validation Loss: 0.03204795718193054\n",
      "Validation Loss: 0.04059360921382904\n",
      "Validation Loss: 0.018940869718790054\n",
      "Validation Loss: 0.03144394978880882\n",
      "Validation Loss: 0.07743942737579346\n",
      "Validation Loss: 0.05494032800197601\n",
      "Validation Loss: 0.07671661674976349\n",
      "Validation Loss: 0.09370932728052139\n",
      "Validation Loss: 0.03531646355986595\n",
      "Validation Loss: 0.037220098078250885\n",
      "Validation Loss: 0.05993412435054779\n",
      "Validation Loss: 0.037567123770713806\n",
      "Validation Loss: 0.034751683473587036\n",
      "Validation Loss: 0.03367290645837784\n",
      "Validation Loss: 0.056689489632844925\n",
      "Train Loss: 0.07604549080133438\n",
      "Train Loss: 0.10959445685148239\n",
      "Train Loss: 0.04227261245250702\n",
      "Train Loss: 0.03720714524388313\n",
      "Train Loss: 0.04306304082274437\n",
      "Train Loss: 0.05405378341674805\n",
      "Train Loss: 0.034470293670892715\n",
      "Train Loss: 0.0385960228741169\n",
      "Train Loss: 0.0493180975317955\n",
      "Train Loss: 0.0454743467271328\n",
      "Train Loss: 0.08938495069742203\n",
      "Train Loss: 0.1592206358909607\n",
      "Train Loss: 0.03933451324701309\n",
      "Train Loss: 0.10301832854747772\n",
      "Train Loss: 0.06949374079704285\n",
      "Train Loss: 0.049125224351882935\n",
      "Train Loss: 0.042221903800964355\n",
      "Train Loss: 0.06342621892690659\n",
      "Train Loss: 0.05703211575746536\n",
      "Train Loss: 0.06371594965457916\n",
      "Train Loss: 0.09413514286279678\n",
      "Train Loss: 0.07014298439025879\n",
      "Train Loss: 0.07394595444202423\n",
      "Train Loss: 0.05326693877577782\n",
      "Train Loss: 0.05052730441093445\n",
      "Train Loss: 0.05378864333033562\n",
      "Train Loss: 0.03790125250816345\n",
      "Train Loss: 0.039029769599437714\n",
      "Train Loss: 0.039406973868608475\n",
      "Train Loss: 0.06891854107379913\n",
      "Train Loss: 0.09651406854391098\n",
      "Train Loss: 0.04709227755665779\n",
      "Train Loss: 0.02422332763671875\n",
      "Train Loss: 0.06054583564400673\n",
      "Train Loss: 0.06993069499731064\n",
      "Train Loss: 0.050404880195856094\n",
      "Train Loss: 0.07289143651723862\n",
      "Train Loss: 0.039171017706394196\n",
      "Train Loss: 0.06947153806686401\n",
      "Train Loss: 0.07658890634775162\n",
      "Train Loss: 0.0679125264286995\n",
      "Train Loss: 0.044796548783779144\n",
      "Train Loss: 0.09764736890792847\n",
      "Train Loss: 0.06011597812175751\n",
      "Train Loss: 0.03948328271508217\n",
      "Train Loss: 0.03384341672062874\n",
      "Train Loss: 0.04816664010286331\n",
      "Train Loss: 0.05685783550143242\n",
      "Train Loss: 0.067766472697258\n",
      "Train Loss: 0.05451353266835213\n",
      "Train Loss: 0.03340557962656021\n",
      "Train Loss: 0.07283937186002731\n",
      "Train Loss: 0.0443587526679039\n",
      "Train Loss: 0.06922390311956406\n",
      "Train Loss: 0.08375206589698792\n",
      "Train Loss: 0.03389718011021614\n",
      "Train Loss: 0.055906742811203\n",
      "Train Loss: 0.05277498438954353\n",
      "Train Loss: 0.0484425388276577\n",
      "Train Loss: 0.06528319418430328\n",
      "Train Loss: 0.06999282538890839\n",
      "Train Loss: 0.04256055876612663\n",
      "Train Loss: 0.06166749820113182\n",
      "Train Loss: 0.059924524277448654\n",
      "Train Loss: 0.03443516045808792\n",
      "Train Loss: 0.1667606383562088\n",
      "Train Loss: 0.03324614837765694\n",
      "Train Loss: 0.04904564097523689\n",
      "Train Loss: 0.16767144203186035\n",
      "Train Loss: 0.040333691984415054\n",
      "Train Loss: 0.04235386103391647\n",
      "Train Loss: 0.05885478854179382\n",
      "Train Loss: 0.055403731763362885\n",
      "Train Loss: 0.04215782508254051\n",
      "Train Loss: 0.07657203078269958\n",
      "Train Loss: 0.06997213512659073\n",
      "Train Loss: 0.06144271418452263\n",
      "Train Loss: 0.08426161855459213\n",
      "Train Loss: 0.08275547623634338\n",
      "Train Loss: 0.09279368072748184\n",
      "Train Loss: 0.20909321308135986\n",
      "Train Loss: 0.051457829773426056\n",
      "Train Loss: 0.06664035469293594\n",
      "Train Loss: 0.040741175413131714\n",
      "Train Loss: 0.03877292945981026\n",
      "Train Loss: 0.07187959551811218\n",
      "Train Loss: 0.040813956409692764\n",
      "Train Loss: 0.05102897807955742\n",
      "Train Loss: 0.04939400032162666\n",
      "Train Loss: 0.062097568064928055\n",
      "Train Loss: 0.042615458369255066\n",
      "Train Loss: 0.04052815958857536\n",
      "Train Loss: 0.028712984174489975\n",
      "Train Loss: 0.05060790106654167\n",
      "Train Loss: 0.0966540277004242\n",
      "Train Loss: 0.05849897116422653\n",
      "Train Loss: 0.07847562432289124\n",
      "Train Loss: 0.09935154765844345\n",
      "Train Loss: 0.08042758703231812\n",
      "Train Loss: 0.047747284173965454\n",
      "Train Loss: 0.07767239958047867\n",
      "Train Loss: 0.03676091507077217\n",
      "Train Loss: 0.1247878298163414\n",
      "Train Loss: 0.03920183330774307\n",
      "Train Loss: 0.05243851989507675\n",
      "Train Loss: 0.05706512928009033\n",
      "Train Loss: 0.060153644531965256\n",
      "Train Loss: 0.04607119411230087\n",
      "Train Loss: 0.0499340184032917\n",
      "Train Loss: 0.04222005605697632\n",
      "Train Loss: 0.043189164251089096\n",
      "Train Loss: 0.04220104217529297\n",
      "Train Loss: 0.054590675979852676\n",
      "Train Loss: 0.7524518966674805\n",
      "Train Loss: 0.04926026985049248\n",
      "Train Loss: 0.07492945343255997\n",
      "Train Loss: 0.04737266153097153\n",
      "Train Loss: 0.05874476954340935\n",
      "Train Loss: 0.06759116798639297\n",
      "Train Loss: 0.06386458873748779\n",
      "Train Loss: 0.05647076293826103\n",
      "Train Loss: 0.0361468531191349\n",
      "Train Loss: 0.05963025614619255\n",
      "Train Loss: 0.0651901513338089\n",
      "Train Loss: 2.247488021850586\n",
      "Train Loss: 0.06853403896093369\n",
      "Train Loss: 0.037818606942892075\n",
      "Train Loss: 0.04710773006081581\n",
      "Train Loss: 0.03734318166971207\n",
      "Train Loss: 0.09789206832647324\n",
      "Train Loss: 0.04849332198500633\n",
      "Train Loss: 0.06239264830946922\n",
      "Train Loss: 0.07251212745904922\n",
      "Train Loss: 0.09884730726480484\n",
      "Train Loss: 0.04662032797932625\n",
      "Train Loss: 0.05652960017323494\n",
      "Train Loss: 0.03535059094429016\n",
      "Train Loss: 0.07457272708415985\n",
      "Train Loss: 0.054809220135211945\n",
      "Train Loss: 0.04237440228462219\n",
      "Train Loss: 0.04222959652543068\n",
      "Train Loss: 0.05132834613323212\n",
      "Train Loss: 0.04088229686021805\n",
      "Train Loss: 0.0474630668759346\n",
      "Train Loss: 0.0455777645111084\n",
      "Train Loss: 0.07320596277713776\n",
      "Train Loss: 0.05624236539006233\n",
      "Train Loss: 0.10109732300043106\n",
      "Train Loss: 0.0365537665784359\n",
      "Train Loss: 0.05085432156920433\n",
      "Train Loss: 0.04310035705566406\n",
      "Train Loss: 0.07593242079019547\n",
      "Train Loss: 0.04055722430348396\n",
      "Train Loss: 0.03983763977885246\n",
      "Train Loss: 0.05828409641981125\n",
      "Train Loss: 0.07102371752262115\n",
      "Train Loss: 0.06376488506793976\n",
      "Train Loss: 0.044485073536634445\n",
      "Train Loss: 0.04928690940141678\n",
      "Train Loss: 0.0536562018096447\n",
      "Train Loss: 0.035031888633966446\n",
      "Train Loss: 0.06160486862063408\n",
      "Train Loss: 0.04701664298772812\n",
      "Train Loss: 0.05391974002122879\n",
      "Train Loss: 0.050621792674064636\n",
      "Train Loss: 0.053687434643507004\n",
      "Train Loss: 0.05080922320485115\n",
      "Train Loss: 0.042372096329927444\n",
      "Train Loss: 0.04098481684923172\n",
      "Train Loss: 0.07516386359930038\n",
      "Train Loss: 0.03756079822778702\n",
      "Train Loss: 0.05341794341802597\n",
      "Train Loss: 0.048621222376823425\n",
      "Train Loss: 0.03459947928786278\n",
      "Train Loss: 0.03322555869817734\n",
      "Train Loss: 0.04525947943329811\n",
      "Train Loss: 0.03425319120287895\n",
      "Train Loss: 0.06470233201980591\n",
      "Train Loss: 0.04449338838458061\n",
      "Train Loss: 0.08948715776205063\n",
      "Train Loss: 0.12778924405574799\n",
      "Train Loss: 0.060155387967824936\n",
      "Train Loss: 0.03817346692085266\n",
      "Train Loss: 0.053649622946977615\n",
      "Train Loss: 0.05236911028623581\n",
      "Train Loss: 0.0691225454211235\n",
      "Train Loss: 0.07064402848482132\n",
      "Train Loss: 0.03163517639040947\n",
      "Train Loss: 0.06870520114898682\n",
      "Train Loss: 0.04745393618941307\n",
      "Train Loss: 0.04000987485051155\n",
      "Train Loss: 0.07770103961229324\n",
      "Train Loss: 0.058735352009534836\n",
      "Train Loss: 0.14586718380451202\n",
      "Train Loss: 0.048697419464588165\n",
      "Train Loss: 0.09453798830509186\n",
      "Train Loss: 0.06320998072624207\n",
      "Train Loss: 0.06006905809044838\n",
      "Train Loss: 0.046739526093006134\n",
      "Train Loss: 0.0539228618144989\n",
      "Train Loss: 0.060116324573755264\n",
      "Train Loss: 0.03726837784051895\n",
      "Train Loss: 0.07545653730630875\n",
      "Train Loss: 0.06194692477583885\n",
      "Train Loss: 0.05888970568776131\n",
      "Train Loss: 0.07713031768798828\n",
      "Train Loss: 0.04021836444735527\n",
      "Train Loss: 0.057854291051626205\n",
      "Train Loss: 0.029450276866555214\n",
      "Train Loss: 0.12402939796447754\n",
      "Train Loss: 0.0332159623503685\n",
      "Train Loss: 0.05980224162340164\n",
      "Train Loss: 0.04965153709053993\n",
      "Train Loss: 0.06636015325784683\n",
      "Train Loss: 0.03465437516570091\n",
      "Train Loss: 0.08579493314027786\n",
      "Train Loss: 0.04902324080467224\n",
      "Train Loss: 0.07097270339727402\n",
      "Train Loss: 0.05376393347978592\n",
      "Train Loss: 0.047378282994031906\n",
      "Train Loss: 0.07154641300439835\n",
      "Train Loss: 0.06761665642261505\n",
      "Train Loss: 0.059473905712366104\n",
      "Train Loss: 0.052858393639326096\n",
      "Train Loss: 0.06476845592260361\n",
      "Train Loss: 0.044123757630586624\n",
      "Train Loss: 0.05190909653902054\n",
      "Train Loss: 0.06456129997968674\n",
      "Train Loss: 0.04757847636938095\n",
      "Train Loss: 0.045405805110931396\n",
      "Train Loss: 0.06475818157196045\n",
      "Train Loss: 0.05733819678425789\n",
      "Train Loss: 0.05801897868514061\n",
      "Train Loss: 0.07848130166530609\n",
      "Train Loss: 0.05507638305425644\n",
      "Train Loss: 0.04781332612037659\n",
      "Train Loss: 0.04804791882634163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9d7368498d44ce9df5af889026f11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04228680580854416\n",
      "Validation Loss: 0.03708082064986229\n",
      "Validation Loss: 0.033196598291397095\n",
      "Validation Loss: 0.04009220004081726\n",
      "Validation Loss: 0.8679198026657104\n",
      "Validation Loss: 0.22114865481853485\n",
      "Validation Loss: 0.026280419901013374\n",
      "Validation Loss: 0.059882521629333496\n",
      "Validation Loss: 0.049045462161302567\n",
      "Validation Loss: 0.03582313656806946\n",
      "Validation Loss: 0.04180973768234253\n",
      "Validation Loss: 0.04064171388745308\n",
      "Validation Loss: 0.02677653171122074\n",
      "Validation Loss: 0.07300896942615509\n",
      "Validation Loss: 0.05254632234573364\n",
      "Validation Loss: 0.009824707172811031\n",
      "Validation Loss: 0.05879414081573486\n",
      "Validation Loss: 0.05014509707689285\n",
      "Validation Loss: 0.05773548781871796\n",
      "Validation Loss: 0.03468971326947212\n",
      "Validation Loss: 0.036837849766016006\n",
      "Validation Loss: 0.015249591320753098\n",
      "Validation Loss: 0.028717517852783203\n",
      "Validation Loss: 0.07791753113269806\n",
      "Validation Loss: 0.05460395663976669\n",
      "Validation Loss: 0.07423630356788635\n",
      "Validation Loss: 0.0872630625963211\n",
      "Validation Loss: 0.03327519819140434\n",
      "Validation Loss: 0.03517904132604599\n",
      "Validation Loss: 0.05478444695472717\n",
      "Validation Loss: 0.034274667501449585\n",
      "Validation Loss: 0.03044629655778408\n",
      "Validation Loss: 0.03278800845146179\n",
      "Validation Loss: 0.05167552828788757\n",
      "Train Loss: 0.048865288496017456\n",
      "Train Loss: 2.1769821643829346\n",
      "Train Loss: 0.07785650342702866\n",
      "Train Loss: 0.047353409230709076\n",
      "Train Loss: 0.051533978432416916\n",
      "Train Loss: 0.06042829528450966\n",
      "Train Loss: 0.06213155761361122\n",
      "Train Loss: 0.10947680473327637\n",
      "Train Loss: 0.05487240478396416\n",
      "Train Loss: 0.054988961666822433\n",
      "Train Loss: 0.07717213779687881\n",
      "Train Loss: 0.05422418937087059\n",
      "Train Loss: 0.05271756276488304\n",
      "Train Loss: 0.10727345943450928\n",
      "Train Loss: 0.0706571713089943\n",
      "Train Loss: 0.07158300280570984\n",
      "Train Loss: 0.05192536115646362\n",
      "Train Loss: 0.072696752846241\n",
      "Train Loss: 0.07524508237838745\n",
      "Train Loss: 0.13583219051361084\n",
      "Train Loss: 0.05400371551513672\n",
      "Train Loss: 0.04113437607884407\n",
      "Train Loss: 0.08371161669492722\n",
      "Train Loss: 0.048324164003133774\n",
      "Train Loss: 0.11120676249265671\n",
      "Train Loss: 0.06276757270097733\n",
      "Train Loss: 0.04314257577061653\n",
      "Train Loss: 0.039805300533771515\n",
      "Train Loss: 0.06213178113102913\n",
      "Train Loss: 0.05202565714716911\n",
      "Train Loss: 0.048400867730379105\n",
      "Train Loss: 0.04868520423769951\n",
      "Train Loss: 0.07184290885925293\n",
      "Train Loss: 0.05262321978807449\n",
      "Train Loss: 0.06253697723150253\n",
      "Train Loss: 0.03852991387248039\n",
      "Train Loss: 0.043907295912504196\n",
      "Train Loss: 0.05301753059029579\n",
      "Train Loss: 0.05113287642598152\n",
      "Train Loss: 0.0415903702378273\n",
      "Train Loss: 0.0686759352684021\n",
      "Train Loss: 0.03838549554347992\n",
      "Train Loss: 0.07961490005254745\n",
      "Train Loss: 0.02651551365852356\n",
      "Train Loss: 0.04803554713726044\n",
      "Train Loss: 0.05143432319164276\n",
      "Train Loss: 0.045966487377882004\n",
      "Train Loss: 0.05101510137319565\n",
      "Train Loss: 0.04557791352272034\n",
      "Train Loss: 0.03817490488290787\n",
      "Train Loss: 0.04250949248671532\n",
      "Train Loss: 0.0739573985338211\n",
      "Train Loss: 0.07835247367620468\n",
      "Train Loss: 0.03744301572442055\n",
      "Train Loss: 0.06773007661104202\n",
      "Train Loss: 0.06047125533223152\n",
      "Train Loss: 0.04294739291071892\n",
      "Train Loss: 0.04202122613787651\n",
      "Train Loss: 0.045880112797021866\n",
      "Train Loss: 0.06389247626066208\n",
      "Train Loss: 0.04780590161681175\n",
      "Train Loss: 0.0434085987508297\n",
      "Train Loss: 0.04494073987007141\n",
      "Train Loss: 0.030984437093138695\n",
      "Train Loss: 0.041945599019527435\n",
      "Train Loss: 0.03921111300587654\n",
      "Train Loss: 0.07021894305944443\n",
      "Train Loss: 0.047936875373125076\n",
      "Train Loss: 0.05175575613975525\n",
      "Train Loss: 0.031105881556868553\n",
      "Train Loss: 0.06531764566898346\n",
      "Train Loss: 0.04726871848106384\n",
      "Train Loss: 0.04597661271691322\n",
      "Train Loss: 0.07084191590547562\n",
      "Train Loss: 0.054087381809949875\n",
      "Train Loss: 0.06487101316452026\n",
      "Train Loss: 0.06141534820199013\n",
      "Train Loss: 0.02818617783486843\n",
      "Train Loss: 0.04147550091147423\n",
      "Train Loss: 0.04029616713523865\n",
      "Train Loss: 0.028036266565322876\n",
      "Train Loss: 0.060613662004470825\n",
      "Train Loss: 0.03238911181688309\n",
      "Train Loss: 0.05294374004006386\n",
      "Train Loss: 0.05972161144018173\n",
      "Train Loss: 0.08319859951734543\n",
      "Train Loss: 0.08001744747161865\n",
      "Train Loss: 0.08051880449056625\n",
      "Train Loss: 0.06835498660802841\n",
      "Train Loss: 0.10087067633867264\n",
      "Train Loss: 0.05228716880083084\n",
      "Train Loss: 0.04875459522008896\n",
      "Train Loss: 0.061515696346759796\n",
      "Train Loss: 0.04482023045420647\n",
      "Train Loss: 0.07280723005533218\n",
      "Train Loss: 0.053810469806194305\n",
      "Train Loss: 0.03535988926887512\n",
      "Train Loss: 0.05704687163233757\n",
      "Train Loss: 0.04924312233924866\n",
      "Train Loss: 0.04585777595639229\n",
      "Train Loss: 0.06340017914772034\n",
      "Train Loss: 0.048136744648218155\n",
      "Train Loss: 0.07441587746143341\n",
      "Train Loss: 0.10785742849111557\n",
      "Train Loss: 0.07958816736936569\n",
      "Train Loss: 0.030889078974723816\n",
      "Train Loss: 0.05515209957957268\n",
      "Train Loss: 0.03179842233657837\n",
      "Train Loss: 0.04386915639042854\n",
      "Train Loss: 0.04611172154545784\n",
      "Train Loss: 0.11175428330898285\n",
      "Train Loss: 0.054091546684503555\n",
      "Train Loss: 0.04894259572029114\n",
      "Train Loss: 0.07333095371723175\n",
      "Train Loss: 0.06673280149698257\n",
      "Train Loss: 0.046761415898799896\n",
      "Train Loss: 0.036223430186510086\n",
      "Train Loss: 0.10073139518499374\n",
      "Train Loss: 0.0749361664056778\n",
      "Train Loss: 0.03614211827516556\n",
      "Train Loss: 0.03786006569862366\n",
      "Train Loss: 0.05252190679311752\n",
      "Train Loss: 0.10574381053447723\n",
      "Train Loss: 0.10924293845891953\n",
      "Train Loss: 0.030860761180520058\n",
      "Train Loss: 0.08835788071155548\n",
      "Train Loss: 0.06163511797785759\n",
      "Train Loss: 0.044989582151174545\n",
      "Train Loss: 0.0459890179336071\n",
      "Train Loss: 0.0466977059841156\n",
      "Train Loss: 0.0435660183429718\n",
      "Train Loss: 0.049733564257621765\n",
      "Train Loss: 0.03888345882296562\n",
      "Train Loss: 0.034372128546237946\n",
      "Train Loss: 0.04840170964598656\n",
      "Train Loss: 0.03671089559793472\n",
      "Train Loss: 0.038851384073495865\n",
      "Train Loss: 0.030194608494639397\n",
      "Train Loss: 0.07017779350280762\n",
      "Train Loss: 0.046564776450395584\n",
      "Train Loss: 0.07125769555568695\n",
      "Train Loss: 0.12084059417247772\n",
      "Train Loss: 0.04937604442238808\n",
      "Train Loss: 0.056844670325517654\n",
      "Train Loss: 0.07655564695596695\n",
      "Train Loss: 0.08405589312314987\n",
      "Train Loss: 0.053724680095911026\n",
      "Train Loss: 0.1324124038219452\n",
      "Train Loss: 0.06762103736400604\n",
      "Train Loss: 0.08816021680831909\n",
      "Train Loss: 0.036319442093372345\n",
      "Train Loss: 0.04026901721954346\n",
      "Train Loss: 0.03235745429992676\n",
      "Train Loss: 0.04956540837883949\n",
      "Train Loss: 0.04720164090394974\n",
      "Train Loss: 0.046032436192035675\n",
      "Train Loss: 0.12206369638442993\n",
      "Train Loss: 0.04499789699912071\n",
      "Train Loss: 0.03249738737940788\n",
      "Train Loss: 0.05559147521853447\n",
      "Train Loss: 0.06298797577619553\n",
      "Train Loss: 0.05892715975642204\n",
      "Train Loss: 0.03964421898126602\n",
      "Train Loss: 0.03923226147890091\n",
      "Train Loss: 0.05877076834440231\n",
      "Train Loss: 0.05333131551742554\n",
      "Train Loss: 0.04597203806042671\n",
      "Train Loss: 0.03220532089471817\n",
      "Train Loss: 0.06129952520132065\n",
      "Train Loss: 0.09651719778776169\n",
      "Train Loss: 0.03112494759261608\n",
      "Train Loss: 0.06596331298351288\n",
      "Train Loss: 0.05831971764564514\n",
      "Train Loss: 0.03370455279946327\n",
      "Train Loss: 0.0748603418469429\n",
      "Train Loss: 0.06690651178359985\n",
      "Train Loss: 0.12436329573392868\n",
      "Train Loss: 0.03918777033686638\n",
      "Train Loss: 0.058282434940338135\n",
      "Train Loss: 0.05039925128221512\n",
      "Train Loss: 0.05743942782282829\n",
      "Train Loss: 0.042371898889541626\n",
      "Train Loss: 0.06377904862165451\n",
      "Train Loss: 0.0931563526391983\n",
      "Train Loss: 0.07034258544445038\n",
      "Train Loss: 0.050181735306978226\n",
      "Train Loss: 0.07050730288028717\n",
      "Train Loss: 0.03848586976528168\n",
      "Train Loss: 0.06363091617822647\n",
      "Train Loss: 0.04585091769695282\n",
      "Train Loss: 0.07301042973995209\n",
      "Train Loss: 0.0356028787791729\n",
      "Train Loss: 0.045631859451532364\n",
      "Train Loss: 0.10004017502069473\n",
      "Train Loss: 0.02979394420981407\n",
      "Train Loss: 0.04264623299241066\n",
      "Train Loss: 0.03948293998837471\n",
      "Train Loss: 0.1724557876586914\n",
      "Train Loss: 0.04342850297689438\n",
      "Train Loss: 0.05037034675478935\n",
      "Train Loss: 0.048306845128536224\n",
      "Train Loss: 0.07921452820301056\n",
      "Train Loss: 0.05224232375621796\n",
      "Train Loss: 0.06354208290576935\n",
      "Train Loss: 0.041169796139001846\n",
      "Train Loss: 0.03429358825087547\n",
      "Train Loss: 0.03516155481338501\n",
      "Train Loss: 0.03258576989173889\n",
      "Train Loss: 0.046615928411483765\n",
      "Train Loss: 0.052537184208631516\n",
      "Train Loss: 0.055683862417936325\n",
      "Train Loss: 0.05170249193906784\n",
      "Train Loss: 0.05683957785367966\n",
      "Train Loss: 0.04204004257917404\n",
      "Train Loss: 0.0337478406727314\n",
      "Train Loss: 0.040436118841171265\n",
      "Train Loss: 0.055393677204847336\n",
      "Train Loss: 0.04041808843612671\n",
      "Train Loss: 0.05108381062746048\n",
      "Train Loss: 0.0632098913192749\n",
      "Train Loss: 0.7589591145515442\n",
      "Train Loss: 0.06370866298675537\n",
      "Train Loss: 0.11943008750677109\n",
      "Train Loss: 0.05316401645541191\n",
      "Train Loss: 0.06352686882019043\n",
      "Train Loss: 0.040337372571229935\n",
      "Train Loss: 0.06268060207366943\n",
      "Train Loss: 0.05602242425084114\n",
      "Train Loss: 0.07041256874799728\n",
      "Train Loss: 0.05891575291752815\n",
      "Train Loss: 0.07884357124567032\n",
      "Train Loss: 0.03642921522259712\n",
      "Train Loss: 0.054194092750549316\n",
      "Train Loss: 0.07340998202562332\n",
      "Train Loss: 0.053292177617549896\n",
      "Train Loss: 0.057347722351551056\n",
      "Train Loss: 0.04013216868042946\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97550cae28b949ce9a2c38baaf0132ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.04360643029212952\n",
      "Validation Loss: 0.03595510497689247\n",
      "Validation Loss: 0.032689377665519714\n",
      "Validation Loss: 0.039903074502944946\n",
      "Validation Loss: 0.9471080303192139\n",
      "Validation Loss: 0.20411166548728943\n",
      "Validation Loss: 0.023510584607720375\n",
      "Validation Loss: 0.0562797412276268\n",
      "Validation Loss: 0.04714236781001091\n",
      "Validation Loss: 0.038289207965135574\n",
      "Validation Loss: 0.04454934224486351\n",
      "Validation Loss: 0.04143042117357254\n",
      "Validation Loss: 0.02821512706577778\n",
      "Validation Loss: 0.07398096472024918\n",
      "Validation Loss: 0.05390091612935066\n",
      "Validation Loss: 0.01067133154720068\n",
      "Validation Loss: 0.05485280603170395\n",
      "Validation Loss: 0.05462808534502983\n",
      "Validation Loss: 0.06007550284266472\n",
      "Validation Loss: 0.03276687487959862\n",
      "Validation Loss: 0.043340105563402176\n",
      "Validation Loss: 0.018314629793167114\n",
      "Validation Loss: 0.028575584292411804\n",
      "Validation Loss: 0.06866616010665894\n",
      "Validation Loss: 0.05255376547574997\n",
      "Validation Loss: 0.07531397044658661\n",
      "Validation Loss: 0.09101863950490952\n",
      "Validation Loss: 0.039256397634744644\n",
      "Validation Loss: 0.04108871519565582\n",
      "Validation Loss: 0.05356520041823387\n",
      "Validation Loss: 0.04007967188954353\n",
      "Validation Loss: 0.03503119572997093\n",
      "Validation Loss: 0.03774018958210945\n",
      "Validation Loss: 0.06050918623805046\n",
      "Train Loss: 0.03786986693739891\n",
      "Train Loss: 0.05128716677427292\n",
      "Train Loss: 0.07128481566905975\n",
      "Train Loss: 0.04184531047940254\n",
      "Train Loss: 0.06269499659538269\n",
      "Train Loss: 0.05196481570601463\n",
      "Train Loss: 0.045746881514787674\n",
      "Train Loss: 0.06364434212446213\n",
      "Train Loss: 0.04208251088857651\n",
      "Train Loss: 0.03813892602920532\n",
      "Train Loss: 0.05120376870036125\n",
      "Train Loss: 0.038587786257267\n",
      "Train Loss: 0.08721887320280075\n",
      "Train Loss: 0.05317971110343933\n",
      "Train Loss: 0.07559327036142349\n",
      "Train Loss: 0.7190741896629333\n",
      "Train Loss: 0.06019009277224541\n",
      "Train Loss: 0.05189819261431694\n",
      "Train Loss: 0.045012976974248886\n",
      "Train Loss: 0.03931532800197601\n",
      "Train Loss: 0.07793102413415909\n",
      "Train Loss: 0.05381100997328758\n",
      "Train Loss: 0.05314651131629944\n",
      "Train Loss: 0.06675133854150772\n",
      "Train Loss: 0.053044017404317856\n",
      "Train Loss: 0.05053654685616493\n",
      "Train Loss: 0.039084527641534805\n",
      "Train Loss: 0.04676331207156181\n",
      "Train Loss: 0.058283742517232895\n",
      "Train Loss: 0.04610632732510567\n",
      "Train Loss: 0.036629077047109604\n",
      "Train Loss: 0.0424082987010479\n",
      "Train Loss: 0.06320561468601227\n",
      "Train Loss: 0.07038889080286026\n",
      "Train Loss: 0.07580862194299698\n",
      "Train Loss: 0.07286433130502701\n",
      "Train Loss: 0.0643417239189148\n",
      "Train Loss: 0.045556772500276566\n",
      "Train Loss: 0.06074066832661629\n",
      "Train Loss: 0.05639384314417839\n",
      "Train Loss: 0.08642100542783737\n",
      "Train Loss: 0.039601050317287445\n",
      "Train Loss: 0.07372648268938065\n",
      "Train Loss: 0.03298983350396156\n",
      "Train Loss: 0.05873790755867958\n",
      "Train Loss: 0.054500408470630646\n",
      "Train Loss: 0.04082753509283066\n",
      "Train Loss: 0.05538562312722206\n",
      "Train Loss: 0.04088215157389641\n",
      "Train Loss: 0.05274409055709839\n",
      "Train Loss: 0.05007140338420868\n",
      "Train Loss: 0.15613436698913574\n",
      "Train Loss: 0.050029825419187546\n",
      "Train Loss: 0.06467435508966446\n",
      "Train Loss: 0.14957749843597412\n",
      "Train Loss: 0.07410847395658493\n",
      "Train Loss: 0.044686149805784225\n",
      "Train Loss: 0.08110173791646957\n",
      "Train Loss: 0.08216625452041626\n",
      "Train Loss: 0.04290500283241272\n",
      "Train Loss: 0.1173984482884407\n",
      "Train Loss: 0.12643426656723022\n",
      "Train Loss: 0.09257637709379196\n",
      "Train Loss: 0.056511085480451584\n",
      "Train Loss: 0.05501443147659302\n",
      "Train Loss: 0.04833909124135971\n",
      "Train Loss: 0.2409249246120453\n",
      "Train Loss: 0.06522989273071289\n",
      "Train Loss: 0.08862944692373276\n",
      "Train Loss: 0.0511200986802578\n",
      "Train Loss: 0.05426982045173645\n",
      "Train Loss: 0.04269234463572502\n",
      "Train Loss: 0.05328458547592163\n",
      "Train Loss: 0.04679952189326286\n",
      "Train Loss: 0.09119242429733276\n",
      "Train Loss: 0.04643423482775688\n",
      "Train Loss: 0.06474506855010986\n",
      "Train Loss: 0.050301309674978256\n",
      "Train Loss: 0.036091651767492294\n",
      "Train Loss: 0.07679063081741333\n",
      "Train Loss: 0.04187052324414253\n",
      "Train Loss: 0.05678341165184975\n",
      "Train Loss: 0.05946967378258705\n",
      "Train Loss: 0.05727282539010048\n",
      "Train Loss: 0.07141242176294327\n",
      "Train Loss: 0.060690972954034805\n",
      "Train Loss: 0.06209617480635643\n",
      "Train Loss: 0.06064983457326889\n",
      "Train Loss: 0.05148832127451897\n",
      "Train Loss: 0.03764428570866585\n",
      "Train Loss: 0.04478989914059639\n",
      "Train Loss: 0.052410613745450974\n",
      "Train Loss: 0.07632753998041153\n",
      "Train Loss: 0.06039873883128166\n",
      "Train Loss: 0.0613219328224659\n",
      "Train Loss: 0.04691728949546814\n",
      "Train Loss: 0.052816860377788544\n",
      "Train Loss: 0.05705898627638817\n",
      "Train Loss: 0.0805368572473526\n",
      "Train Loss: 0.056077342480421066\n",
      "Train Loss: 0.04230909422039986\n",
      "Train Loss: 0.05297715589404106\n",
      "Train Loss: 0.06373181939125061\n",
      "Train Loss: 0.035180170089006424\n",
      "Train Loss: 0.05473417043685913\n",
      "Train Loss: 0.06359114497900009\n",
      "Train Loss: 0.09046654403209686\n",
      "Train Loss: 0.034230250865221024\n",
      "Train Loss: 0.04935317859053612\n",
      "Train Loss: 0.04000282287597656\n",
      "Train Loss: 0.07991094142198563\n",
      "Train Loss: 0.04362171143293381\n",
      "Train Loss: 0.04848921298980713\n",
      "Train Loss: 0.035921335220336914\n",
      "Train Loss: 0.07398450374603271\n",
      "Train Loss: 0.04759778827428818\n",
      "Train Loss: 0.08371124416589737\n",
      "Train Loss: 0.05149146169424057\n",
      "Train Loss: 0.05600135028362274\n",
      "Train Loss: 0.05631830543279648\n",
      "Train Loss: 0.07470721751451492\n",
      "Train Loss: 0.04182786867022514\n",
      "Train Loss: 0.04758286476135254\n",
      "Train Loss: 0.03815535455942154\n",
      "Train Loss: 0.029492048546671867\n",
      "Train Loss: 0.044045161455869675\n",
      "Train Loss: 0.06074233725667\n",
      "Train Loss: 0.06240805238485336\n",
      "Train Loss: 0.03509625047445297\n",
      "Train Loss: 0.03396822139620781\n",
      "Train Loss: 0.03424898162484169\n",
      "Train Loss: 0.03375522047281265\n",
      "Train Loss: 0.06238441914319992\n",
      "Train Loss: 0.06500779837369919\n",
      "Train Loss: 0.041608650237321854\n",
      "Train Loss: 0.054620202630758286\n",
      "Train Loss: 0.04744343087077141\n",
      "Train Loss: 0.053423553705215454\n",
      "Train Loss: 0.046385642141103745\n",
      "Train Loss: 0.041769299656152725\n",
      "Train Loss: 0.05992669612169266\n",
      "Train Loss: 0.044953085482120514\n",
      "Train Loss: 0.060834985226392746\n",
      "Train Loss: 0.05912545695900917\n",
      "Train Loss: 0.027902303263545036\n",
      "Train Loss: 0.07182544469833374\n",
      "Train Loss: 0.04987458512187004\n",
      "Train Loss: 0.054731328040361404\n",
      "Train Loss: 0.044399797916412354\n",
      "Train Loss: 0.04196816682815552\n",
      "Train Loss: 0.06269912421703339\n",
      "Train Loss: 0.04200361669063568\n",
      "Train Loss: 0.04104667529463768\n",
      "Train Loss: 0.05565410107374191\n",
      "Train Loss: 0.036653921008110046\n",
      "Train Loss: 0.06170524284243584\n",
      "Train Loss: 0.0628475695848465\n",
      "Train Loss: 0.0491798110306263\n",
      "Train Loss: 0.06392598897218704\n",
      "Train Loss: 0.03213910013437271\n",
      "Train Loss: 0.03546702861785889\n",
      "Train Loss: 0.033146779984235764\n",
      "Train Loss: 0.06636364758014679\n",
      "Train Loss: 0.031950563192367554\n",
      "Train Loss: 0.0452306903898716\n",
      "Train Loss: 0.06509564071893692\n",
      "Train Loss: 0.060676753520965576\n",
      "Train Loss: 0.04095390811562538\n",
      "Train Loss: 0.05193222314119339\n",
      "Train Loss: 0.05335032567381859\n",
      "Train Loss: 0.031513188034296036\n",
      "Train Loss: 0.05007971450686455\n",
      "Train Loss: 0.047917746007442474\n",
      "Train Loss: 0.05582208186388016\n",
      "Train Loss: 0.1406819224357605\n",
      "Train Loss: 0.07136555016040802\n",
      "Train Loss: 0.1467653065919876\n",
      "Train Loss: 0.07639362663030624\n",
      "Train Loss: 0.05929344519972801\n",
      "Train Loss: 0.056960999965667725\n",
      "Train Loss: 0.09925267845392227\n",
      "Train Loss: 2.1967289447784424\n",
      "Train Loss: 0.07526932656764984\n",
      "Train Loss: 0.1259925216436386\n",
      "Train Loss: 0.06153324618935585\n",
      "Train Loss: 0.07146689295768738\n",
      "Train Loss: 0.09332463890314102\n",
      "Train Loss: 0.05892382562160492\n",
      "Train Loss: 0.05589072033762932\n",
      "Train Loss: 0.06456977874040604\n",
      "Train Loss: 0.06447722017765045\n",
      "Train Loss: 0.0840684249997139\n",
      "Train Loss: 0.05608324706554413\n",
      "Train Loss: 0.07600036263465881\n",
      "Train Loss: 0.060203056782484055\n",
      "Train Loss: 0.05974646657705307\n",
      "Train Loss: 0.0767379179596901\n",
      "Train Loss: 0.04931511729955673\n",
      "Train Loss: 0.07274824380874634\n",
      "Train Loss: 0.036278724670410156\n",
      "Train Loss: 0.049779556691646576\n",
      "Train Loss: 0.06377697736024857\n",
      "Train Loss: 0.05441349372267723\n",
      "Train Loss: 0.05040609464049339\n",
      "Train Loss: 0.06317804008722305\n",
      "Train Loss: 0.06061731278896332\n",
      "Train Loss: 0.04661009833216667\n",
      "Train Loss: 0.05190667510032654\n",
      "Train Loss: 0.04829864576458931\n",
      "Train Loss: 0.038460634648799896\n",
      "Train Loss: 0.03504369407892227\n",
      "Train Loss: 0.04046294093132019\n",
      "Train Loss: 0.031466685235500336\n",
      "Train Loss: 0.043394993990659714\n",
      "Train Loss: 0.04304789751768112\n",
      "Train Loss: 0.12248440831899643\n",
      "Train Loss: 0.0740024596452713\n",
      "Train Loss: 0.06690964847803116\n",
      "Train Loss: 0.05378677695989609\n",
      "Train Loss: 0.048502154648303986\n",
      "Train Loss: 0.04479476809501648\n",
      "Train Loss: 0.05712346360087395\n",
      "Train Loss: 0.07261312752962112\n",
      "Train Loss: 0.030641714110970497\n",
      "Train Loss: 0.03711812198162079\n",
      "Train Loss: 0.08497098088264465\n",
      "Train Loss: 0.048976004123687744\n",
      "Train Loss: 0.053044818341732025\n",
      "Train Loss: 0.05142861232161522\n",
      "Train Loss: 0.043229084461927414\n",
      "Train Loss: 0.05726628750562668\n",
      "Train Loss: 0.04794466122984886\n",
      "Train Loss: 0.08330721408128738\n",
      "Train Loss: 0.043515659868717194\n",
      "Train Loss: 0.030751017853617668\n",
      "Train Loss: 0.04506191611289978\n",
      "Train Loss: 0.06903894245624542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f256731cce442789c9674cb67f2ddb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03868246451020241\n",
      "Validation Loss: 0.03889436274766922\n",
      "Validation Loss: 0.03487514331936836\n",
      "Validation Loss: 0.0417415127158165\n",
      "Validation Loss: 1.316960334777832\n",
      "Validation Loss: 0.1845761239528656\n",
      "Validation Loss: 0.026303734630346298\n",
      "Validation Loss: 0.05861997604370117\n",
      "Validation Loss: 0.045564647763967514\n",
      "Validation Loss: 0.0397774837911129\n",
      "Validation Loss: 0.04619751498103142\n",
      "Validation Loss: 0.042679041624069214\n",
      "Validation Loss: 0.030717303976416588\n",
      "Validation Loss: 0.07233599573373795\n",
      "Validation Loss: 0.05566117540001869\n",
      "Validation Loss: 0.014988867565989494\n",
      "Validation Loss: 0.05795915797352791\n",
      "Validation Loss: 0.05099533125758171\n",
      "Validation Loss: 0.05922095477581024\n",
      "Validation Loss: 0.03188677877187729\n",
      "Validation Loss: 0.04628258943557739\n",
      "Validation Loss: 0.018735356628894806\n",
      "Validation Loss: 0.03197089210152626\n",
      "Validation Loss: 0.07469312101602554\n",
      "Validation Loss: 0.052722521126270294\n",
      "Validation Loss: 0.07875111699104309\n",
      "Validation Loss: 0.09162483364343643\n",
      "Validation Loss: 0.0429445318877697\n",
      "Validation Loss: 0.041742682456970215\n",
      "Validation Loss: 0.05839364975690842\n",
      "Validation Loss: 0.04417920112609863\n",
      "Validation Loss: 0.04099081829190254\n",
      "Validation Loss: 0.04239910468459129\n",
      "Validation Loss: 0.06636690348386765\n",
      "Train Loss: 0.04213200509548187\n",
      "Train Loss: 0.042642779648303986\n",
      "Train Loss: 0.041795480996370316\n",
      "Train Loss: 0.06284204870462418\n",
      "Train Loss: 2.132338762283325\n",
      "Train Loss: 0.07412096858024597\n",
      "Train Loss: 0.04513256624341011\n",
      "Train Loss: 0.052925556898117065\n",
      "Train Loss: 0.05261543393135071\n",
      "Train Loss: 0.07022371888160706\n",
      "Train Loss: 0.05349902808666229\n",
      "Train Loss: 0.04517831653356552\n",
      "Train Loss: 0.06912361085414886\n",
      "Train Loss: 0.03857376053929329\n",
      "Train Loss: 0.06924758106470108\n",
      "Train Loss: 0.0527767650783062\n",
      "Train Loss: 0.05293114855885506\n",
      "Train Loss: 0.03463262319564819\n",
      "Train Loss: 0.04516228288412094\n",
      "Train Loss: 0.09048932790756226\n",
      "Train Loss: 0.07230585813522339\n",
      "Train Loss: 0.047673214226961136\n",
      "Train Loss: 0.11758429557085037\n",
      "Train Loss: 0.07574078440666199\n",
      "Train Loss: 0.039094701409339905\n",
      "Train Loss: 0.03852775692939758\n",
      "Train Loss: 0.03974787890911102\n",
      "Train Loss: 0.058678559958934784\n",
      "Train Loss: 0.06649716198444366\n",
      "Train Loss: 0.04285275563597679\n",
      "Train Loss: 0.07200244069099426\n",
      "Train Loss: 0.04212377965450287\n",
      "Train Loss: 0.038808077573776245\n",
      "Train Loss: 0.03446819260716438\n",
      "Train Loss: 0.07204946875572205\n",
      "Train Loss: 0.03540067747235298\n",
      "Train Loss: 0.04453413560986519\n",
      "Train Loss: 0.0526721216738224\n",
      "Train Loss: 0.03901764005422592\n",
      "Train Loss: 0.04262136295437813\n",
      "Train Loss: 0.05475956201553345\n",
      "Train Loss: 0.037305187433958054\n",
      "Train Loss: 0.04862603917717934\n",
      "Train Loss: 0.03471590206027031\n",
      "Train Loss: 0.07176101952791214\n",
      "Train Loss: 0.08061597496271133\n",
      "Train Loss: 0.0458475761115551\n",
      "Train Loss: 0.05579626187682152\n",
      "Train Loss: 0.04298580437898636\n",
      "Train Loss: 0.04140106588602066\n",
      "Train Loss: 0.030761977657675743\n",
      "Train Loss: 0.04029547795653343\n",
      "Train Loss: 0.03465542197227478\n",
      "Train Loss: 0.7250065207481384\n",
      "Train Loss: 0.0428733266890049\n",
      "Train Loss: 0.043506305664777756\n",
      "Train Loss: 0.09725058078765869\n",
      "Train Loss: 0.037977803498506546\n",
      "Train Loss: 0.07789383083581924\n",
      "Train Loss: 0.0713634267449379\n",
      "Train Loss: 0.04768449813127518\n",
      "Train Loss: 0.04329625889658928\n",
      "Train Loss: 0.04011508822441101\n",
      "Train Loss: 0.05550708621740341\n",
      "Train Loss: 0.052331507205963135\n",
      "Train Loss: 0.04126856476068497\n",
      "Train Loss: 0.058701109141111374\n",
      "Train Loss: 0.11623363196849823\n",
      "Train Loss: 0.03913194686174393\n",
      "Train Loss: 0.08757321536540985\n",
      "Train Loss: 0.03851775452494621\n",
      "Train Loss: 0.06962616741657257\n",
      "Train Loss: 0.05630000680685043\n",
      "Train Loss: 0.05336436629295349\n",
      "Train Loss: 0.06151726096868515\n",
      "Train Loss: 0.04623495414853096\n",
      "Train Loss: 0.044481679797172546\n",
      "Train Loss: 0.145930677652359\n",
      "Train Loss: 0.04827495291829109\n",
      "Train Loss: 0.043641697615385056\n",
      "Train Loss: 0.03192305937409401\n",
      "Train Loss: 0.055057916790246964\n",
      "Train Loss: 0.08831868320703506\n",
      "Train Loss: 0.07190509140491486\n",
      "Train Loss: 0.07459435611963272\n",
      "Train Loss: 0.08456424623727798\n",
      "Train Loss: 0.03397025540471077\n",
      "Train Loss: 0.05538146197795868\n",
      "Train Loss: 0.058108244091272354\n",
      "Train Loss: 0.0484912283718586\n",
      "Train Loss: 0.050310395658016205\n",
      "Train Loss: 0.06952928751707077\n",
      "Train Loss: 0.06323565542697906\n",
      "Train Loss: 0.0534827783703804\n",
      "Train Loss: 0.04274216666817665\n",
      "Train Loss: 0.0362674854695797\n",
      "Train Loss: 0.051994919776916504\n",
      "Train Loss: 0.061291154474020004\n",
      "Train Loss: 0.04149241000413895\n",
      "Train Loss: 0.06325139105319977\n",
      "Train Loss: 0.07106635719537735\n",
      "Train Loss: 0.0775592178106308\n",
      "Train Loss: 0.042142104357481\n",
      "Train Loss: 0.05835545063018799\n",
      "Train Loss: 0.08398977667093277\n",
      "Train Loss: 0.0508609302341938\n",
      "Train Loss: 0.04088955745100975\n",
      "Train Loss: 0.0861823782324791\n",
      "Train Loss: 0.04936053603887558\n",
      "Train Loss: 0.06543561816215515\n",
      "Train Loss: 0.0529521219432354\n",
      "Train Loss: 0.07606123387813568\n",
      "Train Loss: 0.052369922399520874\n",
      "Train Loss: 0.046625155955553055\n",
      "Train Loss: 0.02605815976858139\n",
      "Train Loss: 0.0667407214641571\n",
      "Train Loss: 0.11422313749790192\n",
      "Train Loss: 0.043970346450805664\n",
      "Train Loss: 0.03793609142303467\n",
      "Train Loss: 0.029848651960492134\n",
      "Train Loss: 0.08680566400289536\n",
      "Train Loss: 0.08222988247871399\n",
      "Train Loss: 0.03894547373056412\n",
      "Train Loss: 0.05945596098899841\n",
      "Train Loss: 0.03395440801978111\n",
      "Train Loss: 0.04697241261601448\n",
      "Train Loss: 0.038770586252212524\n",
      "Train Loss: 0.05176994204521179\n",
      "Train Loss: 0.07190689444541931\n",
      "Train Loss: 0.04715600982308388\n",
      "Train Loss: 0.05391506850719452\n",
      "Train Loss: 0.032161518931388855\n",
      "Train Loss: 0.09703261405229568\n",
      "Train Loss: 0.05961501598358154\n",
      "Train Loss: 0.028967002406716347\n",
      "Train Loss: 0.04563814029097557\n",
      "Train Loss: 0.04416404291987419\n",
      "Train Loss: 0.035687919706106186\n",
      "Train Loss: 0.04752173274755478\n",
      "Train Loss: 0.04258626699447632\n",
      "Train Loss: 0.08605823665857315\n",
      "Train Loss: 0.09382571280002594\n",
      "Train Loss: 0.05458412691950798\n",
      "Train Loss: 0.05312846601009369\n",
      "Train Loss: 0.055096980184316635\n",
      "Train Loss: 0.06811921298503876\n",
      "Train Loss: 0.04646804928779602\n",
      "Train Loss: 0.06781801581382751\n",
      "Train Loss: 0.0763443261384964\n",
      "Train Loss: 0.07344866544008255\n",
      "Train Loss: 0.04211917892098427\n",
      "Train Loss: 0.08266279101371765\n",
      "Train Loss: 0.041676297783851624\n",
      "Train Loss: 0.055231973528862\n",
      "Train Loss: 0.0582379549741745\n",
      "Train Loss: 0.044920261949300766\n",
      "Train Loss: 0.06077428534626961\n",
      "Train Loss: 0.061708949506282806\n",
      "Train Loss: 0.06536515057086945\n",
      "Train Loss: 0.03520625829696655\n",
      "Train Loss: 0.05028789862990379\n",
      "Train Loss: 0.06951967626810074\n",
      "Train Loss: 0.04554164037108421\n",
      "Train Loss: 0.07050494104623795\n",
      "Train Loss: 0.07931787520647049\n",
      "Train Loss: 0.04140172898769379\n",
      "Train Loss: 0.03559305518865585\n",
      "Train Loss: 0.06079704314470291\n",
      "Train Loss: 0.06945467740297318\n",
      "Train Loss: 0.03872986510396004\n",
      "Train Loss: 0.04112384095788002\n",
      "Train Loss: 0.051106926053762436\n",
      "Train Loss: 0.04098857566714287\n",
      "Train Loss: 0.03453924134373665\n",
      "Train Loss: 0.06544093042612076\n",
      "Train Loss: 0.06696251779794693\n",
      "Train Loss: 0.04417291283607483\n",
      "Train Loss: 0.043540965765714645\n",
      "Train Loss: 0.08562026172876358\n",
      "Train Loss: 0.043801698833703995\n",
      "Train Loss: 0.05793141573667526\n",
      "Train Loss: 0.0596308708190918\n",
      "Train Loss: 0.03583486005663872\n",
      "Train Loss: 0.03268855810165405\n",
      "Train Loss: 0.03676547482609749\n",
      "Train Loss: 0.04630089923739433\n",
      "Train Loss: 0.06419384479522705\n",
      "Train Loss: 0.1570073366165161\n",
      "Train Loss: 0.053017910569906235\n",
      "Train Loss: 0.03460725024342537\n",
      "Train Loss: 0.07239186763763428\n",
      "Train Loss: 0.10707832872867584\n",
      "Train Loss: 0.0505889467895031\n",
      "Train Loss: 0.0914875715970993\n",
      "Train Loss: 0.08096400648355484\n",
      "Train Loss: 0.041679903864860535\n",
      "Train Loss: 0.04425768181681633\n",
      "Train Loss: 0.03622635453939438\n",
      "Train Loss: 0.05869558826088905\n",
      "Train Loss: 0.04857063293457031\n",
      "Train Loss: 0.043620821088552475\n",
      "Train Loss: 0.035708338022232056\n",
      "Train Loss: 0.030893711373209953\n",
      "Train Loss: 0.05155402049422264\n",
      "Train Loss: 0.060008127242326736\n",
      "Train Loss: 0.042008865624666214\n",
      "Train Loss: 0.03763711452484131\n",
      "Train Loss: 0.04124872758984566\n",
      "Train Loss: 0.09486226737499237\n",
      "Train Loss: 0.04393164440989494\n",
      "Train Loss: 0.048428039997816086\n",
      "Train Loss: 0.0870635136961937\n",
      "Train Loss: 0.0727376937866211\n",
      "Train Loss: 0.026288509368896484\n",
      "Train Loss: 0.0416891872882843\n",
      "Train Loss: 0.05608299747109413\n",
      "Train Loss: 0.05198981240391731\n",
      "Train Loss: 0.0450889989733696\n",
      "Train Loss: 0.032978031784296036\n",
      "Train Loss: 0.03542587533593178\n",
      "Train Loss: 0.05003757402300835\n",
      "Train Loss: 0.053133588284254074\n",
      "Train Loss: 0.06284568458795547\n",
      "Train Loss: 0.04579990729689598\n",
      "Train Loss: 0.07047069072723389\n",
      "Train Loss: 0.030236540362238884\n",
      "Train Loss: 0.02922758460044861\n",
      "Train Loss: 0.07547543197870255\n",
      "Train Loss: 0.05322593078017235\n",
      "Train Loss: 0.04153619334101677\n",
      "Train Loss: 0.06024212762713432\n",
      "Train Loss: 0.05875679850578308\n",
      "Train Loss: 0.08172032982110977\n",
      "Train Loss: 0.08802084624767303\n",
      "Train Loss: 0.03373605012893677\n",
      "Train Loss: 0.054027244448661804\n",
      "Train Loss: 0.026478638872504234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8191b2dd0a3848e8b5772bcd9dfe0492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.042626846581697464\n",
      "Validation Loss: 0.0372769832611084\n",
      "Validation Loss: 0.036934994161129\n",
      "Validation Loss: 0.040512245148420334\n",
      "Validation Loss: 0.9252106547355652\n",
      "Validation Loss: 0.24132928252220154\n",
      "Validation Loss: 0.023393135517835617\n",
      "Validation Loss: 0.0568416453897953\n",
      "Validation Loss: 0.051703471690416336\n",
      "Validation Loss: 0.035793889313936234\n",
      "Validation Loss: 0.03956666216254234\n",
      "Validation Loss: 0.04370443895459175\n",
      "Validation Loss: 0.027004925534129143\n",
      "Validation Loss: 0.07404160499572754\n",
      "Validation Loss: 0.0574527233839035\n",
      "Validation Loss: 0.011798188090324402\n",
      "Validation Loss: 0.0629136711359024\n",
      "Validation Loss: 0.04898769408464432\n",
      "Validation Loss: 0.058582957834005356\n",
      "Validation Loss: 0.03425402194261551\n",
      "Validation Loss: 0.04160919785499573\n",
      "Validation Loss: 0.01645669713616371\n",
      "Validation Loss: 0.03014717437326908\n",
      "Validation Loss: 0.07554874569177628\n",
      "Validation Loss: 0.057521529495716095\n",
      "Validation Loss: 0.0746418908238411\n",
      "Validation Loss: 0.08991692215204239\n",
      "Validation Loss: 0.03297983482480049\n",
      "Validation Loss: 0.037496987730264664\n",
      "Validation Loss: 0.054777007550001144\n",
      "Validation Loss: 0.038319945335388184\n",
      "Validation Loss: 0.03523325175046921\n",
      "Validation Loss: 0.032409749925136566\n",
      "Validation Loss: 0.05415574833750725\n",
      "Train Loss: 0.065489761531353\n",
      "Train Loss: 0.037817567586898804\n",
      "Train Loss: 0.041368331760168076\n",
      "Train Loss: 0.03337765857577324\n",
      "Train Loss: 0.09212538599967957\n",
      "Train Loss: 0.03922457993030548\n",
      "Train Loss: 0.060272715985774994\n",
      "Train Loss: 0.050800204277038574\n",
      "Train Loss: 0.05260821431875229\n",
      "Train Loss: 0.05379186198115349\n",
      "Train Loss: 0.0611313171684742\n",
      "Train Loss: 0.02769068442285061\n",
      "Train Loss: 0.0495142824947834\n",
      "Train Loss: 0.0411638580262661\n",
      "Train Loss: 0.04908601567149162\n",
      "Train Loss: 0.03754657134413719\n",
      "Train Loss: 0.09435521811246872\n",
      "Train Loss: 0.042938049882650375\n",
      "Train Loss: 0.04205494001507759\n",
      "Train Loss: 0.02971266768872738\n",
      "Train Loss: 0.05202670022845268\n",
      "Train Loss: 0.02703634835779667\n",
      "Train Loss: 0.05593977868556976\n",
      "Train Loss: 0.05662554129958153\n",
      "Train Loss: 0.048524122685194016\n",
      "Train Loss: 0.07001356780529022\n",
      "Train Loss: 0.0403287410736084\n",
      "Train Loss: 0.052721619606018066\n",
      "Train Loss: 0.060581859201192856\n",
      "Train Loss: 0.0581667497754097\n",
      "Train Loss: 0.03392472490668297\n",
      "Train Loss: 0.030541714280843735\n",
      "Train Loss: 0.05093791335821152\n",
      "Train Loss: 0.031119374558329582\n",
      "Train Loss: 0.06380251795053482\n",
      "Train Loss: 0.045723818242549896\n",
      "Train Loss: 0.05564876273274422\n",
      "Train Loss: 0.19836457073688507\n",
      "Train Loss: 0.04962021857500076\n",
      "Train Loss: 0.05865871161222458\n",
      "Train Loss: 0.05280807986855507\n",
      "Train Loss: 0.048004455864429474\n",
      "Train Loss: 0.050195395946502686\n",
      "Train Loss: 0.08847516030073166\n",
      "Train Loss: 0.032965488731861115\n",
      "Train Loss: 0.05002688243985176\n",
      "Train Loss: 0.06571842730045319\n",
      "Train Loss: 0.03560848906636238\n",
      "Train Loss: 0.041956692934036255\n",
      "Train Loss: 0.04646492749452591\n",
      "Train Loss: 0.033953625708818436\n",
      "Train Loss: 0.06063447520136833\n",
      "Train Loss: 0.057305436581373215\n",
      "Train Loss: 0.0342007577419281\n",
      "Train Loss: 0.041215915232896805\n",
      "Train Loss: 0.0620366670191288\n",
      "Train Loss: 0.04775660112500191\n",
      "Train Loss: 0.06680740416049957\n",
      "Train Loss: 0.04401002824306488\n",
      "Train Loss: 0.06163613498210907\n",
      "Train Loss: 0.041249070316553116\n",
      "Train Loss: 0.06554016470909119\n",
      "Train Loss: 0.0399913415312767\n",
      "Train Loss: 0.04804137721657753\n",
      "Train Loss: 0.06683775782585144\n",
      "Train Loss: 0.03670750930905342\n",
      "Train Loss: 0.0478883795440197\n",
      "Train Loss: 0.051302701234817505\n",
      "Train Loss: 0.046264540404081345\n",
      "Train Loss: 0.07356876134872437\n",
      "Train Loss: 0.036035824567079544\n",
      "Train Loss: 0.03410426154732704\n",
      "Train Loss: 0.055105388164520264\n",
      "Train Loss: 0.03376409411430359\n",
      "Train Loss: 0.07472638785839081\n",
      "Train Loss: 0.06514017283916473\n",
      "Train Loss: 0.04061374440789223\n",
      "Train Loss: 0.04506046324968338\n",
      "Train Loss: 0.05875031650066376\n",
      "Train Loss: 0.04140769690275192\n",
      "Train Loss: 0.06429379433393478\n",
      "Train Loss: 0.04913780093193054\n",
      "Train Loss: 0.09140543639659882\n",
      "Train Loss: 0.043376270681619644\n",
      "Train Loss: 0.06639198213815689\n",
      "Train Loss: 0.04235442727804184\n",
      "Train Loss: 0.06805950403213501\n",
      "Train Loss: 0.04039416089653969\n",
      "Train Loss: 0.10835384577512741\n",
      "Train Loss: 0.09659721702337265\n",
      "Train Loss: 0.04635748267173767\n",
      "Train Loss: 0.08190108835697174\n",
      "Train Loss: 0.03955624997615814\n",
      "Train Loss: 0.07447704672813416\n",
      "Train Loss: 0.060882218182086945\n",
      "Train Loss: 0.05463279038667679\n",
      "Train Loss: 0.033644553273916245\n",
      "Train Loss: 0.04688166454434395\n",
      "Train Loss: 0.040001410990953445\n",
      "Train Loss: 0.028485694900155067\n",
      "Train Loss: 0.033187031745910645\n",
      "Train Loss: 0.03869202733039856\n",
      "Train Loss: 0.07394847273826599\n",
      "Train Loss: 0.03248777240514755\n",
      "Train Loss: 0.04403861612081528\n",
      "Train Loss: 0.038616497069597244\n",
      "Train Loss: 0.036487169563770294\n",
      "Train Loss: 0.04219886660575867\n",
      "Train Loss: 0.03277622535824776\n",
      "Train Loss: 0.06303457915782928\n",
      "Train Loss: 0.05252267047762871\n",
      "Train Loss: 0.04566624015569687\n",
      "Train Loss: 2.095170497894287\n",
      "Train Loss: 0.045863326638936996\n",
      "Train Loss: 0.05263986438512802\n",
      "Train Loss: 0.05228151008486748\n",
      "Train Loss: 0.038180816918611526\n",
      "Train Loss: 0.08434344828128815\n",
      "Train Loss: 0.044263530522584915\n",
      "Train Loss: 0.07460970431566238\n",
      "Train Loss: 0.05483338236808777\n",
      "Train Loss: 0.051831573247909546\n",
      "Train Loss: 0.05096445977687836\n",
      "Train Loss: 0.05063801631331444\n",
      "Train Loss: 0.05766559764742851\n",
      "Train Loss: 0.045191798359155655\n",
      "Train Loss: 0.12470759451389313\n",
      "Train Loss: 0.052638888359069824\n",
      "Train Loss: 0.06521055847406387\n",
      "Train Loss: 0.0644131451845169\n",
      "Train Loss: 0.0686684176325798\n",
      "Train Loss: 0.04058908671140671\n",
      "Train Loss: 0.054076049476861954\n",
      "Train Loss: 0.03963460028171539\n",
      "Train Loss: 0.05692987143993378\n",
      "Train Loss: 0.042178064584732056\n",
      "Train Loss: 0.0489383190870285\n",
      "Train Loss: 0.0815647542476654\n",
      "Train Loss: 0.03186720237135887\n",
      "Train Loss: 0.03997832536697388\n",
      "Train Loss: 0.035522427409887314\n",
      "Train Loss: 0.07235870510339737\n",
      "Train Loss: 0.04125450924038887\n",
      "Train Loss: 0.05212777107954025\n",
      "Train Loss: 0.0522284097969532\n",
      "Train Loss: 0.03806401044130325\n",
      "Train Loss: 0.030269619077444077\n",
      "Train Loss: 0.08013448119163513\n",
      "Train Loss: 0.04918986186385155\n",
      "Train Loss: 0.05866151303052902\n",
      "Train Loss: 0.04651219770312309\n",
      "Train Loss: 0.061124369502067566\n",
      "Train Loss: 0.08907316625118256\n",
      "Train Loss: 0.05769546702504158\n",
      "Train Loss: 0.03403728827834129\n",
      "Train Loss: 0.06706888973712921\n",
      "Train Loss: 0.039160631597042084\n",
      "Train Loss: 0.038524825125932693\n",
      "Train Loss: 0.03393446281552315\n",
      "Train Loss: 0.059106774628162384\n",
      "Train Loss: 0.062143534421920776\n",
      "Train Loss: 0.04239720106124878\n",
      "Train Loss: 0.08683141320943832\n",
      "Train Loss: 0.0894777774810791\n",
      "Train Loss: 0.046314772218465805\n",
      "Train Loss: 0.061626095324754715\n",
      "Train Loss: 0.0365058071911335\n",
      "Train Loss: 0.06262728571891785\n",
      "Train Loss: 0.044520847499370575\n",
      "Train Loss: 0.058274757117033005\n",
      "Train Loss: 0.07120580226182938\n",
      "Train Loss: 0.05839676409959793\n",
      "Train Loss: 0.04640376567840576\n",
      "Train Loss: 0.03861980140209198\n",
      "Train Loss: 0.04624105617403984\n",
      "Train Loss: 0.06504414230585098\n",
      "Train Loss: 0.06918532401323318\n",
      "Train Loss: 0.04747757315635681\n",
      "Train Loss: 0.052190136164426804\n",
      "Train Loss: 0.05288241431117058\n",
      "Train Loss: 0.040553148835897446\n",
      "Train Loss: 0.04596225917339325\n",
      "Train Loss: 0.04418228939175606\n",
      "Train Loss: 0.03836945444345474\n",
      "Train Loss: 0.07523367553949356\n",
      "Train Loss: 0.029806390404701233\n",
      "Train Loss: 0.05993741378188133\n",
      "Train Loss: 0.7235068082809448\n",
      "Train Loss: 0.04393802210688591\n",
      "Train Loss: 0.05265706405043602\n",
      "Train Loss: 0.0463358573615551\n",
      "Train Loss: 0.05512109771370888\n",
      "Train Loss: 0.06837358325719833\n",
      "Train Loss: 0.04094719514250755\n",
      "Train Loss: 0.060591571033000946\n",
      "Train Loss: 0.028810029849410057\n",
      "Train Loss: 0.06093495339155197\n",
      "Train Loss: 0.048448413610458374\n",
      "Train Loss: 0.04130203649401665\n",
      "Train Loss: 0.05598907172679901\n",
      "Train Loss: 0.06288734823465347\n",
      "Train Loss: 0.059564683586359024\n",
      "Train Loss: 0.10148655623197556\n",
      "Train Loss: 0.04827434569597244\n",
      "Train Loss: 0.05677146464586258\n",
      "Train Loss: 0.04484982416033745\n",
      "Train Loss: 0.07087013125419617\n",
      "Train Loss: 0.06314019113779068\n",
      "Train Loss: 0.07518643140792847\n",
      "Train Loss: 0.04322730377316475\n",
      "Train Loss: 0.06162780150771141\n",
      "Train Loss: 0.06184515729546547\n",
      "Train Loss: 0.05431383475661278\n",
      "Train Loss: 0.043009597808122635\n",
      "Train Loss: 0.051928456872701645\n",
      "Train Loss: 0.0256534181535244\n",
      "Train Loss: 0.03514385595917702\n",
      "Train Loss: 0.052406713366508484\n",
      "Train Loss: 0.05851389095187187\n",
      "Train Loss: 0.05542508140206337\n",
      "Train Loss: 0.041553229093551636\n",
      "Train Loss: 0.04287956282496452\n",
      "Train Loss: 0.03082859516143799\n",
      "Train Loss: 0.07108864933252335\n",
      "Train Loss: 0.07484421879053116\n",
      "Train Loss: 0.06734402477741241\n",
      "Train Loss: 0.05870463699102402\n",
      "Train Loss: 0.09747719764709473\n",
      "Train Loss: 0.055628061294555664\n",
      "Train Loss: 0.031044870615005493\n",
      "Train Loss: 0.11034468561410904\n",
      "Train Loss: 0.06055353209376335\n",
      "Train Loss: 0.08893676847219467\n",
      "Train Loss: 0.04602362960577011\n",
      "Train Loss: 0.055518731474876404\n",
      "Train Loss: 0.03775578737258911\n",
      "Train Loss: 0.034668322652578354\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883487d7a5d4424ea94ac9b8329d02dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03649717569351196\n",
      "Validation Loss: 0.03735308721661568\n",
      "Validation Loss: 0.03902982547879219\n",
      "Validation Loss: 0.03654856234788895\n",
      "Validation Loss: 1.0685453414916992\n",
      "Validation Loss: 0.20973657071590424\n",
      "Validation Loss: 0.025759980082511902\n",
      "Validation Loss: 0.061710651963949203\n",
      "Validation Loss: 0.04754149541258812\n",
      "Validation Loss: 0.039122387766838074\n",
      "Validation Loss: 0.040125831961631775\n",
      "Validation Loss: 0.03944239765405655\n",
      "Validation Loss: 0.026308715343475342\n",
      "Validation Loss: 0.0728951096534729\n",
      "Validation Loss: 0.057156916707754135\n",
      "Validation Loss: 0.01566929742693901\n",
      "Validation Loss: 0.06113683432340622\n",
      "Validation Loss: 0.044356632977724075\n",
      "Validation Loss: 0.0604969821870327\n",
      "Validation Loss: 0.03337536007165909\n",
      "Validation Loss: 0.04146425426006317\n",
      "Validation Loss: 0.017314886674284935\n",
      "Validation Loss: 0.030126789584755898\n",
      "Validation Loss: 0.07915202528238297\n",
      "Validation Loss: 0.05555601790547371\n",
      "Validation Loss: 0.07678656280040741\n",
      "Validation Loss: 0.09141544252634048\n",
      "Validation Loss: 0.037036772817373276\n",
      "Validation Loss: 0.03649146482348442\n",
      "Validation Loss: 0.05744920298457146\n",
      "Validation Loss: 0.03868008404970169\n",
      "Validation Loss: 0.03326231986284256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.03440159559249878\n",
      "Validation Loss: 0.052015457302331924\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9d38b64a19451baad4763978d49c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.05222459137439728    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.05222459137439728   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.05222459137439728}]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_dataset = WeatherDataset(X_train, y_train)\n",
    "val_dataset = WeatherDataset(X_val, y_val)\n",
    "test_dataset = WeatherDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Hyperparameters for SegRNN\n",
    "input_size = X.shape[2]  # Number of features\n",
    "hidden_size = 512  # Based on the SEGRNN paper\n",
    "output_size = X.shape[2]  # Predict all features\n",
    "segment_length = 8  # Based on the SEGRNN paper\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize SegRNNModel\n",
    "model = SegRNNModel(\n",
    "   input_size=input_size,\n",
    "   hidden_size=hidden_size,\n",
    "   output_size=output_size,\n",
    "   segment_length=segment_length,\n",
    "   learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger(\"logs\", name=\"segrnn_experiment\")\n",
    "\n",
    "# Checkpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "   dirpath=\"checkpoints/\",\n",
    "   filename=\"segrnn-{epoch:02d}-{val_loss:.4f}\",\n",
    "   save_top_k=1,\n",
    "   monitor=\"val_loss\",  # Monitor validation loss\n",
    "   mode=\"min\"\n",
    ")\n",
    "\n",
    "# Trainer with logging and checkpointing\n",
    "trainer = Trainer(\n",
    "   max_epochs=10,\n",
    "   accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "   devices=1,\n",
    "   logger=logger,\n",
    "   callbacks=[checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Train the model, including validation loader\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Optional: Evaluate on the test set\n",
    "trainer.test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23700), started 8:15:41 ago. (Use '!kill 23700' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-82df61d3509ce785\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-82df61d3509ce785\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_projects",
   "language": "python",
   "name": "torch_projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
